{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af325be-1697-46f9-ad1f-39f2451d9614",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install aicsimageio[nd2]\n",
    "!pip install xlsxwriter\n",
    "!pip install reportlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882e2ef9-43a3-43d2-a0cb-17fe199b14be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import napari\n",
    "from napari.settings import get_settings\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.lines import Line2D\n",
    "import SimpleITK as sitk\n",
    "import skimage\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "from scipy.ndimage import label, zoom, binary_dilation, generate_binary_structure\n",
    "from scipy.stats import gaussian_kde\n",
    "from skimage.segmentation import watershed, relabel_sequential, expand_labels\n",
    "from skimage.draw import line as draw_line\n",
    "from vispy.color import Colormap\n",
    "from matplotlib.colors import to_rgb\n",
    "from csbdeep.utils import normalize\n",
    "from stardist.models import StarDist2D\n",
    "from collections import defaultdict\n",
    "from aicsimageio import AICSImage\n",
    "from nd2reader import ND2Reader\n",
    "import meshlib.mrmeshpy as mr\n",
    "import meshlib.mrmeshnumpy as mrn\n",
    "import meshio\n",
    "import statistics as st\n",
    "import tetgen\n",
    "\n",
    "from skimage import filters, morphology\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import ball\n",
    "from skimage.filters import threshold_otsu, threshold_sauvola\n",
    "from skimage.measure import find_contours, regionprops\n",
    "\n",
    "from PIL import Image as PILImage\n",
    "from reportlab.platypus import Image as RLImage\n",
    "from reportlab.platypus import (\n",
    "    SimpleDocTemplate, Image, Paragraph, Spacer, Table, TableStyle, PageBreak\n",
    ")\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.lib import colors\n",
    "import xlsxwriter\n",
    "\n",
    "# Enable interactive mode for napari in Jupyter\n",
    "settings = get_settings()\n",
    "settings.application.ipy_interactive = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388a39a6-25b4-497e-bfe1-5250ba3ad7bc",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f0f80-eaef-49a8-b5b7-f772bcfb4f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image processing and utility functions\n",
    "\n",
    "def hist_plot(im_in, stain_complete_df, thresh=0, legend=False):\n",
    "    \"\"\"Plot histogram and CDF for each channel.\"\"\"\n",
    "    fig, axs = plt.subplots(1, im_in.shape[3], figsize=(15, 2))\n",
    "    for c in range(im_in.shape[3]):\n",
    "        hist, _ = np.histogram(im_in[:, :, :, c].flatten(), 256, [0, 256])\n",
    "        cdf = hist.cumsum()\n",
    "        cdf_normalized = cdf * hist.max() / cdf.max()\n",
    "        color = stain_complete_df.loc[stain_complete_df.index[c], 'Color']\n",
    "        axs[c].plot(cdf_normalized, color='b')\n",
    "        axs[c].hist(im_in[:, :, :, c].flatten(), 256, [0, 256], color=color if color != 'WHITE' else 'GRAY')\n",
    "        axs[c].set_xlim([0, 256])\n",
    "        if legend:\n",
    "            axs[c].legend(('cdf', 'histogram'), loc='upper left')\n",
    "        if thresh > 0:\n",
    "            axs[c].plot([thresh, thresh], [0, cdf_normalized.max()], color='g')\n",
    "        axs[c].set_title(stain_complete_df.index[c])\n",
    "        axs[c].set_yscale('log')\n",
    "\n",
    "def napari_contrast_gamma_uint8(image, contrast_limits, gamma):\n",
    "    \"\"\"\n",
    "    Apply Napari-style contrast limits + gamma correction,\n",
    "    and return the resulting image as uint8.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.ndarray\n",
    "        Input image (any dtype).\n",
    "    contrast_limits : tuple (clim_min, clim_max)\n",
    "        Same values you see in Napari GUI.\n",
    "    gamma : float\n",
    "        Gamma value from Napari GUI.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out_uint8 : np.ndarray (uint8)\n",
    "        Image transformed exactly like Napari display,\n",
    "        then mapped to 0–255.\n",
    "    \"\"\"\n",
    "\n",
    "    clim_min, clim_max = contrast_limits\n",
    "\n",
    "    # Convert to float\n",
    "    img = image.astype(np.float32)\n",
    "\n",
    "    # Napari contrast normalization\n",
    "    img = (img - clim_min) / (clim_max - clim_min)\n",
    "    img = np.clip(img, 0.0, 1.0)\n",
    "\n",
    "    # Napari gamma\n",
    "    img = img ** gamma\n",
    "\n",
    "    # Convert display range [0,1] → uint8 [0,255]\n",
    "    out_uint8 = (img * 255).round().astype(np.uint8)\n",
    "\n",
    "    return out_uint8\n",
    "\n",
    "def remove_small_islands(binary_matrix, area_threshold):\n",
    "    \"\"\"Remove small connected components from a binary mask.\"\"\"\n",
    "    labeled_array, num_features = label(binary_matrix)\n",
    "    for i in range(1, num_features + 1):\n",
    "        component = (labeled_array == i)\n",
    "        if component.sum() < area_threshold:\n",
    "            binary_matrix[component] = 0\n",
    "    return binary_matrix\n",
    "\n",
    "def stardist3d_from_2d(\n",
    "    img_3d,\n",
    "    model_name=\"2D_versatile_fluo\",\n",
    "    nucleus_radius=5,\n",
    "    voxel_size=(1.0, 0.5, 0.5),\n",
    "    norm=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Apply StarDist2D slice-by-slice to a 3D stack, merge predictions,\n",
    "    and split weakly connected nuclei using distance-based watershed.\n",
    "    Handles anisotropic voxel spacing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_3d : np.ndarray\n",
    "        Input 3D grayscale image, shape (Z, Y, X).\n",
    "    model_name : str\n",
    "        Name of pretrained StarDist2D model.\n",
    "    nucleus_radius : float\n",
    "        Approximate radius of nuclei in pixels (XY units).\n",
    "    voxel_size : tuple(float)\n",
    "        Physical voxel size as (z_spacing, y_spacing, x_spacing).\n",
    "    norm : bool\n",
    "        Normalize each 2D slice before prediction.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    labels_split : np.ndarray\n",
    "        3D labeled array (int32), same shape as input.\n",
    "    \"\"\"\n",
    "\n",
    "    assert img_3d.ndim == 3, \"Input must be 3D (Z, Y, X)\"\n",
    "    z_spacing, y_spacing, x_spacing = voxel_size\n",
    "\n",
    "    print(f\"Running StarDist2D on {img_3d.shape[0]} z-slices...\")\n",
    "    model = StarDist2D.from_pretrained(model_name)\n",
    "\n",
    "    labels_3d = np.zeros_like(img_3d, dtype=np.int32)\n",
    "    current_label = 1\n",
    "\n",
    "    for z in range(img_3d.shape[0]):\n",
    "        img = img_3d[z]\n",
    "        if norm:\n",
    "            img = normalize(img, 1, 99.8, axis=None)\n",
    "\n",
    "        labels2d, _ = model.predict_instances(img)\n",
    "        labels2d = np.where(labels2d > 0, labels2d + current_label, 0)\n",
    "        labels_3d[z] = labels2d\n",
    "        current_label = labels2d.max() + 1\n",
    "\n",
    "    # Merge touching objects in 3D\n",
    "    labels_3d = skimage.measure.label(labels_3d > 0, connectivity=1)\n",
    "\n",
    "    # --- Anisotropic distance-based splitting ---\n",
    "    print(\"Computing distance transform with anisotropic voxel spacing...\")\n",
    "    distance = ndi.distance_transform_edt(labels_3d > 0, sampling=voxel_size)\n",
    "\n",
    "    # Estimate local maxima using nucleus_radius as search distance in XY\n",
    "    footprint = np.ones(\n",
    "        (\n",
    "            max(1, int(z_spacing / y_spacing)),  # thin in z\n",
    "            int(nucleus_radius),\n",
    "            int(nucleus_radius),\n",
    "        ),\n",
    "        dtype=bool,\n",
    "    )\n",
    "\n",
    "    local_max = peak_local_max(\n",
    "        distance,\n",
    "        footprint=footprint,\n",
    "        labels=labels_3d > 0,\n",
    "        exclude_border=False,\n",
    "    )\n",
    "\n",
    "    # Create markers for watershed\n",
    "    markers = np.zeros_like(labels_3d, dtype=int)\n",
    "    for i, coord in enumerate(local_max, start=1):\n",
    "        markers[tuple(coord)] = i\n",
    "\n",
    "    # Watershed segmentation\n",
    "    print(\"Running 3D watershed to split connected nuclei...\")\n",
    "    labels_split = watershed(-distance, markers, mask=labels_3d > 0)\n",
    "\n",
    "    print(f\"Done. Found {labels_split.max()} nuclei.\")\n",
    "    return labels_split\n",
    "\n",
    "def make_anisotropic_footprint(radius_Z, radius_Y, radius_X):\n",
    "    zz, yy, xx = np.ogrid[\n",
    "        -radius_Z:radius_Z+1,\n",
    "        -radius_Y:radius_Y+1,\n",
    "        -radius_X:radius_X+1\n",
    "    ]\n",
    "    ellipsoid = ((zz / radius_Z)**2 + (yy / radius_Y)**2 + (xx / radius_X)**2) <= 1\n",
    "    return ellipsoid\n",
    "\n",
    "def voxel_volume(ri_x, ri_y, ri_z, zooms):\n",
    "    return (ri_x * ri_y * ri_z) / np.prod(zooms)\n",
    "\n",
    "def save_raw_png(arr, filename, contrast_limits=None, gamma=None):\n",
    "    \"\"\"\n",
    "    Save a 2D numpy array to PNG while optionally applying Napari-style\n",
    "    contrast limits and gamma so saved images match displayed intensities.\n",
    "\n",
    "    Parameters\n",
    "    - arr: 2D array-like\n",
    "    - filename: output path\n",
    "    - contrast_limits: tuple (min, max) to map to [0,1] before gamma (optional)\n",
    "    - gamma: gamma exponent to apply after contrast (optional)\n",
    "\n",
    "    Backwards-compatible: if no contrast_limits provided, tries to preserve\n",
    "    dtype and dynamic range as before.\n",
    "    \"\"\"\n",
    "    arr = np.asarray(arr)\n",
    "\n",
    "    # If user requested Napari-style mapping, use helper\n",
    "    if contrast_limits is not None:\n",
    "        clim = contrast_limits\n",
    "        g = 1.0 if gamma is None else float(gamma)\n",
    "        try:\n",
    "            out = napari_contrast_gamma_uint8(arr.astype(np.float32), (float(clim[0]), float(clim[1])), g)\n",
    "            img = PILImage.fromarray(out)\n",
    "            img.save(filename)\n",
    "            return filename\n",
    "        except Exception:\n",
    "            # fallback to naive save below\n",
    "            pass\n",
    "\n",
    "    # --- Fallback / legacy behavior ---\n",
    "    # Already uint8/uint16 → save as-is\n",
    "    if arr.dtype == np.uint8 or arr.dtype == np.uint16:\n",
    "        img = PILImage.fromarray(arr)\n",
    "        img.save(filename)\n",
    "        return filename\n",
    "\n",
    "    # Float data: scale by max to choose appropriate depth\n",
    "    if np.issubdtype(arr.dtype, np.floating):\n",
    "        maxv = float(arr.max()) if arr.size else 0.0\n",
    "        if maxv == 0:\n",
    "            arr8 = np.zeros_like(arr, dtype=np.uint8)\n",
    "            img = PILImage.fromarray(arr8)\n",
    "            img.save(filename)\n",
    "            return filename\n",
    "\n",
    "        if maxv <= 255:\n",
    "            arr_scaled = (arr / maxv) * 255.0\n",
    "            arr_scaled = np.clip(arr_scaled, 0, 255).astype(np.uint8)\n",
    "        else:\n",
    "            arr_scaled = (arr / maxv) * 65535.0\n",
    "            arr_scaled = np.clip(arr_scaled, 0, 65535).astype(np.uint16)\n",
    "\n",
    "        img = PILImage.fromarray(arr_scaled)\n",
    "        img.save(filename)\n",
    "        return filename\n",
    "\n",
    "    # Integer types other than uint8/uint16\n",
    "    if np.issubdtype(arr.dtype, np.integer):\n",
    "        maxv = int(arr.max()) if arr.size else 0\n",
    "        if maxv <= 255:\n",
    "            arr8 = arr.astype(np.uint8)\n",
    "            img = PILImage.fromarray(arr8)\n",
    "            img.save(filename)\n",
    "            return filename\n",
    "        elif maxv <= 65535:\n",
    "            arr16 = arr.astype(np.uint16)\n",
    "            img = PILImage.fromarray(arr16)\n",
    "            img.save(filename)\n",
    "            return filename\n",
    "        else:\n",
    "            arr16 = (arr / maxv * 65535).astype(np.uint16)\n",
    "            img = PILImage.fromarray(arr16)\n",
    "            img.save(filename)\n",
    "            return filename\n",
    "\n",
    "    raise ValueError(\"Unsupported dtype for PNG saving.\")\n",
    "\n",
    "def crop_nucleus_with_padding(nucleus_mask, full_img_stack, pad=20):\n",
    "    \"\"\"\n",
    "    nucleus_mask: 3D boolean array\n",
    "    full_img_stack: dict {cond: 3D array}\n",
    "    \"\"\"\n",
    "    # pick best z slice\n",
    "    if nucleus_mask.ndim == 3:\n",
    "        z_counts = nucleus_mask.sum(axis=(1, 2))\n",
    "        best_z = int(np.argmax(z_counts))\n",
    "        nuc2d = nucleus_mask[best_z]\n",
    "    else:\n",
    "        best_z = 0\n",
    "        nuc2d = nucleus_mask\n",
    "\n",
    "    ys, xs = np.where(nuc2d)\n",
    "    if len(xs) == 0:\n",
    "        return None, best_z, None, None\n",
    "\n",
    "    # bounding box\n",
    "    y_min0 = max(0, ys.min() - pad)\n",
    "    y_max0 = ys.max() + pad\n",
    "    x_min0 = max(0, xs.min() - pad)\n",
    "    x_max0 = xs.max() + pad\n",
    "\n",
    "    crop_dict = {}\n",
    "    heights, widths = [], []\n",
    "\n",
    "    # crop each condition\n",
    "    for cond, img3D in full_img_stack.items():\n",
    "        Z, H_full, W_full = img3D.shape\n",
    "\n",
    "        y_min = y_min0\n",
    "        y_max = min(y_max0, H_full)\n",
    "        x_min = x_min0\n",
    "        x_max = min(x_max0, W_full)\n",
    "\n",
    "        # keep original intensities (do not normalize here)\n",
    "        cropped = img3D[best_z, y_min:y_max, x_min:x_max].astype(float)\n",
    "\n",
    "        crop_dict[cond] = cropped\n",
    "        heights.append(cropped.shape[0])\n",
    "        widths.append(cropped.shape[1])\n",
    "\n",
    "    min_H = int(min(heights)) if heights else 0\n",
    "    min_W = int(min(widths)) if widths else 0\n",
    "\n",
    "    return crop_dict, best_z, (y_min0, x_min0), (min_H, min_W)\n",
    "\n",
    "def save_merged_figure(\n",
    "    nucleus_mask, full_img_stack, condition_colors, nucleus_id,\n",
    "    seg_stack,\n",
    "    nucleus_color='blue', cytoplasm_color='green', pcm_color='magenta',\n",
    "    pad=20, out_dir=\"merged_png\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Build merged RGB: nuclei (blue) + cytoplasm (green) + PCM (magenta) + marker overlay.\n",
    "    \"\"\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    crop_dict, best_z, (y0, x0), (min_H, min_W) = crop_nucleus_with_padding(nucleus_mask, full_img_stack, pad=pad)\n",
    "    if crop_dict is None or min_H <= 0 or min_W <= 0:\n",
    "        return None\n",
    "\n",
    "    # Initialize black RGB\n",
    "    merged_rgb = np.zeros((min_H, min_W, 3), dtype=float)\n",
    "\n",
    "    structure_opacity = 0.2\n",
    "    white_rgb = np.array([1.0, 1.0, 1.0])  # Pure white\n",
    "    blue_rgb = np.array([0.0,0.0,1.0])\n",
    "    \n",
    "    # 1. Nuclei (white @ 20%)\n",
    "    if nucleus_mask.ndim == 3:\n",
    "        nuc2d = nucleus_mask[best_z]\n",
    "    else:\n",
    "        nuc2d = nucleus_mask\n",
    "    nuc_crop = nuc2d[y0:y0+min_H, x0:x0+min_W].astype(float)\n",
    "    merged_rgb += nuc_crop[..., None] * blue_rgb * structure_opacity\n",
    "    \n",
    "    # 2+3. Dashed contours around cytoplasm + PCM (white, 20% opacity)\n",
    "    structure_opacity = 0.2\n",
    "    white_rgb = np.array([1.0, 1.0, 1.0])\n",
    "    \n",
    "    # Combined cyto + PCM mask\n",
    "    cyto_mask = (seg_stack.get('Cytoplasm', np.zeros_like(nucleus_mask)) == nucleus_id)\n",
    "    pcm_mask = (seg_stack.get('PCM', np.zeros_like(nucleus_mask)) == nucleus_id)\n",
    "    combined_mask = cyto_mask | pcm_mask  # Union of both\n",
    "    \n",
    "    if np.any(combined_mask):\n",
    "        # Use best_z slice\n",
    "        if combined_mask.ndim == 3:\n",
    "            combined_2d = combined_mask[best_z]\n",
    "        else:\n",
    "            combined_2d = combined_mask\n",
    "        \n",
    "        # Crop\n",
    "        combined_crop = combined_2d[y0:y0+min_H, x0:x0+min_W].astype(float)\n",
    "        \n",
    "        # Create dashed contour (3px thick, 50% dash:gap)\n",
    "        from skimage.measure import find_contours\n",
    "        contours = find_contours(combined_crop, 0.5, fully_connected='low')\n",
    "        \n",
    "        # Draw on temp RGB canvas\n",
    "        contour_rgb = np.zeros((min_H, min_W, 3), dtype=float)\n",
    "        for contour in contours:\n",
    "            # Scale contour coords back to image space\n",
    "            contour[:, 0] *= min_H / combined_crop.shape[0]  # y\n",
    "            contour[:, 1] *= min_W / combined_crop.shape[1]  # x\n",
    "            \n",
    "            # Integer positions for drawing\n",
    "            contour_int = contour.astype(int)\n",
    "            \n",
    "            # Dash pattern: every other pixel\n",
    "            for i in range(0, len(contour_int), 2):  # Step 2 for dash/gap\n",
    "                if i+1 < len(contour_int):\n",
    "                    # Draw 2px line segments\n",
    "                    rr, cc = draw_line(int(contour_int[i,0]), int(contour_int[i,1]),\n",
    "                                       int(contour_int[i+1,0]), int(contour_int[i+1,1]))\n",
    "                    contour_rgb[rr, cc] = white_rgb * structure_opacity\n",
    "        \n",
    "        merged_rgb += contour_rgb\n",
    "\n",
    "    # 4. Marker channels (additive overlay)\n",
    "    for cond, img in crop_dict.items():\n",
    "        img_small = img[:min_H, :min_W].copy()\n",
    "        \n",
    "        # Napari contrast/gamma\n",
    "        if (cond in stain_complete_df.index) and ('Cont_min' in stain_complete_df.columns):\n",
    "            try:\n",
    "                clim = (stain_complete_df.loc[cond, 'Cont_min'], stain_complete_df.loc[cond, 'Cont_max'])\n",
    "                gamma = stain_complete_df.loc[cond, 'Gamma'] if 'Gamma' in stain_complete_df.columns else 1.0\n",
    "                img_display = napari_contrast_gamma_uint8(img_small.astype(np.float32), \n",
    "                                                          (float(clim[0]), float(clim[1])), \n",
    "                                                          float(gamma))\n",
    "                img_normalized = img_display.astype(float) / 255.0\n",
    "            except:\n",
    "                img_normalized = img_small / (img_small.max() + 1e-6)\n",
    "        else:\n",
    "            img_normalized = img_small / (img_small.max() + 1e-6)\n",
    "        \n",
    "        color = np.array(mcolors.to_rgb(condition_colors.get(cond, 'gray')))\n",
    "        merged_rgb += img_normalized[..., None] * color * 0.6  # Transparent overlay\n",
    "\n",
    "    # Clip and convert to uint8\n",
    "    merged_rgb = np.clip(merged_rgb, 0, 1.0)\n",
    "    merged_uint8 = (merged_rgb * 255).astype(np.uint8)\n",
    "\n",
    "    # Save PNG filename (not array)\n",
    "    fname = os.path.join(out_dir, f\"n{nucleus_id}_merged.png\")\n",
    "    PILImage.fromarray(merged_uint8).save(fname)\n",
    "    return fname\n",
    "\n",
    "def double_plateau_hist_equalization_nd(\n",
    "    img: np.ndarray,\n",
    "    num_plateaus: int = 2,\n",
    "    plateau_factor: float = 0.5\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Multi-plateau histogram equalization for 8-bit images or volumes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img : np.ndarray\n",
    "        Input image/volume, uint8. Can be 2D (H,W) or 3D (Z,H,W) or 3D color (H,W,3).\n",
    "        For 3D, assumes scalar intensities (one channel).\n",
    "    num_plateaus : int\n",
    "        Number of plateau levels (2 = double plateau).\n",
    "    plateau_factor : float\n",
    "        Factor (0–1+) to compute plateau(s) from average count.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : np.ndarray\n",
    "        Equalized image/volume with multi-plateau clipping.\n",
    "    \"\"\"\n",
    "    if img.dtype != np.uint8:\n",
    "        raise ValueError(\"Input must be uint8\")\n",
    "\n",
    "    # 2D grayscale\n",
    "    if img.ndim == 2:\n",
    "        return _mphe_channel(img, num_plateaus, plateau_factor)\n",
    "\n",
    "    # 3D scalar volume (e.g. Z,H,W)\n",
    "    if img.ndim == 3 and img.shape[-1] != 3:\n",
    "        # Flatten to 1D for histogram, then map back\n",
    "        flat = img.ravel()\n",
    "        flat_eq = _mphe_flat(flat, num_plateaus, plateau_factor)\n",
    "        return flat_eq.reshape(img.shape)\n",
    "\n",
    "    # 3D color (H,W,3) image: apply on luminance\n",
    "    if img.ndim == 3 and img.shape[-1] == 3:\n",
    "        ycrcb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "        y, cr, cb = cv2.split(ycrcb)\n",
    "        y_eq = _mphe_channel(y, num_plateaus, plateau_factor)\n",
    "        ycrcb_eq = cv2.merge([y_eq, cr, cb])\n",
    "        out = cv2.cvtColor(ycrcb_eq, cv2.COLOR_YCrCb2BGR)\n",
    "        return out\n",
    "\n",
    "    raise ValueError(\"Unsupported input shape\")\n",
    "\n",
    "\n",
    "def _mphe_flat(\n",
    "    flat: np.ndarray,\n",
    "    num_plateaus: int,\n",
    "    plateau_factor: float\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Multi-plateau HE on a flat uint8 array.\"\"\"\n",
    "    # Compute histogram\n",
    "    hist = np.bincount(flat, minlength=256).astype(np.float64)\n",
    "    total_pixels = flat.size\n",
    "\n",
    "    mean_count = total_pixels / 256.0\n",
    "    base_plateau = plateau_factor * mean_count\n",
    "\n",
    "    plateau_levels = np.linspace(\n",
    "        base_plateau * 0.5,\n",
    "        base_plateau * (0.5 + num_plateaus),\n",
    "        num_plateaus\n",
    "    )\n",
    "\n",
    "    clipped_hist = hist.copy()\n",
    "\n",
    "    for p in plateau_levels:\n",
    "        excess = np.maximum(clipped_hist - p, 0)\n",
    "        clipped_hist = np.minimum(clipped_hist, p)\n",
    "        redistributed = excess.sum() / 256.0\n",
    "        clipped_hist += redistributed\n",
    "\n",
    "    cdf = np.cumsum(clipped_hist)\n",
    "    cdf_norm = cdf / cdf[-1]\n",
    "    lut = np.floor(255 * cdf_norm).astype(np.uint8)\n",
    "\n",
    "    return lut[flat]\n",
    "\n",
    "\n",
    "def _mphe_channel(channel: np.ndarray,\n",
    "                  num_plateaus: int,\n",
    "                  plateau_factor: float) -> np.ndarray:\n",
    "    \"\"\"2D helper using the 1D flat implementation.\"\"\"\n",
    "    flat = channel.ravel()\n",
    "    flat_eq = _mphe_flat(flat, num_plateaus, plateau_factor)\n",
    "    return flat_eq.reshape(channel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acba6cf-3693-44f0-a84e-458fe3eccc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unused watershed functions removed\n",
    "# The main nuclei segmentation is performed using shrink_to_markers_robust in the segmentation section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eee1c3-7752-4f21-803a-bf592e4dee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "\n",
    "def shrink_to_markers(binary_3d, connectivity=2, max_iter=100,\n",
    "                     min_final_size=3, max_final_cc=3,\n",
    "                     merge_small_touching=False, size_ratio_thresh=0.5):\n",
    "    \"\"\"\n",
    "    Shrink each island until stable and create markers.\n",
    "    Optionally merge small touching marker-islands into larger neighbors.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    marker_image : bool\n",
    "    marker_labels : int\n",
    "    \"\"\"\n",
    "\n",
    "    binary_3d = binary_3d.astype(bool)\n",
    "    cc_labels, n_cc = ndi.label(\n",
    "        binary_3d,\n",
    "        structure=ndi.generate_binary_structure(3, connectivity)\n",
    "    )\n",
    "    marker_image = np.zeros_like(binary_3d, dtype=bool)\n",
    "    selem = ndi.generate_binary_structure(3, connectivity)\n",
    "\n",
    "    # --- shrink step ---\n",
    "    for cc_id in range(1, n_cc + 1):\n",
    "        cc_mask = (cc_labels == cc_id)\n",
    "        current = cc_mask.copy()\n",
    "        it = 0\n",
    "\n",
    "        while np.sum(current) > min_final_size and it < max_iter:\n",
    "            eroded = ndi.binary_erosion(current, structure=selem)\n",
    "\n",
    "            # if erosion kills it completely, keep last state\n",
    "            if not np.any(eroded):\n",
    "                break\n",
    "\n",
    "            # count components after erosion\n",
    "            n_cc_eroded = ndi.label(eroded, structure=selem)[1]\n",
    "            if n_cc_eroded > max_final_cc:\n",
    "                break  # keep pre-split state\n",
    "\n",
    "            current = eroded\n",
    "            it += 1\n",
    "\n",
    "        marker_image |= current\n",
    "\n",
    "    # label marker islands\n",
    "    marker_labels, n_markers = ndi.label(\n",
    "        marker_image,\n",
    "        structure=ndi.generate_binary_structure(3, connectivity)\n",
    "    )\n",
    "    \n",
    "    if not merge_small_touching or n_markers <= 1:\n",
    "        return marker_image, marker_labels\n",
    "\n",
    "    # --- adjacency + size-based merging ---\n",
    "    # compute sizes\n",
    "    labels, counts = np.unique(marker_labels, return_counts=True)\n",
    "    sizes = dict(zip(labels.tolist(), counts.tolist()))\n",
    "    sizes.pop(0, None)  # remove background\n",
    "\n",
    "    Z, Y, X = marker_labels.shape\n",
    "    offsets = []\n",
    "    for dz in [-1, 0, 1]:\n",
    "        for dy in [-1, 0, 1]:\n",
    "            for dx in [-1, 0, 1]:\n",
    "                if dz == dy == dx == 0:\n",
    "                    continue\n",
    "                # 6-neighborhood if connectivity==1, else denser\n",
    "                if connectivity == 1 and (abs(dx)+abs(dy)+abs(dz) > 1):\n",
    "                    continue\n",
    "                offsets.append((dz, dy, dx))\n",
    "\n",
    "    # build adjacency set\n",
    "    neighbors = defaultdict(set)\n",
    "    for z in range(Z):\n",
    "        for y in range(Y):\n",
    "            for x in range(X):\n",
    "                c = marker_labels[z, y, x]\n",
    "                if c == 0:\n",
    "                    continue\n",
    "                for dz, dy, dx in offsets:\n",
    "                    nz, ny, nx = z+dz, y+dy, x+dx\n",
    "                    if 0 <= nz < Z and 0 <= ny < Y and 0 <= nx < X:\n",
    "                        n = marker_labels[nz, ny, nx]\n",
    "                        if n > 0 and n != c:\n",
    "                            neighbors[c].add(n)\n",
    "\n",
    "    # decide reassignment: each label may be reassigned to one bigger neighbor\n",
    "    new_label = {lab: lab for lab in sizes.keys()}\n",
    "    print(neighbors)\n",
    "    for lab, neighs in neighbors.items():\n",
    "        #print(neighs)\n",
    "        if not neighs:\n",
    "            continue\n",
    "        size_lab = sizes[lab]\n",
    "        # find biggest neighbor\n",
    "        big = max(neighs, key=lambda L: sizes.get(L, 0))\n",
    "        size_big = sizes.get(big, 0)\n",
    "        if size_big <= 0:\n",
    "            continue\n",
    "        # if lab is at least 50% smaller than the biggest neighbor, merge into it\n",
    "        print(size_lab)\n",
    "        print(size_big)\n",
    "        if (size_lab <= size_ratio_thresh * size_big) or (size_lab < 20.0):\n",
    "            new_label[lab] = big\n",
    "        else:\n",
    "            print(size_lab)\n",
    "            print(size_big)\n",
    "\n",
    "    # apply reassignment\n",
    "    relabeled = marker_labels.copy()\n",
    "    for lab, target in new_label.items():\n",
    "        if lab != target:\n",
    "            relabeled[marker_labels == lab] = target\n",
    "\n",
    "    # relabel to consecutive integers\n",
    "    final_labels, _ = ndi.label(relabeled > 0,\n",
    "                                structure=ndi.generate_binary_structure(3, connectivity))\n",
    "\n",
    "    final_markers = final_labels > 0\n",
    "    return final_markers, final_labels\n",
    "\n",
    "def shrink_to_markers_robust(binary_3d, min_marker_size=1, size_ratio_thresh=0.4, **kwargs):\n",
    "    \"\"\"shrink_to_markers + absolute size filter + relaxed connectivity\"\"\"\n",
    "    markers_bin, markers_lab = shrink_to_markers(binary_3d, connectivity=2, **kwargs)\n",
    "    \n",
    "    # absolute size filter\n",
    "    sizes = np.bincount(markers_lab.ravel())[1:]\n",
    "    keep_labels = np.where(sizes >= min_marker_size)[0] + 1\n",
    "    \n",
    "    filtered = np.isin(markers_lab, keep_labels)\n",
    "    final_labels, _ = ndi.label(filtered)\n",
    "    \n",
    "    return filtered, final_labels\n",
    "\n",
    "def remove_small_island_labels(marker_labels, connectivity=1, size_ratio_thresh=0.5, min_cell_size=5.0):\n",
    "    labels, counts = np.unique(marker_labels, return_counts=True)\n",
    "    sizes = dict(zip(labels.tolist(), counts.tolist()))\n",
    "    sizes.pop(0, None)  # remove background\n",
    "\n",
    "    Z, Y, X = marker_labels.shape\n",
    "    offsets = []\n",
    "    for dz in [-1, 0, 1]:\n",
    "        for dy in [-1, 0, 1]:\n",
    "            for dx in [-1, 0, 1]:\n",
    "                if dz == dy == dx == 0:\n",
    "                    continue\n",
    "                # 6-neighborhood if connectivity==1, else denser\n",
    "                if connectivity == 1 and (abs(dx)+abs(dy)+abs(dz) > 1):\n",
    "                    continue\n",
    "                offsets.append((dz, dy, dx))\n",
    "\n",
    "    # build adjacency set\n",
    "    neighbors = defaultdict(set)\n",
    "    for z in range(Z):\n",
    "        for y in range(Y):\n",
    "            for x in range(X):\n",
    "                c = marker_labels[z, y, x]\n",
    "                if c == 0:\n",
    "                    continue\n",
    "                for dz, dy, dx in offsets:\n",
    "                    nz, ny, nx = z+dz, y+dy, x+dx\n",
    "                    if 0 <= nz < Z and 0 <= ny < Y and 0 <= nx < X:\n",
    "                        n = marker_labels[nz, ny, nx]\n",
    "                        if n > 0 and n != c:\n",
    "                            neighbors[c].add(n)\n",
    "\n",
    "    # decide reassignment: each label may be reassigned to one bigger neighbor\n",
    "    new_label = {lab: lab for lab in sizes.keys()}\n",
    "    for lab, neighs in neighbors.items():\n",
    "        #print(neighs)\n",
    "        if not neighs:\n",
    "            continue\n",
    "        size_lab = sizes[lab]\n",
    "        # find biggest neighbor\n",
    "        big = max(neighs, key=lambda L: sizes.get(L, 0))\n",
    "        size_big = sizes.get(big, 0)\n",
    "        if size_big <= 0:\n",
    "            continue\n",
    "        # if lab is at least 50% smaller than the biggest neighbor, merge into it\n",
    "        if (size_lab <= size_ratio_thresh * size_big) or (size_lab < min_cell_size):\n",
    "            new_label[lab] = big\n",
    "\n",
    "    # apply reassignment\n",
    "    relabeled = marker_labels.copy()\n",
    "    for lab, target in new_label.items():\n",
    "        if lab != target:\n",
    "            relabeled[marker_labels == lab] = target\n",
    "\n",
    "    # relabel to consecutive integers\n",
    "    final_labels, _ = ndi.label(relabeled > 0,\n",
    "                                structure=ndi.generate_binary_structure(3, connectivity))\n",
    "\n",
    "    final_markers = final_labels > 0\n",
    "    return final_markers, relabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5340cf51-c1a1-4848-8063-c6b2086121df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional functions are defined in the Functions cell above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f9ed9d-96d7-4068-9b7c-f2ec17a58aa4",
   "metadata": {},
   "source": [
    "# INPUTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7688f7-5b17-498f-86b8-90e4a13226f3",
   "metadata": {},
   "source": [
    "### File upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41837bd-55ba-4b37-affd-bc756542813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TIFF file and extract image data\n",
    "input_file = 'GELMA1.nd2'\n",
    "big_image=True\n",
    "\n",
    "ROI = [0, 0, 0, 0, 0, 0] #XYZ - put 0 to keep the original value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cff9db6-0cb9-415e-afce-8202c42d9ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = AICSImage(input_file)\n",
    "if big_image:\n",
    "    x0, x1, y0, y1, z0, z1 = ROI\n",
    "    if x1==0:\n",
    "        x1 = meta.shape[4]\n",
    "    if y1==0:\n",
    "        y1 = meta.shape[3]\n",
    "    if z1==0:\n",
    "        z1 = meta.shape[2]\n",
    "    # Get lazy dask array in ZYXC order\n",
    "    lazy = meta.get_image_dask_data(\"ZYXC\")\n",
    "    sub = lazy[z0:z1, y0:y1, x0:x1, :]\n",
    "    # Actually load this subset into memory\n",
    "    img = sub.compute()  # This will be in ZYXC order\n",
    "    ROI = [0, 0, 0, 0, 0, 0]\n",
    "else:\n",
    "    # Also use ZYXC order for consistency\n",
    "    img = meta.get_image_data(\"ZYXC\", T=0) \n",
    "\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fabebf-7945-48e6-97a8-7683caed6219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get physical pixel sizes\n",
    "r_X = meta.physical_pixel_sizes.X #um/px\n",
    "r_Y = meta.physical_pixel_sizes.Y #um/px\n",
    "r_Z = meta.physical_pixel_sizes.Z #um/px\n",
    "print([r_X, r_Y, r_Z])\n",
    "\n",
    "if big_image==False:\n",
    "    imdata=meta.get_image_data()\n",
    "    imtype=imdata.dtype\n",
    "    bdepth=imtype.itemsize*8\n",
    "    print(imtype)\n",
    "\n",
    "with ND2Reader(input_file) as nd2:\n",
    "    print(\"Date:\", nd2.metadata.get(\"date\"))\n",
    "    print(\"Channels:\", nd2.metadata.get(\"channels\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e47b986-7d7b-4a57-a8ed-0473e4601c40",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c105211-8565-4b07-8add-dec175f71881",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei_diameter=10 #um\n",
    "cell_diameter=30 #um\n",
    "\n",
    "cyto_factor=3.0\n",
    "PCM_factor=4.0\n",
    "\n",
    "stain_dict = {\n",
    "    'LIVE': ['Calcein', '488_10x', 'Green'],\n",
    "    'DEAD': ['EthD', '555_10x', 'Red']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4afa3b-4101-4f6a-9632-11933a75c444",
   "metadata": {},
   "source": [
    "### Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b103b005-2497-4954-a829-2884c6bff02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_factor=0.5\n",
    "zoom_factors = [1.0, 1.0, 1.0] #XYZ\n",
    "zoom_factors = [x * scale_factor for x in zoom_factors]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957d1a10-4f9e-41ca-9785-ca2bae4302fd",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee8fc80-6be8-4ba6-b29f-f630c2648295",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_setup = 'CARLOTTA_LD_30m'\n",
    "use_setup = True\n",
    "trig_stardist = False  # Set to True to use StarDist model\n",
    "multilabel=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fa8737-3bbf-4ad5-a5af-5e4d20ffb197",
   "metadata": {},
   "source": [
    "## INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2fa518-bb33-4a94-92c0-9a9e932f8c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei_radius=nuclei_diameter*0.5 #um\n",
    "cell_radius=cell_diameter*0.5 #um\n",
    "\n",
    "nuclei_volume=np.ceil(4.0*((nuclei_radius)**3.0)*np.pi/3.0) #um^3\n",
    "cell_volume=np.ceil(4.0*((cell_radius)**3.0)*np.pi/3.0) #um^3\n",
    "\n",
    "x0, x1, y0, y1, z0, z1 = ROI\n",
    "\n",
    "# img is in ZYXC order, so shape[0]=Z, shape[1]=Y, shape[2]=X, shape[3]=C\n",
    "if z1==0:\n",
    "    z1 = img.shape[0]\n",
    "if y1==0:\n",
    "    y1 = img.shape[1]\n",
    "if x1==0:\n",
    "    x1 = img.shape[2]\n",
    "\n",
    "if big_image:\n",
    "    im_original = img.astype('float32')\n",
    "    im_original_ROI = im_original.copy()\n",
    "else:\n",
    "    im_original = meta.get_image_data(\"ZYXC\", S=0, T=0).astype('float32')\n",
    "    im_original_ROI = im_original[z0:z1,y0:y1,x0:x1,:]\n",
    "\n",
    "im_final_stack={'Original image': im_original_ROI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e12c7a-72e0-4050-91e8-0991d92718c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if big_image:\n",
    "    # Image is already in ZYXC order, just verify shape\n",
    "    orig = im_final_stack['Original image']\n",
    "    print('Original image shape (ZYXC):', orig.shape)\n",
    "    # Handle edge case: if there's an extra singleton dimension, squeeze it\n",
    "    if len(orig.shape) == 5 and orig.shape[4] == 1:\n",
    "        orig = orig[..., 0]\n",
    "        im_final_stack['Original image'] = orig\n",
    "        print('After removing singleton dimension:', orig.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24701d78-90c0-4df3-a9ac-0f9098776dc0",
   "metadata": {},
   "source": [
    "### Information about the staining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157d0505-c5fb-4b93-b130-254add588d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define staining dictionary and create DataFrame\n",
    "stain_dict = {k.upper(): [item.upper() if isinstance(item, str) else item for item in v] for k, v in stain_dict.items()}\n",
    "stain_df = pd.DataFrame.from_dict(stain_dict, orient='index', columns=['Marker', 'Laser', 'Color'])\n",
    "laser_order=nd2.metadata.get(\"channels\")\n",
    "\n",
    "# Map fluorophore to its order index\n",
    "order_map = {name.strip().upper(): i for i, name in enumerate(laser_order)}\n",
    "stain_df['order'] = stain_df['Laser'].map(order_map)\n",
    "\n",
    "# Sort by that and drop helper column\n",
    "stain_df = stain_df.sort_values('order').drop(columns='order')\n",
    "\n",
    "stain_df.index.name = 'Condition'\n",
    "\n",
    "if 'NUCLEI' not in stain_df.index:\n",
    "    print('No nuclei condition!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32d257a-9efb-44c3-8228-2be4978e9c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize each channel using napari\n",
    "im_in=im_final_stack['Original image'].copy()\n",
    "\n",
    "viewer_0 = napari.Viewer()\n",
    "for c, c_name in enumerate(stain_df['Marker']):\n",
    "    #im_in = meta.get_image_data(\"ZYX\", C=c, S=0, T=0).astype('float32')\n",
    "    im_channel = im_in[:,:,:,c]\n",
    "\n",
    "    # Stretch to [0, 255]\n",
    "    im_8b = ((im_channel - im_channel.min()) / (im_channel.max() - im_channel.min()) * 255).clip(0, 255).astype('uint8')\n",
    "    \n",
    "    viewer_0.add_image(im_8b, name=f\"{stain_df.index[c]} ({c_name})\", \n",
    "                        colormap=stain_df['Color'][c], blending='additive')\n",
    "\n",
    "    viewer_0.scale_bar.visible = True\n",
    "    viewer_0.scale_bar.unit = 'um'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d63bd45-32c7-45be-8c8e-d1644df8e94c",
   "metadata": {},
   "source": [
    "### Acquisition processing setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a2d9c9-3a3b-4f03-ab0d-85d806558cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for acquisition and contrast/gamma settings\n",
    "im_in=im_final_stack['Original image'].copy()\n",
    "\n",
    "stain_df = stain_df.reset_index(drop=False)\n",
    "stain_initial_df = stain_df.copy()\n",
    "stain_initial_df.set_index(['Condition', 'Marker', 'Laser'], inplace=True)\n",
    "stain_initial_df[['Cont_min', 'Cont_max', 'Gamma']] = [0, 255, 1]\n",
    "stain_complete_df=stain_initial_df.copy()\n",
    "\n",
    "setup_path = f\"{name_setup}_setup.csv\"\n",
    "if use_setup and os.path.exists(setup_path):\n",
    "    stain_setup_df = pd.read_csv(setup_path)\n",
    "    stain_setup_df.set_index(['Condition', 'Marker', 'Laser'], inplace=True)\n",
    "    for idx in stain_complete_df.index:\n",
    "        if idx in stain_setup_df.index:\n",
    "            stain_complete_df.loc[idx] = stain_setup_df.loc[idx]\n",
    "            stain_complete_df['Color'] = stain_initial_df['Color']\n",
    "        else:\n",
    "            use_setup = False\n",
    "\n",
    "if not use_setup or not os.path.exists(setup_path):\n",
    "    stain_complete_df=stain_initial_df.copy()\n",
    "    settings.application.ipy_interactive = False\n",
    "    viewer_1 = napari.Viewer()\n",
    "    for c, idx in enumerate(stain_complete_df.index):\n",
    "        im_channel = im_in[:,:,:,c]\n",
    "        im_channel = ((im_channel - im_channel.min()) / (im_channel.max() - im_channel.min()) * 255).clip(0, 255).astype('uint8')\n",
    "        viewer_1.add_image(im_channel, name=f\"{idx[0]} ({idx[1]})\", colormap=stain_initial_df.loc[idx]['Color'], blending='additive')\n",
    "    napari.run()\n",
    "    image_layers = [layer for layer in viewer_1.layers if isinstance(layer, napari.layers.Image)]\n",
    "    contrast_limits = {layer.name: layer.contrast_limits for layer in image_layers}\n",
    "    gamma_val = {layer.name: layer.gamma for layer in image_layers}\n",
    "    stain_complete_df.sort_index(inplace=True)\n",
    "    for c, idx in enumerate(stain_complete_df.index):\n",
    "        name = f\"{idx[0]} ({idx[1]})\"\n",
    "        stain_complete_df.loc[idx, 'Cont_min'] = int(contrast_limits[name][0])\n",
    "        stain_complete_df.loc[idx, 'Cont_max'] = int(contrast_limits[name][1])\n",
    "        stain_complete_df.loc[idx, 'Gamma'] = gamma_val[name]\n",
    "    if os.path.exists(setup_path):\n",
    "        stain_setup_df = pd.read_csv(setup_path)\n",
    "        stain_setup_df.set_index(['Condition', 'Marker', 'Laser'], inplace=True)\n",
    "        for idx in stain_complete_df.index:\n",
    "            stain_setup_df.loc[idx] = stain_complete_df.loc[idx]\n",
    "    else:\n",
    "        stain_setup_df = stain_complete_df.copy()\n",
    "    stain_csv_setup_df = stain_setup_df.reset_index().sort_values(by='Condition')\n",
    "    stain_csv_setup_df = stain_csv_setup_df[['Condition', 'Marker', 'Laser', 'Cont_min', 'Cont_max', 'Gamma']]\n",
    "    stain_csv_setup_df.to_csv(setup_path, index=False)\n",
    "\n",
    "stain_df = stain_df.set_index('Condition')\n",
    "stain_complete_df = stain_complete_df.reset_index().set_index('Condition')\n",
    "stain_complete_df = stain_complete_df.loc[stain_df.index]\n",
    "stain_complete_df = stain_complete_df[['Marker', 'Laser', 'Color', 'Cont_min', 'Cont_max', 'Gamma']]\n",
    "original_stain_complete_df=stain_complete_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c459fc7-429e-4592-b5eb-9cedb37c8fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display stain settings DataFrame\n",
    "stain_complete_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d61176-9e49-4c94-8f04-b4fa2a16219f",
   "metadata": {},
   "source": [
    "## IMAGE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b679eb17-77b9-4454-b807-e2a074f239d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and normalize image data for all channels\n",
    "im_in=im_final_stack['Original image'].copy()\n",
    "im_out=im_in.copy()\n",
    "for c in range(im_in.shape[3]):\n",
    "    im_ori = im_in[:, :, :, c].copy()\n",
    "    im_out[:, :, :, c] = ((im_ori - im_ori.min()) / (im_ori.max() - im_ori.min()) * 255).clip(0, 255).astype('uint8')\n",
    "\n",
    "im_final_stack['Normalized image']=im_out.copy()\n",
    "\n",
    "# Plot histogram for each channel\n",
    "hist_plot(im_final_stack['Normalized image'], stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1863a4-8080-41ed-bec3-1c0aa0a13686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt resolution to isotropic\n",
    "im_in=im_final_stack['Normalized image'].copy()\n",
    "\n",
    "im_out = np.zeros((round(np.shape(im_in)[0] * (zoom_factors[0])),round(np.shape(im_in)[1] * (zoom_factors[1])),round(np.shape(im_in)[2] * (zoom_factors[2])),np.shape(im_in)[3]))\n",
    "\n",
    "# Compute zoom factors to get isotropic spacing (same as Y and X)\n",
    "r_zX = meta.physical_pixel_sizes.X/zoom_factors[0]\n",
    "r_zY = meta.physical_pixel_sizes.Y/zoom_factors[1]\n",
    "r_zZ = meta.physical_pixel_sizes.Z/zoom_factors[2]\n",
    "\n",
    "# Resample image to isotropic spacing\n",
    "for c in range(im_in.shape[3]):\n",
    "    im_out[:, :, :, c] = zoom(im_in[:, :, :, c], zoom=zoom_factors, order=1)\n",
    "    im_out[:, :, :, c] = im_out[:, :, :, c] - np.min(im_out[:, :, :, c])\n",
    "\n",
    "    im_out[:, :, :, c] = ((im_out[:, :, :, c] - im_out[:, :, :, c].min()) / (im_out[:, :, :, c].max() - im_out[:, :, :, c].min()) * 255).clip(0, 255).astype('uint8')\n",
    "\n",
    "im_final_stack['Zoomed image']=im_out.copy()\n",
    "hist_plot(im_final_stack['Zoomed image'], stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92171d9e-4dde-4f95-ba32-07d8cd4940e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise removal using median filter\n",
    "im_in = im_final_stack['Zoomed image'].copy()\n",
    "for c in range(im_in.shape[3]):\n",
    "    im_out[:, :, :, c] = filters.median(im_in[:, :, :, c])\n",
    "im_final_stack['Denoised image'] = im_out.copy()\n",
    "hist_plot(im_final_stack['Denoised image'], stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1216ae01-cee5-4d8a-8e9b-14069a0fc92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrast and gamma adjustment for each channel\n",
    "im_in = im_final_stack['Denoised image'].copy()\n",
    "for c in range(im_in.shape[3]):\n",
    "    idx = stain_complete_df.index[c]\n",
    "    im_out[:, :, :, c] = napari_contrast_gamma_uint8(im_in[:, :, :, c], (stain_complete_df.loc[idx, 'Cont_min'], stain_complete_df.loc[idx, 'Cont_max']), stain_complete_df.loc[idx, 'Gamma'])\n",
    "    \n",
    "im_final_stack['Adjusted image'] = im_out.copy()\n",
    "hist_plot(im_final_stack['Adjusted image'], stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13246cee-6f45-4fd9-b95f-f9cc8df4865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian filter for smoothing\n",
    "im_in = im_final_stack['Adjusted image'].copy()\n",
    "for c in range(im_in.shape[3]):\n",
    "    im_out[:, :, :, c] = filters.gaussian(im_in[:, :, :, c], 0.5, preserve_range=True)\n",
    "\n",
    "im_final_stack['Filtered image'] = im_out.astype('uint8')\n",
    "hist_plot(im_final_stack['Filtered image'], stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3d119a-a4e3-41ad-8de5-b91c110d3300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export histograms\n",
    "output_path=Path(input_file).stem + '_histograms.xlsx'\n",
    "im_in = im_final_stack['Adjusted image'].copy()\n",
    "\n",
    "with pd.ExcelWriter(output_path, engine=\"xlsxwriter\") as writer:\n",
    "    for c in range(im_in.shape[3]):\n",
    "        # Example input: 3D array (e.g. image stack)\n",
    "        im3d = im_in[:, :, :, c].copy()\n",
    "\n",
    "        # Compute histogram\n",
    "        values, counts = np.unique(im3d.astype('int'), return_counts=True)\n",
    "        hist = np.zeros(256, dtype=int)\n",
    "        hist[values] = counts\n",
    "\n",
    "        # Calculate totals, percentages, and cumulative values\n",
    "        total = hist.sum()\n",
    "        percentage = (hist / total) * 100\n",
    "        cumulative = np.cumsum(hist)\n",
    "        cumulative_percentage = np.cumsum(percentage)\n",
    "\n",
    "        # Build DataFrame\n",
    "        df = pd.DataFrame({\n",
    "            \"Pixel_Value\": np.arange(256),\n",
    "            \"Count\": hist,\n",
    "            \"Percentage\": percentage,\n",
    "            \"Cumulative_Count\": cumulative,\n",
    "            \"Cumulative_Percentage\": cumulative_percentage\n",
    "        })\n",
    "\n",
    "        idx = stain_complete_df.index[c]\n",
    "        marker = stain_complete_df.loc[idx, 'Marker']\n",
    "\n",
    "        # Write each to a different sheet\n",
    "        df.to_excel(writer, sheet_name=marker, index=False)\n",
    "    \n",
    "print(f\"Saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389400c6-b361-4689-8140-72c48146e4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram equalization, supporting thresholding\n",
    "im_in = im_final_stack['Filtered image'].copy()\n",
    "for c in range(im_in.shape[3]):\n",
    "    im_out[:, :, :, c] = double_plateau_hist_equalization_nd(im_in[:, :, :, c].astype('uint8'), num_plateaus=2, plateau_factor=0.7)\n",
    "    im_ori = im_out[:, :, :, c].copy()\n",
    "    im_out[:, :, :, c] = ((im_ori - im_ori.min()) / (im_ori.max() - im_ori.min()) * 255).clip(0, 255).astype('uint8')\n",
    "\n",
    "im_final_stack['Equalized image'] = im_out.copy()\n",
    "hist_plot(im_final_stack['Equalized image'], stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258aaf4f-0507-4ab1-9fc6-e9d47c6d9fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding using Otsu, Sauvola, statistical background, gain filtering\n",
    "im_in = im_final_stack[\"Equalized image\"].copy()\n",
    "im_out = im_in.copy()\n",
    "\n",
    "# Sizes\n",
    "nuclei_size = int(nuclei_diameter / (np.mean([r_zX, r_zY])))\n",
    "cell_size = int(cell_diameter / (np.mean([r_zX, r_zY])))\n",
    "\n",
    "for c in range(im_in.shape[3]):\n",
    "    img = sitk.GetImageFromArray(im_in[:, :, :, c])\n",
    "\n",
    "    # Stretch for Otsu\n",
    "    rescaler = sitk.RescaleIntensityImageFilter()\n",
    "    rescaler.SetOutputMinimum(0)\n",
    "    rescaler.SetOutputMaximum(255)\n",
    "    stretched = rescaler.Execute(img)\n",
    "\n",
    "\n",
    "    # Otsu thresholds\n",
    "    th_filter = sitk.OtsuThresholdImageFilter()\n",
    "    _ = th_filter.Execute(stretched)\n",
    "    otsu_value = th_filter.GetThreshold()\n",
    "\n",
    "    _ = th_filter.Execute(img)\n",
    "    otsu_value2 = th_filter.GetThreshold()\n",
    "\n",
    "    if stain_complete_df.index[c] == \"NUCLEI\":\n",
    "        window_size = 1 * nuclei_size #+ 1\n",
    "    else:\n",
    "        window_size = 4 * cell_size + 1\n",
    "\n",
    "    # Convert to array\n",
    "    arr = sitk.GetArrayFromImage(img) #.astype(np.float32)\n",
    "\n",
    "    # Sauvola threshold map\n",
    "    sauvola_value = threshold_sauvola(arr, window_size=int(window_size))\n",
    "\n",
    "    # -------- GLOBAL statistical background, excluding zeros --------\n",
    "    non_zero = arr[arr > 0]\n",
    "\n",
    "    if non_zero.size > 0:\n",
    "        hist, bins = np.histogram(non_zero, bins=256, range=(0, non_zero.max()))\n",
    "        mode_bin = bins[np.argmax(hist)]\n",
    "        print(mode_bin)\n",
    "        bg_mask = (arr >= mode_bin - 5) & (arr <= mode_bin + 5) & (arr > 0) \n",
    "        gain_tot=6.0\n",
    "\n",
    "        gain_ass=gain_tot*(255.0-4.0*mode_bin)/255.0\n",
    "        bg_vals = arr[bg_mask]\n",
    "\n",
    "        if bg_vals.size < 50:\n",
    "            p10 = np.percentile(non_zero, 10)\n",
    "            bg_vals = non_zero[non_zero <= p10]\n",
    "    else:\n",
    "        bg_vals = arr\n",
    "\n",
    "    bg_mean = bg_vals.mean()\n",
    "    bg_std = bg_vals.std() + 1e-6\n",
    "\n",
    "    bg_mean_z = arr.mean()\n",
    "    bg_std_z = arr.std() + 1e-6\n",
    "    z = 3.0\n",
    "    statistical_thr = bg_mean_z + z * bg_std_z\n",
    "\n",
    "    # ---------------------------------------------------------------\n",
    "\n",
    "    # 1) Soften Sauvola if it is too aggressive for large/bright cells\n",
    "    # Clip Sauvola so it cannot exceed a few std above the global (zero‑including) mean\n",
    "    max_sauvola = bg_mean_z + 2.0 * bg_std_z\n",
    "    sauvola_clipped = np.minimum(sauvola_value, max_sauvola)\n",
    "\n",
    "    # Final combined threshold map (slightly less Sauvola weight)\n",
    "    final_thr = (\n",
    "        0.60 * sauvola_clipped +\n",
    "        0.25 * statistical_thr +\n",
    "        0.15 * otsu_value2\n",
    "    )\n",
    "\n",
    "    # Extra improvement: intensity gain check (global, using non-zero-based bg_mean)\n",
    "    gain = arr / (bg_mean + 1e-6)\n",
    "    mask_gain = gain > gain_ass    # tune 2–5 depending on SNR\n",
    "\n",
    "    # 2) Rescue pixels: strong gain but slightly under final_thr\n",
    "    primary = (arr > final_thr) & mask_gain\n",
    "    rescue = (gain > (gain_ass+3.0)) & (arr > statistical_thr)   # gain threshold > primary, to keep it conservative\n",
    "\n",
    "    arrayseg = primary | rescue\n",
    "\n",
    "    if stain_complete_df.index[c] != 'NUCLEI':\n",
    "        min_size = np.ceil(0.8 * np.pi * ((nuclei_size / 2) ** 2))\n",
    "    else:\n",
    "        min_size= np.ceil(0.4 * np.pi * ((nuclei_size / 2) ** 2))\n",
    "\n",
    "    # Remove small islands\n",
    "    \n",
    "    im_out[:, :, :, c] = remove_small_islands(arrayseg, min_size)\n",
    "\n",
    "im_final_stack[\"Threshold image\"] = im_out.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e22fad8-8e61-4701-be76-e79d6f67c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation of nuclei using watershed or StarDist\n",
    "from skimage.segmentation import relabel_sequential\n",
    "\n",
    "im_in=im_final_stack['Threshold image'].copy()\n",
    "\n",
    "if 'NUCLEI' in stain_df.index:\n",
    "   \n",
    "    for c in range(im_in.shape[3]):\n",
    "        if stain_complete_df.index[c] == 'NUCLEI':\n",
    "            if trig_stardist:\n",
    "                im_in=im_final_stack['Filtered image'].copy()\n",
    "                transl=stardist3d_from_2d(img_3d=im_in[:,:,:,c],nucleus_radius=nuclei_diameter/2.0,voxel_size=(r_zZ, r_zY, r_zX))\n",
    "                im_mask = transl>0\n",
    "                im_mask = morphology.binary_erosion(im_mask, footprint=np.ones((2, 2, 2))).astype(im_mask.dtype)\n",
    "                im_out,num = label((transl * im_mask)>0)\n",
    "            else:\n",
    "                binary_mask = im_in[:, :, :, c].copy()\n",
    "                _, true_markers = shrink_to_markers_robust(binary_mask)\n",
    "                distance = ndi.distance_transform_edt(binary_mask, sampling=[r_zZ, r_zY, r_zX])\n",
    "                im_out = watershed(-distance, true_markers, mask=binary_mask)\n",
    "                _,im_out = remove_small_island_labels(im_out, connectivity=1, size_ratio_thresh=0.5)\n",
    "                im_out, _, _ = relabel_sequential(im_out)\n",
    "else:\n",
    "    im_thresh = np.zeros_like(im_in[:,:,:,0], dtype=np.int32)\n",
    "    for c in range(im_in.shape[3]):\n",
    "        binary_mask = im_in[:, :, :, c].copy()\n",
    "        im_thresh = im_thresh | (binary_mask>0)\n",
    "\n",
    "        stain_complete_df.loc['NUCLEI']=['', '', '', '', '', '']\n",
    "        \n",
    "    im_out= skimage.measure.label(im_thresh)\n",
    "                \n",
    "im_segmentation_stack={'Nuclei': im_out, 'Cytoplasm': np.zeros_like(im_out), 'PCM': np.zeros_like(im_out)} \n",
    "\n",
    "cm_rand = np.random.rand(int(np.max(im_segmentation_stack['Nuclei'])), 3)\n",
    "cm_rand[0, :] = [0.0, 0.0, 0.0]\n",
    "colormaps_rand = Colormap(cm_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcc09a6-7acd-4e89-94ef-341b69728685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign segmented nuclei labels to other channels (cell assignment)\n",
    "im_in=im_final_stack['Threshold image'].copy()\n",
    "\n",
    "for c in range(im_in.shape[3]):\n",
    "    im_segmentation_stack[stain_df.index[c]] = im_in[:, :, :, c] * im_segmentation_stack['Nuclei']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435cff7e-fe98-48d5-b32a-bbe0fabd7929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize original, denoised, filtered, corrected, thresholded, assigned, and segmented images\n",
    "viewer_0 = napari.Viewer()\n",
    "scale_zoom=(r_zZ, r_zY, r_zX)\n",
    "\n",
    "for c in range(im_in.shape[3]):\n",
    "    idx = stain_complete_df.index[c]\n",
    "    marker = stain_complete_df.loc[idx, 'Marker']\n",
    "    color = stain_complete_df['Color'].iloc[c]\n",
    "    #viewer_0.add_image(im_final_stack['Normalized image'], name=f'NORMALIZED {idx} ({marker})', colormap=color, blending='additive')\n",
    "    viewer_0.add_image(im_final_stack['Original image'][:, :, :, c], name=f'ORIGINAL {idx} ({marker})', colormap=color, blending='additive', scale=[r_Z, r_Y, r_X])\n",
    "    viewer_0.add_image(im_final_stack['Zoomed image'][:, :, :, c], name=f'ZOOMED {idx} ({marker})', colormap=color, blending='additive', scale=scale_zoom)\n",
    "    viewer_0.add_image(im_final_stack['Denoised image'][:, :, :, c], name=f'DENOISED {idx} ({marker})', colormap=color, blending='additive', scale=scale_zoom)\n",
    "    viewer_0.add_image(im_final_stack['Adjusted image'][:, :, :, c], name=f'CORRECTED {idx} ({marker})', colormap=color, blending='additive', scale=scale_zoom)\n",
    "    viewer_0.add_image(im_final_stack['Filtered image'][:, :, :, c], name=f'FILTERED {idx} ({marker})', colormap=color, blending='additive', scale=scale_zoom)\n",
    "    viewer_0.add_image(im_final_stack['Equalized image'][:, :, :, c], name=f'EQ {idx} ({marker})', colormap=color, blending='additive', scale=scale_zoom)\n",
    "    viewer_0.add_image(im_final_stack['Threshold image'][:, :, :, c].astype('uint8'), name=f'THRESHOLD {idx} ({marker})', contrast_limits=[0, 1], colormap=color, blending='additive', scale=scale_zoom)    \n",
    "    \n",
    "viewer_0.add_labels(im_segmentation_stack['Nuclei'].astype('uint8'), name=f'NUCLEI', blending='additive', scale=scale_zoom) #, colormap=colormaps_rand, contrast_limits=[0, np.max(im_nuclei_segmented)], blending='additive')\n",
    "viewer_0.scale_bar.visible = True\n",
    "viewer_0.scale_bar.unit = 'um'\n",
    "\n",
    "if ('NUCLEI' in stain_complete_df.index)|('CYTOPLASM' in stain_complete_df.index):\n",
    "    viewer_1 = napari.Viewer()\n",
    "\n",
    "    im_in=im_final_stack['Threshold image'].copy()\n",
    "    \n",
    "    for c in range(len(stain_df.index)):\n",
    "        idx = stain_complete_df.index[c]\n",
    "        marker = stain_complete_df.loc[idx, 'Marker']\n",
    "        # viewer_1.add_labels(im_segmentation_stack['Nuclei'].astype('uint8'), name=f'{idx} ({marker})', blending='additive', scale=scale_zoom) #, colormap=colormaps_rand, contrast_limits=[0, np.max(im_nuclei_segmented)], blending='additive')\n",
    "        viewer_1.add_labels(im_segmentation_stack[stain_df.index[c]].astype('uint8'), name=f'{idx} ({marker})', blending='additive', scale=scale_zoom) #, colormap=colormaps_rand, contrast_limits=[0, np.max(im_nuclei_segmented)], blending='additive')\n",
    "    viewer_1.scale_bar.visible = True\n",
    "    viewer_1.scale_bar.unit = 'um'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aab820-7f42-4903-8132-d83edc9479d4",
   "metadata": {},
   "source": [
    "## QUANTIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e025d799-05f4-4b3a-adcd-3bec0a42eb5e",
   "metadata": {},
   "source": [
    "# 6. Quantification and Analysis\n",
    "\n",
    "This section quantifies nuclei and cell properties, computes statistics, and visualizes distributions. Results are exported for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3368afcc-5721-4785-82d8-c99433b3ac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {}\n",
    "#nuc_positions=np.zeros((1,np.max(im_segmentation_stack['Nuclei'])+1))[0]\n",
    "nuc_sizes=np.zeros((1,np.max(im_segmentation_stack['Nuclei'])+1))[0]\n",
    "nuc_position = [(0.0, 0.0, 0.0) for _ in range(np.max(im_segmentation_stack['Nuclei'])+1)]\n",
    "\n",
    "r_xyz = (r_zX, r_zY, r_zZ)\n",
    "zooms = zoom_factors\n",
    "\n",
    "for n in list(np.unique(im_segmentation_stack['Nuclei']))[1:]:\n",
    "    nuc_sizes[n]=np.sum(im_segmentation_stack['Nuclei']==n)*r_zX*r_zY*r_zZ\n",
    "    z,y,x = np.where(im_segmentation_stack['Nuclei']==n)\n",
    "    nuc_position[n]=(np.mean(x)*r_zX, np.mean(y)*r_zY, np.mean(z)*r_zZ)\n",
    "\n",
    "for c in range(len(stain_df.index)):\n",
    "    condition = stain_complete_df.index[c]\n",
    "    if condition in ['NUCLEI', 'CYTOPLASM', 'PCM']:\n",
    "        continue\n",
    "    marker = stain_complete_df.index[c]\n",
    "\n",
    "    shared_labels = list(np.unique(im_segmentation_stack[marker]).astype('int'))[1:]\n",
    "\n",
    "    labels_dict[marker] = [\n",
    "        condition,\n",
    "        stain_complete_df['Laser'][c],\n",
    "        stain_complete_df['Color'][c],\n",
    "        len(shared_labels),\n",
    "        tuple(sorted(shared_labels)),\n",
    "        tuple(nuc_position[int(i)] for i in shared_labels) if len(shared_labels)>0 else (),\n",
    "        tuple(nuc_sizes[int(i)] for i in shared_labels) if len(shared_labels)>0 else ()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc27794-fce2-4632-80a0-56de4ea09181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for quantification results and truncate long values for display\n",
    "labels_df = pd.DataFrame.from_dict(labels_dict, orient='index', columns=['Condition', 'Laser', 'Color', 'Number', 'Shared labels', 'Mean nuclei positions [um]', 'Nuclei size [um3]'])\n",
    "labels_df.index.name = 'Combination'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb236ce0-4e76-4b10-8bf4-47351900c693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display quantification DataFrame\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8333a47d-9919-4bfe-ae8b-41706aec1673",
   "metadata": {},
   "source": [
    "## Evaluate cell distribution in the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef35bbdd-693f-45c5-8654-fd6c387a19e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot spatial distribution of nuclei and cells\n",
    "im_in=im_final_stack['Filtered image']\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(15, 15))\n",
    "for i, marker in enumerate(labels_df.index):   \n",
    "    xcoor = [t[0] for t in labels_df['Mean nuclei positions [um]'][i]]\n",
    "    ycoor = [t[1] for t in labels_df['Mean nuclei positions [um]'][i]]\n",
    "    zcoor = [t[2] for t in labels_df['Mean nuclei positions [um]'][i]] \n",
    "    xcount, xbins = np.histogram(xcoor, range=(0, im_in.shape[2] * r_X /zoom_factors[2]), bins=30)\n",
    "    ycount, ybins = np.histogram(ycoor, range=(0, im_in.shape[1] * r_Y /zoom_factors[1]), bins=30)\n",
    "    zcount, zbins = np.histogram(zcoor, range=(0, im_in.shape[0] * r_Z /zoom_factors[0]), bins=30)\n",
    "    xbin_centers = (xbins[:-1] + xbins[1:]) / 2\n",
    "    ybin_centers = (ybins[:-1] + ybins[1:]) / 2\n",
    "    zbin_centers = (zbins[:-1] + zbins[1:]) / 2\n",
    "    if (np.size(marker)==1):\n",
    "        color = stain_complete_df.loc[str(labels_df['Condition'][i])]['Color']\n",
    "        if color == '':\n",
    "            color='BLUE'\n",
    "        if (labels_df['Condition'][i]!='NUCLEI'):\n",
    "            axs[0].plot(xbin_centers,xcount,label=str(labels_df['Condition'][i]),color=color)\n",
    "            axs[1].plot(ybin_centers,ycount,label=str(labels_df['Condition'][i]),color=color)\n",
    "            axs[2].plot(zbin_centers,zcount,label=str(labels_df['Condition'][i]),color=color)\n",
    "    else:\n",
    "        rgb_list=[]\n",
    "        for k in range(np.size(marker)):\n",
    "            if stain_df.loc[(labels_df['Condition'][i][k])]['Color']!='WHITE':\n",
    "                rgb_list.append(stain_complete_df.loc[(labels_df['Condition'][i][k])]['Color'])\n",
    "            else:\n",
    "                rgb_list.append('GRAY')\n",
    "\n",
    "        colors_rgb = [to_rgb(name) for name in rgb_list]\n",
    "\n",
    "        r_total, g_total, b_total = 0.0, 0.0, 0.0\n",
    "\n",
    "        for r, g, b in colors_rgb:\n",
    "            r_total += r\n",
    "            g_total += g\n",
    "            b_total += b\n",
    "        \n",
    "        r_final = min(r_total, 1.0)\n",
    "        g_final = min(g_total, 1.0)\n",
    "        b_final = min(b_total, 1.0)\n",
    "    \n",
    "        final_rgb = (r_final, g_final, b_final)\n",
    "        \n",
    "        axs[0].plot(xbin_centers,xcount,label=str(labels_df['Condition'][i]),linestyle=(0, (2, np.size(marker)-1)), color=final_rgb)\n",
    "        axs[1].plot(ybin_centers,ycount,label=str(labels_df['Condition'][i]),linestyle=(0, (2, np.size(marker)-1)), color=final_rgb)\n",
    "        axs[2].plot(zbin_centers,zcount,label=str(labels_df['Condition'][i]),linestyle=(0, (2, np.size(marker)-1)), color=final_rgb)\n",
    "        \n",
    "axs[0].set_title('NUCLEI X DISTRIBUTION')\n",
    "axs[0].set_xlabel('[μm]')\n",
    "axs[0].legend(loc='upper right')\n",
    "axs[0].set_facecolor('black')\n",
    "axs[1].set_title('NUCLEI Y DISTRIBUTION')\n",
    "axs[1].set_xlabel('[μm]')\n",
    "axs[1].legend(loc='upper right')\n",
    "axs[1].set_facecolor('black')\n",
    "axs[2].set_title('NUCLEI Z DISTRIBUTION')\n",
    "axs[2].set_xlabel('[μm]')\n",
    "axs[2].legend(loc='upper right')\n",
    "axs[2].set_facecolor('black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d02b15-c10b-4b95-8882-ff6769eadbdb",
   "metadata": {},
   "source": [
    "## Evaluate cell size distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a02a90b-0bb0-46f7-875d-e438714bc22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot size distribution of nuclei and cells\n",
    "nuclei_max_size = max(x for t in labels_df['Nuclei size [um3]'] for x in t)\n",
    "#cytoplasm_max_size = max(x for t in labels_df['Cytoplasm size [um3]'] for x in t)\n",
    "for i, marker in enumerate(labels_df.index):\n",
    "    nuclei_sizes = list(labels_df['Nuclei size [um3]'][i])\n",
    "    if np.size(marker)==1:\n",
    "        if stain_complete_df.loc[(labels_df['Condition'][i])]['Color']=='':\n",
    "            color = 'BLUE'\n",
    "        else:\n",
    "            if stain_complete_df.loc[(labels_df['Condition'][i])]['Color']!='WHITE':\n",
    "                color = stain_complete_df.loc[str(labels_df['Condition'][i])]['Color']\n",
    "            else:\n",
    "                color = 'GRAY'\n",
    "        #color = stain_df.loc[str(labels_df['Condition'][i])]['Color']\n",
    "        #axs[0].hist(nuclei_sizes, range=(0, nuclei_max_size), bins=30, label=str(labels_df['Condition'][i]), alpha=1/len(labels_df), color=color)\n",
    "    else:\n",
    "        rgb_list=[]\n",
    "        for k in range(np.size(marker)):\n",
    "            if stain_df.loc[(labels_df['Condition'][i][k])]['Color']!='WHITE':\n",
    "                rgb_list.append(stain_complete_df.loc[(labels_df['Condition'][i][k])]['Color'])\n",
    "            else:\n",
    "                rgb_list.append('GRAY')\n",
    "\n",
    "        colors_rgb = [to_rgb(name) for name in rgb_list]\n",
    "\n",
    "        r_total, g_total, b_total = 0.0, 0.0, 0.0\n",
    "\n",
    "        for r, g, b in colors_rgb:\n",
    "            r_total += r\n",
    "            g_total += g\n",
    "            b_total += b\n",
    "        \n",
    "        r_final = min(r_total, 1.0)\n",
    "        g_final = min(g_total, 1.0)\n",
    "        b_final = min(b_total, 1.0)\n",
    "    \n",
    "        color = (r_final, g_final, b_final)\n",
    "           \n",
    "    plt.hist(nuclei_sizes, range=(0, nuclei_max_size), bins=30, label=str(labels_df['Condition'][i]), alpha=1/len(labels_df), color=color)\n",
    "plt.title('NUCLEI SIZE DISTRIBUTION')\n",
    "plt.xlabel('[μm3]')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a070bde8-0355-4bec-a563-1f7740d942a2",
   "metadata": {},
   "source": [
    "### Create a complete report XSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c4282f-7756-4c49-8a50-fb7d69eb4ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export quantification results to Excel file\n",
    "with pd.ExcelWriter(Path(input_file).stem + '_segmentation.xlsx', engine='xlsxwriter') as writer:\n",
    "    original_stain_complete_df.to_excel(writer, sheet_name='Staining', index=True)\n",
    "    for i, marker in enumerate(labels_df.index):\n",
    "        xlsx_dict = {}\n",
    "        columns = ['ID', 'X position [um]', 'Y position [um]', 'Z position [um]', 'Nuclei size [um3]']\n",
    "        for j in range(len(list(labels_df['Shared labels'][marker]))):\n",
    "            row = [labels_df['Shared labels'][marker][j], labels_df['Mean nuclei positions [um]'][marker][j], labels_df['Nuclei size [um3]'][marker][j]]\n",
    "            row = [row[0], row[1][0], row[1][1], row[1][2], row[2]]\n",
    "            xlsx_dict[j] = row\n",
    "        xlsx_df = pd.DataFrame.from_dict(xlsx_dict, orient='index', columns=columns)\n",
    "        xlsx_df.to_excel(writer, sheet_name=marker, index=False)  \n",
    "    resume_df = labels_df.copy()\n",
    "    resume_df['Laser'] = [\n",
    "        labels_df['Laser'][t] if (np.size(labels_df['Condition'][t])==1) else ''\n",
    "        for t in range(len(labels_df))\n",
    "    ]\n",
    "    resume_df['Color'] = [\n",
    "        labels_df['Color'][t] if (np.size(labels_df['Condition'][t])==1) else ''\n",
    "        for t in range(len(labels_df))\n",
    "    ]\n",
    "    resume_df['%'] = [\n",
    "        100.0 * labels_df['Number'][t] / labels_df['Number'][0] if labels_df['Condition'][t] != 'NUCLEI' else ''\n",
    "        for t in range(len(labels_df))\n",
    "    ]\n",
    "    resume_df['Mean nuclei size [um3]'] = [np.mean(t) for t in labels_df['Nuclei size [um3]']]\n",
    "    resume_df.to_excel(writer, sheet_name='RECAP', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2bf51e-260b-4374-934c-24464188ef5d",
   "metadata": {},
   "source": [
    "# CREATE .inp FOR FINITE ELEMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0136c70d-e8e3-48be-a6fe-609ed4e4ae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleVolume = mrn.simpleVolumeFrom3Darray(np.float32(im_segmentation_stack['Nuclei']))\n",
    "floatGrid = mr.simpleVolumeToDenseGrid(simpleVolume)\n",
    "mesh_stl = mr.gridToMesh(floatGrid , mr.Vector3f(1.0,1.0,1.0), 0.5)\n",
    "\n",
    "outVerts = mrn.getNumpyVerts(mesh_stl)\n",
    "#print(outVerts)\n",
    "\n",
    "outFaces = mrn.getNumpyFaces(mesh_stl.topology)\n",
    "\n",
    "tet = tetgen.TetGen(outVerts,outFaces)\n",
    "nodes,elems=tet.tetrahedralize(order=1, mindihedral=20, minratio=1.5)\n",
    "\n",
    "tet.write('FE_segmentation_full.vtk', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1305c4d7-ade4-4f5e-b377-18ae57041db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "meshel = meshio.read('FE_segmentation_full.vtk')\n",
    "meshel.write('FE_segmentation.inp')\n",
    "\n",
    "for c in range(1, np.max(im_segmentation_stack['Nuclei'])+1):\n",
    "    globals()[str(c)+'cell_el']=[]\n",
    "\n",
    "for ce, x in enumerate(elems):\n",
    "    #print(np.shape(np.uint16(np.mean(nodes[x],0))))\n",
    "    coord=np.int16(np.round(np.mean(nodes[x],0),0))\n",
    "    step=0\n",
    "    taken=False\n",
    "    while not(taken):\n",
    "        step+=1\n",
    "        coord[coord<step]=1\n",
    "        for k in [0,1,2]:\n",
    "            if coord[k]>=np.shape(im_segmentation_stack['Nuclei'])[k]+1-step:coord[k]=np.shape(im_segmentation_stack['Nuclei'])[k]-1\n",
    "        elemlist=im_segmentation_stack['Nuclei'][coord[0]-step:coord[0]+1+step,coord[1]-step:coord[1]+1+step,coord[2]-step:coord[2]+1+step].flatten()\n",
    "        #print(elemlist)\n",
    "        if sum(elemlist)>0:\n",
    "            c_el=st.mode(elemlist[elemlist!=0])\n",
    "            taken=True\n",
    "\n",
    "    #print(c_el)\n",
    "    if c_el!=0:\n",
    "        globals()[str(c_el)+'cell_el'].append(ce+1)\n",
    "\n",
    "f = open(\"FE_segmentation.inp\", \"a\")\n",
    "for c in range(1,np.max(im_segmentation_stack['Nuclei'])+1):\n",
    "    f.write(\"*Elset, elset=cell\" + str(c) + \"\\n\")\n",
    "    j=1\n",
    "    for t in range(1, np.size(globals()[str(c)+'cell_el'])):\n",
    "        f.write(str(globals()[str(c)+'cell_el'][t]) + \",\")\n",
    "        j+=1\n",
    "        if j>16:\n",
    "            f.write(\"\\n\")\n",
    "            j=1\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2513300b-4e15-4b54-bea3-b60a737b3727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now insert *PART header manually\n",
    "with open(\"FE_segmentation.inp\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with open(Path(input_file).stem + \"_FEA.inp\", \"w\") as f:\n",
    "    for line in lines:\n",
    "        if (line==\"*NODE\\n\"):\n",
    "            f.write(\"*PART, name=Part-1\\n\")\n",
    "        f.write(line)\n",
    "    f.write(\"*END PART\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab0a4d-5051-4a2a-972b-7e3a1c3d8ece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
