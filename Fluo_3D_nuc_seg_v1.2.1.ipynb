{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af325be-1697-46f9-ad1f-39f2451d9614",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install aicsimageio[nd2]\n",
    "!pip install nd2reader\n",
    "!pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e1262a-3ccc-4c94-8f6e-8a5784ced14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check OpenCV version\n",
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61116848-a1b8-4dea-a7da-25a040cc7e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from pathlib import Path\n",
    "import napari\n",
    "from napari.settings import get_settings\n",
    "import pandas as pd\n",
    "import os\n",
    "import pyvista as pv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import skimage\n",
    "from scipy import ndimage as ndi\n",
    "from scipy.ndimage import label #, find_objects\n",
    "from skimage.segmentation import relabel_sequential\n",
    "from itertools import combinations\n",
    "from skimage import filters, morphology\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from vispy.color import Colormap\n",
    "from matplotlib.colors import to_rgb\n",
    "from csbdeep.utils import normalize\n",
    "from stardist.models import StarDist2D\n",
    "from collections import defaultdict\n",
    "from aicsimageio import AICSImage\n",
    "from nd2reader import ND2Reader\n",
    "from scipy.ndimage import zoom\n",
    "import meshlib.mrmeshpy as mr\n",
    "import meshlib.mrmeshnumpy as mrn\n",
    "from IPython.display import clear_output\n",
    "from scipy.ndimage import binary_dilation, generate_binary_structure\n",
    "import meshio\n",
    "import statistics as st\n",
    "import tetgen\n",
    "from skimage.morphology import ball\n",
    "from skimage.filters import threshold_otsu, threshold_niblack, threshold_sauvola\n",
    "import xlsxwriter\n",
    "\n",
    "# Enable interactive mode for napari in Jupyter\n",
    "settings = get_settings()\n",
    "settings.application.ipy_interactive = True\n",
    "\n",
    "import numpy as np\n",
    "from stardist.models import StarDist2D\n",
    "from csbdeep.utils import normalize\n",
    "#from skimage.measure import label\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.segmentation import watershed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388a39a6-25b4-497e-bfe1-5250ba3ad7bc",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b528e5d3-4be6-4c08-bd1a-521791c65756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image processing and utility functions\n",
    "\n",
    "def gamma_trans(im_in, gamma):\n",
    "    \"\"\"Apply gamma correction to an image.\"\"\"\n",
    "    val_c = 255.0 / (np.max(im_in)**gamma)\n",
    "    return (val_c * (im_in**gamma)).copy()\n",
    "\n",
    "def contr_limit(im_in, c_min=None, c_max=None):\n",
    "    \"\"\"\n",
    "    Stretch the contrast of the input image to the 0–255 range.\n",
    "    \n",
    "    Parameters:\n",
    "    - im_in: Input image (NumPy array).\n",
    "    - c_min: Minimum intensity to map to 0. If None, uses im_in.min().\n",
    "    - c_max: Maximum intensity to map to 255. If None, uses im_in.max().\n",
    "    \n",
    "    Returns:\n",
    "    - Contrast-stretched image (uint8).\n",
    "    \"\"\"\n",
    "    im_in = im_in.astype(float)\n",
    "    \n",
    "    if c_min is None:\n",
    "        c_min = im_in.min()\n",
    "    if c_max is None:\n",
    "        c_max = im_in.max()\n",
    "    \n",
    "    if c_max == c_min:\n",
    "        return np.zeros_like(im_in, dtype=np.uint8)  # avoid division by zero\n",
    "\n",
    "    alpha = 255.0 / (c_max - c_min)\n",
    "    beta = -c_min * alpha\n",
    "\n",
    "    im_out = alpha * im_in + beta\n",
    "    return np.clip(im_out, 0, 255).astype(np.uint8)\n",
    "\n",
    "def contr_stretch(im_in, c_min=None, c_max=None):\n",
    "    \"\"\"\n",
    "    Mimic Fiji's Brightness/Contrast adjustment.\n",
    "    Values below min_input become 0.\n",
    "    Values above max_input become 255.\n",
    "    Values in between are linearly scaled to 0–255.\n",
    "    \n",
    "    Parameters:\n",
    "    - im_in: Input image (NumPy array).\n",
    "    - min_input: Input value to be mapped to 0.\n",
    "    - max_input: Input value to be mapped to 255.\n",
    "    \n",
    "    Returns:\n",
    "    - Adjusted image (uint8).\n",
    "    \"\"\"\n",
    "    im_in = im_in.astype(float)\n",
    "\n",
    "    if c_min is None:\n",
    "        c_min = im_in.min()\n",
    "    if c_max is None:\n",
    "        c_max = im_in.max()\n",
    "    \n",
    "    if c_max == c_min:\n",
    "        return np.zeros_like(im_in, dtype=np.uint8)  # avoid division by zero\n",
    "\n",
    "    # Normalize: subtract min and divide by (max - min)\n",
    "    norm = (im_in - c_min) / (c_max - c_min)\n",
    "    \n",
    "    # Clip to [0, 1] so values outside range are fixed to 0 or 1\n",
    "    norm = np.clip(norm, 0, 1)\n",
    "    \n",
    "    return (norm * 255).astype(np.uint8)\n",
    "\n",
    "def hist_plot(im_in, stain_complete_df, thresh=0):\n",
    "    \"\"\"Plot histogram and CDF for each channel.\"\"\"\n",
    "    fig, axs = plt.subplots(1, im_in.shape[3], figsize=(15, 2))\n",
    "    for c in range(im_in.shape[3]):\n",
    "        hist, _ = np.histogram(im_in[:, :, :, c].flatten(), 256, [0, 256])\n",
    "        cdf = hist.cumsum()\n",
    "        cdf_normalized = cdf * hist.max() / cdf.max()\n",
    "        color = stain_complete_df.loc[stain_complete_df.index[c], 'Color']\n",
    "        axs[c].plot(cdf_normalized, color='b')\n",
    "        axs[c].hist(im_in[:, :, :, c].flatten(), 256, [0, 256], color=color if color != 'WHITE' else 'GRAY')\n",
    "        axs[c].set_xlim([0, 256])\n",
    "        axs[c].legend(('cdf', 'histogram'), loc='upper left')\n",
    "        if thresh > 0:\n",
    "            axs[c].plot([thresh, thresh], [0, cdf_normalized.max()], color='g')\n",
    "        axs[c].set_title(stain_complete_df.index[c])\n",
    "        axs[c].set_yscale('log')\n",
    "\n",
    "def truncate_cell(val, width=15):\n",
    "    \"\"\"Truncate long values for display in tables.\"\"\"\n",
    "    val_str = str(val)\n",
    "    return val_str if len(val_str) <= width else val_str[:width-3] + \"...\"\n",
    "\n",
    "def merge_touching_labels(label_matrix):\n",
    "    \"\"\"Merge touching labels in a 3D label matrix using union-find.\"\"\"\n",
    "    if label_matrix.max() == 0:\n",
    "        return label_matrix.copy()\n",
    "\n",
    "    padded = np.pad(label_matrix, 1, mode='constant', constant_values=0)\n",
    "    touching = defaultdict(set)\n",
    "\n",
    "    # Iterate over the inner volume (excluding padding)\n",
    "    for z in range(1, padded.shape[0] - 1):\n",
    "        for y in range(1, padded.shape[1] - 1):\n",
    "            for x in range(1, padded.shape[2] - 1):\n",
    "                center = padded[z, y, x]\n",
    "                if center == 0:\n",
    "                    continue\n",
    "                neighborhood = padded[z-1:z+2, y-1:y+2, x-1:x+2].ravel()\n",
    "                for neighbor in neighborhood:\n",
    "                    if neighbor != center and neighbor != 0:\n",
    "                        touching[center].add(neighbor)\n",
    "\n",
    "    # Union-Find to merge touching labels\n",
    "    all_labels = set(np.unique(label_matrix)) - {0}\n",
    "    parent = {label: label for label in all_labels}\n",
    "\n",
    "    def find(u):\n",
    "        while parent[u] != u:\n",
    "            parent[u] = parent[parent[u]]\n",
    "            u = parent[u]\n",
    "        return u\n",
    "\n",
    "    def union(u, v):\n",
    "        pu, pv = find(u), find(v)\n",
    "        if pu != pv:\n",
    "            parent[pu] = pv\n",
    "\n",
    "    for u, neighbors in touching.items():\n",
    "        for v in neighbors:\n",
    "            if u in parent and v in parent:\n",
    "                union(u, v)\n",
    "\n",
    "    label_map = {label: find(label) for label in all_labels}\n",
    "\n",
    "    # Apply merged labels\n",
    "    merged = np.zeros_like(label_matrix, dtype=np.int32)\n",
    "    for label, root in label_map.items():\n",
    "        merged[label_matrix == label] = root\n",
    "\n",
    "    # Re-label to get sequential labels starting from 1\n",
    "    merged, _, _ = relabel_sequential(merged)\n",
    "    return merged\n",
    "\n",
    "def remove_small_islands(binary_matrix, area_threshold):\n",
    "    \"\"\"Remove small connected components from a binary mask.\"\"\"\n",
    "    labeled_array, num_features = label(binary_matrix)\n",
    "    for i in range(1, num_features + 1):\n",
    "        component = (labeled_array == i)\n",
    "        if component.sum() < area_threshold:\n",
    "            binary_matrix[component] = 0\n",
    "    return binary_matrix\n",
    "\n",
    "def assign_labels(A, B, connectivity=1):\n",
    "    \"\"\"Assign labels from B to islands in A based on overlap (3D).\"\"\"\n",
    "    if connectivity == 2:\n",
    "        structure = np.ones((3, 3, 3))  # 26-connectivity\n",
    "    else:\n",
    "        structure = None  # default is 6-connectivity for 3D\n",
    "\n",
    "    labeled_A, num_features = label(A, structure=structure)\n",
    "    C = np.zeros_like(A, dtype=B.dtype)\n",
    "\n",
    "    for i in range(1, num_features + 1):\n",
    "        mask = labeled_A == i\n",
    "        overlapping_labels = np.unique(B[mask & (B > 0)])\n",
    "        C[mask] = overlapping_labels[0] if len(overlapping_labels) > 0 else 0\n",
    "\n",
    "    return C\n",
    "\n",
    "def grow_labels(label_matrix,volume_factor=5.0):\n",
    "    structure = ball(volume_factor) #generate_binary_structure(3, 1)  # 6-connectivity in 3D\n",
    "    output = label_matrix.copy()\n",
    "    \n",
    "    labels = np.unique(label_matrix)\n",
    "    labels = labels[labels != 0]  # exclude background\n",
    "\n",
    "    # Compute original volumes\n",
    "    volumes = {label: np.sum(label_matrix == label) for label in labels}\n",
    "    target_volumes = {label: volume_factor * vol for label, vol in volumes.items()}\n",
    "\n",
    "    # Create masks for each label\n",
    "    label_masks = {label: (label_matrix == label) for label in labels}\n",
    "    grown_masks = label_masks.copy()\n",
    "\n",
    "    # Initialize growing flags\n",
    "    growing = {label: True for label in labels}\n",
    "\n",
    "    # Start growing iterations\n",
    "    while any(growing.values()):\n",
    "        new_masks = {}\n",
    "        occupied = np.zeros_like(label_matrix, dtype=bool)\n",
    "\n",
    "        # Prepare current occupied space\n",
    "        for label, mask in grown_masks.items():\n",
    "            occupied |= mask\n",
    "\n",
    "        for label in labels:\n",
    "            if not growing[label]:\n",
    "                continue\n",
    "            # Grow\n",
    "            dilated = binary_dilation(grown_masks[label], structure)\n",
    "            # Only grow into free space\n",
    "            new_mask = dilated & ~occupied\n",
    "            combined = grown_masks[label] | new_mask\n",
    "            if np.sum(combined) >= target_volumes[label]:\n",
    "                growing[label] = False\n",
    "            grown_masks[label] = combined\n",
    "            new_masks[label] = combined\n",
    "\n",
    "        # Update output matrix\n",
    "        output[:] = 0\n",
    "        for label, mask in grown_masks.items():\n",
    "            output[mask] = label\n",
    "\n",
    "    return output\n",
    "\n",
    "def stardist3d_from_2d(\n",
    "    img_3d,\n",
    "    model_name=\"2D_versatile_fluo\",\n",
    "    nucleus_radius=5,\n",
    "    voxel_size=(1.0, 0.5, 0.5),\n",
    "    norm=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Apply StarDist2D slice-by-slice to a 3D stack, merge predictions,\n",
    "    and split weakly connected nuclei using distance-based watershed.\n",
    "    Handles anisotropic voxel spacing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_3d : np.ndarray\n",
    "        Input 3D grayscale image, shape (Z, Y, X).\n",
    "    model_name : str\n",
    "        Name of pretrained StarDist2D model.\n",
    "    nucleus_radius : float\n",
    "        Approximate radius of nuclei in pixels (XY units).\n",
    "    voxel_size : tuple(float)\n",
    "        Physical voxel size as (z_spacing, y_spacing, x_spacing).\n",
    "    norm : bool\n",
    "        Normalize each 2D slice before prediction.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    labels_split : np.ndarray\n",
    "        3D labeled array (int32), same shape as input.\n",
    "    \"\"\"\n",
    "\n",
    "    assert img_3d.ndim == 3, \"Input must be 3D (Z, Y, X)\"\n",
    "    z_spacing, y_spacing, x_spacing = voxel_size\n",
    "\n",
    "    print(f\"Running StarDist2D on {img_3d.shape[0]} z-slices...\")\n",
    "    model = StarDist2D.from_pretrained(model_name)\n",
    "\n",
    "    labels_3d = np.zeros_like(img_3d, dtype=np.int32)\n",
    "    current_label = 1\n",
    "\n",
    "    for z in range(img_3d.shape[0]):\n",
    "        img = img_3d[z]\n",
    "        if norm:\n",
    "            img = normalize(img, 1, 99.8, axis=None)\n",
    "\n",
    "        labels2d, _ = model.predict_instances(img)\n",
    "        labels2d = np.where(labels2d > 0, labels2d + current_label, 0)\n",
    "        labels_3d[z] = labels2d\n",
    "        current_label = labels2d.max() + 1\n",
    "\n",
    "    # Merge touching objects in 3D\n",
    "    labels_3d = skimage.measure.label(labels_3d > 0, connectivity=1)\n",
    "\n",
    "    # --- Anisotropic distance-based splitting ---\n",
    "    print(\"Computing distance transform with anisotropic voxel spacing...\")\n",
    "    distance = ndi.distance_transform_edt(labels_3d > 0, sampling=voxel_size)\n",
    "\n",
    "    # Estimate local maxima using nucleus_radius as search distance in XY\n",
    "    footprint = np.ones(\n",
    "        (\n",
    "            max(1, int(z_spacing / y_spacing)),  # thin in z\n",
    "            int(nucleus_radius),\n",
    "            int(nucleus_radius),\n",
    "        ),\n",
    "        dtype=bool,\n",
    "    )\n",
    "\n",
    "    local_max = peak_local_max(\n",
    "        distance,\n",
    "        footprint=footprint,\n",
    "        labels=labels_3d > 0,\n",
    "        exclude_border=False,\n",
    "    )\n",
    "\n",
    "    # Create markers for watershed\n",
    "    markers = np.zeros_like(labels_3d, dtype=int)\n",
    "    for i, coord in enumerate(local_max, start=1):\n",
    "        markers[tuple(coord)] = i\n",
    "\n",
    "    # Watershed segmentation\n",
    "    print(\"Running 3D watershed to split connected nuclei...\")\n",
    "    labels_split = watershed(-distance, markers, mask=labels_3d > 0)\n",
    "\n",
    "    print(f\"Done. Found {labels_split.max()} nuclei.\")\n",
    "    return labels_split\n",
    "\n",
    "\n",
    "# def stardist3d_from_2d(model_name='2D_versatile_fluo', img_3d=None, norm=True):\n",
    "#     \"\"\"\n",
    "#     Apply StarDist2D slice-by-slice to a 3D image stack and merge results.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     model_name : str\n",
    "#         Name of pretrained StarDist2D model (e.g. '2D_versatile_fluo').\n",
    "#     img_3d : np.ndarray\n",
    "#         Input 3D image of shape (Z, Y, X).\n",
    "#     norm : bool\n",
    "#         Whether to normalize each slice individually.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     labels_3d : np.ndarray\n",
    "#         3D labeled array of the same shape as img_3d.\n",
    "#     \"\"\"\n",
    "\n",
    "#     assert img_3d.ndim == 3, \"Input must be a 3D array (Z, Y, X).\"\n",
    "\n",
    "#     # Load pretrained 2D model\n",
    "#     model = StarDist2D.from_pretrained(model_name)\n",
    "\n",
    "#     labels_3d = np.zeros_like(img_3d, dtype=np.int32)\n",
    "#     current_label = 1\n",
    "\n",
    "#     for z in range(img_3d.shape[0]):\n",
    "#         img = img_3d[z]\n",
    "\n",
    "#         if norm:\n",
    "#             img = normalize(img, 1.0, 99.8, axis=None)\n",
    "\n",
    "#         # Predict 2D nuclei\n",
    "#         labels2d, _ = model.predict_instances(img)\n",
    "\n",
    "#         # Re-label so all IDs are unique across z\n",
    "#         labels2d = np.where(labels2d > 0, labels2d + current_label, 0)\n",
    "#         labels_3d[z] = labels2d\n",
    "#         current_label = labels2d.max() + 1\n",
    "\n",
    "#     # Optionally merge across z slices using 3D connectivity\n",
    "#     labels_3d = skimage.measure.label(labels_3d > 0, connectivity=1)\n",
    "\n",
    "#     return labels_3d\n",
    "\n",
    "def make_anisotropic_footprint(radius_Z, radius_Y, radius_X):\n",
    "    zz, yy, xx = np.ogrid[\n",
    "        -radius_Z:radius_Z+1,\n",
    "        -radius_Y:radius_Y+1,\n",
    "        -radius_X:radius_X+1\n",
    "    ]\n",
    "    ellipsoid = ((zz / radius_Z)**2 + (yy / radius_Y)**2 + (xx / radius_X)**2) <= 1\n",
    "    return ellipsoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f9ed9d-96d7-4068-9b7c-f2ec17a58aa4",
   "metadata": {},
   "source": [
    "# INPUTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7688f7-5b17-498f-86b8-90e4a13226f3",
   "metadata": {},
   "source": [
    "### File upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41837bd-55ba-4b37-affd-bc756542813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TIFF file and extract image data\n",
    "input_file = 'AGG_COLIV-INTEGRIN-CUBES_.nd2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fabebf-7945-48e6-97a8-7683caed6219",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = AICSImage(input_file)\n",
    "img = meta.get_image_data(\"XYZ\", T=0) \n",
    "print(img.shape)\n",
    "\n",
    "# Get physical pixel sizes\n",
    "r_X = meta.physical_pixel_sizes.X #um/px\n",
    "r_Y = meta.physical_pixel_sizes.Y #um/px\n",
    "r_Z = meta.physical_pixel_sizes.Z #um/px\n",
    "print([r_X, r_Y, r_Z])\n",
    "\n",
    "imdata=meta.get_image_data()\n",
    "imtype=imdata.dtype\n",
    "bdepth=imtype.itemsize*8\n",
    "print(imtype)\n",
    "\n",
    "with ND2Reader(input_file) as nd2:\n",
    "    print(\"Date:\", nd2.metadata.get(\"date\"))\n",
    "    print(\"Channels:\", nd2.metadata.get(\"channels\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e47b986-7d7b-4a57-a8ed-0473e4601c40",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c105211-8565-4b07-8add-dec175f71881",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei_diameter=10 #um\n",
    "cell_diameter=30 #um\n",
    "\n",
    "cyto_factor=3.0\n",
    "PCM_factor=4.0\n",
    "\n",
    "stain_dict = {\n",
    "    'NUCLEI': ['DAPI', 'DAPI', 'Blue'],\n",
    "    'MACRO': ['F4_80', 'AF488', 'Green'],\n",
    "    'M1': ['CD80', 'AF555', 'Red'],\n",
    "    'M2': ['CD206', 'AF647', 'White']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4afa3b-4101-4f6a-9632-11933a75c444",
   "metadata": {},
   "source": [
    "### Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b103b005-2497-4954-a829-2884c6bff02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = [0,1000,0,1000,0,50] #XYZ - put 0 to keep the original value\n",
    "\n",
    "scale_factor=0.5\n",
    "zoom_factors = [1.0, 1.0, 1.0] #XYZ\n",
    "zoom_factors = [x * scale_factor for x in zoom_factors]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957d1a10-4f9e-41ca-9785-ca2bae4302fd",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee8fc80-6be8-4ba6-b29f-f630c2648295",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_setup = 'AUSE_CHIP'\n",
    "use_setup = True\n",
    "trig_stardist = False  # Set to True to use StarDist model\n",
    "multilabel=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fa8737-3bbf-4ad5-a5af-5e4d20ffb197",
   "metadata": {},
   "source": [
    "## INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2fa518-bb33-4a94-92c0-9a9e932f8c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei_radius=nuclei_diameter*0.5*scale_factor #um\n",
    "cell_radius=cell_diameter*0.5*scale_factor #um\n",
    "\n",
    "nuclei_volume=np.ceil(4.0*((nuclei_radius)**3.0)*np.pi/3.0) #um^3\n",
    "cell_volume=np.ceil(4.0*((cell_radius)**3.0)*np.pi/3.0) #um^3\n",
    "\n",
    "x0, x1, y0, y1, z0, z1 = ROI\n",
    "\n",
    "if x1==0:\n",
    "    x1 = img.shape[0]\n",
    "if y1==0:\n",
    "    y1 = img.shape[1]\n",
    "if z1==0:\n",
    "    z1 = img.shape[2]\n",
    "\n",
    "im_original = meta.get_image_data(\"ZYXC\", S=0, T=0).astype('float32')\n",
    "im_original_ROI = im_original[z0:z1,y0:y1,x0:x1,:]\n",
    "im_final_stack={'Original image': im_original_ROI}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24701d78-90c0-4df3-a9ac-0f9098776dc0",
   "metadata": {},
   "source": [
    "### Information about the staining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157d0505-c5fb-4b93-b130-254add588d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define staining dictionary and create DataFrame\n",
    "stain_dict = {k.upper(): [item.upper() if isinstance(item, str) else item for item in v] for k, v in stain_dict.items()}\n",
    "stain_df = pd.DataFrame.from_dict(stain_dict, orient='index', columns=['Marker', 'Laser', 'Color'])\n",
    "laser_order=nd2.metadata.get(\"channels\")\n",
    "\n",
    "# Map fluorophore to its order index\n",
    "order_map = {name.strip().upper(): i for i, name in enumerate(laser_order)}\n",
    "stain_df['order'] = stain_df['Laser'].map(order_map)\n",
    "\n",
    "# Sort by that and drop helper column\n",
    "stain_df = stain_df.sort_values('order').drop(columns='order')\n",
    "\n",
    "stain_df.index.name = 'Condition'\n",
    "\n",
    "if 'NUCLEI' not in stain_df.index:\n",
    "    print('No nuclei condition!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32d257a-9efb-44c3-8228-2be4978e9c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize each channel using napari\n",
    "im_in=im_final_stack['Original image'].copy()\n",
    "\n",
    "viewer_0 = napari.Viewer()\n",
    "for c, c_name in enumerate(stain_df['Marker']):\n",
    "    #im_in = meta.get_image_data(\"ZYX\", C=c, S=0, T=0).astype('float32')\n",
    "    im_channel = im_in[:,:,:,c]\n",
    "\n",
    "    # Stretch to [0, 255]\n",
    "    im_8b = ((im_channel - im_channel.min()) / (im_channel.max() - im_channel.min()) * 255).clip(0, 255).astype('uint8')\n",
    "    \n",
    "    viewer_0.add_image(im_8b, name=f\"{stain_df.index[c]} ({c_name})\", \n",
    "                        colormap=stain_df['Color'][c], blending='additive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d63bd45-32c7-45be-8c8e-d1644df8e94c",
   "metadata": {},
   "source": [
    "### Acquisition processing setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a2d9c9-3a3b-4f03-ab0d-85d806558cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for acquisition and contrast/gamma settings\n",
    "im_in=im_final_stack['Original image'].copy()\n",
    "\n",
    "stain_df = stain_df.reset_index(drop=False)\n",
    "stain_initial_df = stain_df.copy()\n",
    "stain_initial_df.set_index(['Condition', 'Marker', 'Laser'], inplace=True)\n",
    "stain_initial_df[['Cont_min', 'Cont_max', 'Gamma']] = [0, 255, 1]\n",
    "stain_complete_df=stain_initial_df.copy()\n",
    "\n",
    "setup_path = f\"{name_setup}_setup.csv\"\n",
    "if use_setup and os.path.exists(setup_path):\n",
    "    stain_setup_df = pd.read_csv(setup_path)\n",
    "    stain_setup_df.set_index(['Condition', 'Marker', 'Laser'], inplace=True)\n",
    "    for idx in stain_complete_df.index:\n",
    "        if idx in stain_setup_df.index:\n",
    "            stain_complete_df.loc[idx] = stain_setup_df.loc[idx]\n",
    "            stain_complete_df['Color'] = stain_initial_df['Color']\n",
    "        else:\n",
    "            use_setup = False\n",
    "\n",
    "if not use_setup or not os.path.exists(setup_path):\n",
    "    stain_complete_df=stain_initial_df.copy()\n",
    "    settings.application.ipy_interactive = False\n",
    "    viewer_1 = napari.Viewer()\n",
    "    for c, idx in enumerate(stain_complete_df.index):\n",
    "        im_channel = im_in[:,:,:,c]\n",
    "        im_channel = ((im_channel - im_channel.min()) / (im_channel.max() - im_channel.min()) * 255).clip(0, 255).astype('uint8')\n",
    "        viewer_1.add_image(im_channel, name=f\"{idx[0]} ({idx[1]})\", colormap=stain_initial_df.loc[idx]['Color'], blending='additive')\n",
    "    napari.run()\n",
    "    image_layers = [layer for layer in viewer_1.layers if isinstance(layer, napari.layers.Image)]\n",
    "    contrast_limits = {layer.name: layer.contrast_limits for layer in image_layers}\n",
    "    gamma_val = {layer.name: layer.gamma for layer in image_layers}\n",
    "    stain_complete_df.sort_index(inplace=True)\n",
    "    for c, idx in enumerate(stain_complete_df.index):\n",
    "        name = f\"{idx[0]} ({idx[1]})\"\n",
    "        stain_complete_df.loc[idx, 'Cont_min'] = int(contrast_limits[name][0])\n",
    "        stain_complete_df.loc[idx, 'Cont_max'] = int(contrast_limits[name][1])\n",
    "        stain_complete_df.loc[idx, 'Gamma'] = gamma_val[name]\n",
    "    if os.path.exists(setup_path):\n",
    "        stain_setup_df = pd.read_csv(setup_path)\n",
    "        stain_setup_df.set_index(['Condition', 'Marker', 'Laser'], inplace=True)\n",
    "        for idx in stain_complete_df.index:\n",
    "            stain_setup_df.loc[idx] = stain_complete_df.loc[idx]\n",
    "    else:\n",
    "        stain_setup_df = stain_complete_df.copy()\n",
    "    stain_csv_setup_df = stain_setup_df.reset_index().sort_values(by='Condition')\n",
    "    stain_csv_setup_df = stain_csv_setup_df[['Condition', 'Marker', 'Laser', 'Cont_min', 'Cont_max', 'Gamma']]\n",
    "    stain_csv_setup_df.to_csv(setup_path, index=False)\n",
    "\n",
    "stain_df = stain_df.set_index('Condition')\n",
    "stain_complete_df = stain_complete_df.reset_index().set_index('Condition')\n",
    "stain_complete_df = stain_complete_df.loc[stain_df.index]\n",
    "stain_complete_df = stain_complete_df[['Marker', 'Laser', 'Color', 'Cont_min', 'Cont_max', 'Gamma']]\n",
    "original_stain_complete_df=stain_complete_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c459fc7-429e-4592-b5eb-9cedb37c8fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display stain settings DataFrame\n",
    "stain_complete_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d61176-9e49-4c94-8f04-b4fa2a16219f",
   "metadata": {},
   "source": [
    "## IMAGE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b679eb17-77b9-4454-b807-e2a074f239d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and normalize image data for all channels\n",
    "im_in=im_final_stack['Original image'].copy()\n",
    "im_out = ((im_in - im_in.min()) / (im_in.max() - im_in.min()) * 255).clip(0, 255).astype('uint8')\n",
    "im_final_stack['Normalized image']=im_out.copy()\n",
    "\n",
    "# Plot histogram for each channel\n",
    "hist_plot(im_final_stack['Normalized image'], stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1863a4-8080-41ed-bec3-1c0aa0a13686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt resolution to isotropic\n",
    "im_in=im_final_stack['Normalized image'].copy()\n",
    "\n",
    "im_out = np.zeros((round(np.shape(im_in)[0] * (zoom_factors[0])),round(np.shape(im_in)[1] * (zoom_factors[1])),round(np.shape(im_in)[2] * (zoom_factors[2])),np.shape(im_in)[3]))\n",
    "\n",
    "# Compute zoom factors to get isotropic spacing (same as Y and X)\n",
    "\n",
    "# Resample image to isotropic spacing\n",
    "for c in range(im_in.shape[3]):\n",
    "    im_out[:, :, :, c] = zoom(im_in[:, :, :, c], zoom=zoom_factors, order=1)\n",
    "\n",
    "im_final_stack['Zoomed image']=im_out.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92171d9e-4dde-4f95-ba32-07d8cd4940e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise removal using median filter\n",
    "im_in = im_final_stack['Zoomed image'].copy()\n",
    "for c in range(im_in.shape[3]):\n",
    "    im_out[:, :, :, c] = filters.median(im_in[:, :, :, c])\n",
    "im_final_stack['Denoised image'] = im_out.copy()\n",
    "hist_plot(im_final_stack['Denoised image'], stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1216ae01-cee5-4d8a-8e9b-14069a0fc92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrast and gamma adjustment for each channel\n",
    "im_in = im_final_stack['Denoised image'].copy()\n",
    "for c, idx in enumerate(stain_complete_df.index):\n",
    "    im_out[:, :, :, c] = contr_stretch(im_in[:, :, :, c], stain_complete_df.loc[idx, 'Cont_min'], stain_complete_df.loc[idx, 'Cont_max'])\n",
    "    im_out[:, :, :, c] = gamma_trans(im_in[:, :, :, c], stain_complete_df.loc[idx, 'Gamma'])\n",
    "im_final_stack['Adjusted image'] = im_out.copy()\n",
    "hist_plot(im_final_stack['Adjusted image'], stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2464bd2-a092-4e4b-a903-a76f22969c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian filter for smoothing\n",
    "im_in = im_final_stack['Adjusted image'].copy()\n",
    "for c in range(im_in.shape[3]):\n",
    "    im_out[:, :, :, c] = filters.gaussian(im_in[:, :, :, c], 0.5, preserve_range=True)\n",
    "im_final_stack['Filtered image'] = im_out.copy()\n",
    "hist_plot(im_final_stack['Filtered image'], stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3d119a-a4e3-41ad-8de5-b91c110d3300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export histograms\n",
    "output_path=Path(input_file).stem + '_histograms.xlsx'\n",
    "im_in = im_final_stack['Filtered image'].copy()\n",
    "\n",
    "with pd.ExcelWriter(output_path, engine=\"xlsxwriter\") as writer:\n",
    "    for c in range(im_in.shape[3]):\n",
    "        # Example input: 3D array (e.g. image stack)\n",
    "        im3d = im_in[:, :, :, c].copy()\n",
    "\n",
    "        # Compute histogram\n",
    "        values, counts = np.unique(im3d.astype('int'), return_counts=True)\n",
    "        hist = np.zeros(256, dtype=int)\n",
    "        hist[values] = counts\n",
    "\n",
    "        # Calculate totals, percentages, and cumulative values\n",
    "        total = hist.sum()\n",
    "        percentage = (hist / total) * 100\n",
    "        cumulative = np.cumsum(hist)\n",
    "        cumulative_percentage = np.cumsum(percentage)\n",
    "\n",
    "        # Build DataFrame\n",
    "        df = pd.DataFrame({\n",
    "            \"Pixel_Value\": np.arange(256),\n",
    "            \"Count\": hist,\n",
    "            \"Percentage\": percentage,\n",
    "            \"Cumulative_Count\": cumulative,\n",
    "            \"Cumulative_Percentage\": cumulative_percentage\n",
    "        })\n",
    "\n",
    "        idx = stain_complete_df.index[c]\n",
    "        marker = stain_complete_df.loc[idx, 'Marker']\n",
    "\n",
    "        # Write each to a different sheet\n",
    "        df.to_excel(writer, sheet_name=marker, index=False)\n",
    "    \n",
    "print(f\"Saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b7708-b305-4442-82d8-56378f7e31ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding using Otsu, Sauvola, statistical background, gain filtering\n",
    "im_in = im_final_stack[\"Filtered image\"].copy()\n",
    "im_out = im_in.copy()\n",
    "\n",
    "for c in range(im_in.shape[3]):\n",
    "    img = sitk.GetImageFromArray(im_in[:, :, :, c])\n",
    "\n",
    "    # Stretch for Otsu\n",
    "    rescaler = sitk.RescaleIntensityImageFilter()\n",
    "    rescaler.SetOutputMinimum(0)\n",
    "    rescaler.SetOutputMaximum(255)\n",
    "    stretched = rescaler.Execute(img)\n",
    "\n",
    "    # Otsu thresholds\n",
    "    th_filter = sitk.OtsuThresholdImageFilter()\n",
    "    _ = th_filter.Execute(stretched)\n",
    "    otsu_value = th_filter.GetThreshold()\n",
    "\n",
    "    _ = th_filter.Execute(img)\n",
    "    otsu_value2 = th_filter.GetThreshold()\n",
    "\n",
    "    # Sizes\n",
    "    nuclei_size = int(nuclei_diameter * scale_factor / (np.mean([r_X, r_Y])))\n",
    "    cell_size = int(cell_diameter * scale_factor / (np.mean([r_X, r_Y])))\n",
    "\n",
    "    if stain_complete_df.index[c] == \"NUCLEI\":\n",
    "        window_size = 4 * nuclei_size + 1\n",
    "    else:\n",
    "        window_size = 4 * cell_size + 1\n",
    "\n",
    "    # Convert to array\n",
    "    arr = sitk.GetArrayFromImage(img).astype(np.float32)\n",
    "\n",
    "    # Sauvola threshold map\n",
    "    sauvola_value = threshold_sauvola(arr, window_size=int(window_size))\n",
    "\n",
    "    # Statistical background threshold\n",
    "    hist, bins = np.histogram(arr, bins=256, range=(0, arr.max()))\n",
    "    mode_bin = bins[np.argmax(hist)]\n",
    "\n",
    "    bg_mask = (arr >= mode_bin - 5) & (arr <= mode_bin + 5)\n",
    "    bg_vals = arr[bg_mask]\n",
    "    if bg_vals.size < 50:\n",
    "        bg_vals = arr\n",
    "\n",
    "    bg_mean = bg_vals.mean()\n",
    "    bg_std = bg_vals.std() + 1e-6\n",
    "    z = 3.0\n",
    "    statistical_thr = bg_mean + z * bg_std\n",
    "\n",
    "    # Final combined threshold map\n",
    "    final_thr = (\n",
    "        0.60 * sauvola_value +\n",
    "        0.25 * statistical_thr +\n",
    "        0.15 * otsu_value2\n",
    "    )\n",
    "\n",
    "    # Extra improvement: intensity gain check\n",
    "    # Only keep pixels that rise at least X times above background mean\n",
    "    gain = arr / (bg_mean + 1e-6)\n",
    "    mask_gain = gain > 2.0    # adjust if needed\n",
    "\n",
    "    # Apply threshold\n",
    "    arrayseg = (arr > final_thr) & mask_gain\n",
    "\n",
    "    # Remove small islands\n",
    "    min_size = np.ceil(0.8 * np.pi * ((nuclei_size / 2) ** 2))\n",
    "    im_out[:, :, :, c] = remove_small_islands(arrayseg, min_size)\n",
    "\n",
    "im_final_stack[\"Threshold image\"] = im_out.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e22fad8-8e61-4701-be76-e79d6f67c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation of nuclei using watershed or StarDist\n",
    "if 'NUCLEI' in stain_df.index:\n",
    "    im_in=im_final_stack['Threshold image'].copy()\n",
    "    \n",
    "    for c in range(im_in.shape[3]):\n",
    "        if stain_complete_df.index[c] == 'NUCLEI':\n",
    "            if trig_stardist:\n",
    "                im_in=im_final_stack['Filtered image'].copy()\n",
    "                transl=stardist3d_from_2d(img_3d=im_in[:,:,:,c],nucleus_radius=nuclei_diameter*scale_factor/2.0,voxel_size=(r_Z, r_Y, r_X))\n",
    "                im_mask = transl>0\n",
    "                im_mask = morphology.binary_erosion(im_mask, footprint=np.ones((2, 2, 2))).astype(im_mask.dtype)\n",
    "                im_out,num = label((transl * im_mask)>0)\n",
    "            else:\n",
    "                distance = ndi.distance_transform_edt(im_in[:, :, :, c],sampling=[r_Z,r_Y,r_X])\n",
    "                radius_X = int((nuclei_diameter / 2) *scale_factor/ r_X)\n",
    "                radius_Y = int((nuclei_diameter / 2) *scale_factor/ r_Y)\n",
    "                radius_Z = int((nuclei_diameter / 2) *scale_factor/ r_Z)\n",
    "                coords = peak_local_max(distance, footprint=make_anisotropic_footprint(radius_Z, radius_Y, radius_X), labels=im_in[:, :, :, c].astype(np.int32))\n",
    "                mask = np.zeros(distance.shape, dtype=bool)\n",
    "                mask[tuple(coords.T)] = True\n",
    "                markers, _ = label(mask)\n",
    "                im_out = watershed(-distance, markers, mask=im_in[:, :, :, c])\n",
    "                #im_out = merge_touching_labels(im_out)\n",
    "                \n",
    "            im_segmentation_stack={'Nuclei': im_out}\n",
    "            \n",
    "            cm_rand = np.random.rand(int(np.max(im_segmentation_stack['Nuclei'])), 3)\n",
    "            cm_rand[0, :] = [0.0, 0.0, 0.0]\n",
    "            colormaps_rand = Colormap(cm_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b740f045-770f-4c81-99c1-c96e4ab0134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation of cytoplasm\n",
    "im_in=im_final_stack['Threshold image'].copy()\n",
    "\n",
    "if ('NUCLEI' in stain_df.index)|('CYTOPLASM' in stain_df.index):\n",
    "    im_out = np.zeros_like(im_in[:,:,:,0], dtype=np.int32)\n",
    "    \n",
    "    for c in range(im_in.shape[3]):\n",
    "        if stain_complete_df.index[c] == 'CYTOPLASM':\n",
    "            distance = ndi.distance_transform_edt(im_in[:, :, :, c],sampling=[r_Z,r_Y,r_X])\n",
    "            coords = peak_local_max(distance, footprint=np.ones((3, 3, 3)), labels=im_in[:, :, :, c].astype(np.int32))\n",
    "            mask = np.zeros(distance.shape, dtype=bool)\n",
    "            mask[tuple(coords.T)] = True\n",
    "            markers, _ = label(mask)\n",
    "            im_out = watershed(-distance, im_nuclei_segmented, mask=im_in[:, :, :, c])\n",
    "    \n",
    "    if 'CYTOPLASM' not in stain_df.index:\n",
    "        im_out=grow_labels(im_segmentation_stack['Nuclei'], cyto_factor)\n",
    "        stain_df.loc['CYTOPLASM']=['', '', '']\n",
    "        stain_complete_df.loc['CYTOPLASM']=['', '', '', '', '', '']\n",
    "        \n",
    "    im_segmentation_stack['Cytoplasm'] = im_out.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b6ffa5-b9c9-4b3a-8a99-468b3fee2fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation of the pericellular matrix (PCM)\n",
    "im_in=im_final_stack['Threshold image'].copy()\n",
    "\n",
    "if ('NUCLEI' in stain_df.index)|('CYTOPLASM' in stain_df.index):\n",
    "    im_out = np.zeros_like(im_in[:,:,:,0], dtype=np.int32)\n",
    "    \n",
    "    im_out=grow_labels(im_segmentation_stack['Nuclei'], PCM_factor)\n",
    "    im_out=im_out-im_segmentation_stack['Cytoplasm']\n",
    "        \n",
    "    im_segmentation_stack['PCM'] = im_out.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcc09a6-7acd-4e89-94ef-341b69728685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign segmented nuclei labels to other channels (cell assignment)\n",
    "im_in=im_final_stack['Threshold image'].copy()\n",
    "\n",
    "if ('NUCLEI' in stain_df.index)|('CYTOPLASM' in stain_df.index):\n",
    "    for c in range(im_in.shape[3]):\n",
    "        if (stain_df.index[c] != 'NUCLEI') & (stain_df.index[c] != 'CYTOPLASM') & (stain_df.index[c] != 'PCM'):\n",
    "            im_segmentation_stack[stain_df.index[c]] = im_in[:, :, :, c] * (im_segmentation_stack['Cytoplasm'] + im_segmentation_stack['PCM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b657ebe4-8d4a-49c8-bb13-962b669d83f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate aggregates\n",
    "if ('NUCLEI' in stain_df.index)|('CYTOPLASM' in stain_df.index):\n",
    "    im_out,num_aggregates=label(grow_labels(im_segmentation_stack['Cytoplasm'],2.0)>0)\n",
    "    im_segmentation_stack['Aggregates']=im_out*(im_segmentation_stack['Cytoplasm']>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435cff7e-fe98-48d5-b32a-bbe0fabd7929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize original, denoised, filtered, corrected, thresholded, assigned, and segmented images\n",
    "viewer_0 = napari.Viewer()\n",
    "scale_zoom=(r_Z/zoom_factors[2], r_Y/zoom_factors[1], r_X/zoom_factors[0])\n",
    "\n",
    "for c in range(im_in.shape[3]):\n",
    "    idx = stain_complete_df.index[c]\n",
    "    marker = stain_complete_df.loc[idx, 'Marker']\n",
    "    color = stain_complete_df['Color'].iloc[c]\n",
    "    #viewer_0.add_image(im_final_stack['Normalized image'], name=f'ORIGINAL {idx} ({marker})', colormap=color, blending='additive')\n",
    "    viewer_0.add_image(im_final_stack['Zoomed image'][:, :, :, c], name=f'ORIGINAL {idx} ({marker})', colormap=color, blending='additive', scale=scale_zoom)\n",
    "    viewer_0.add_image(im_final_stack['Denoised image'][:, :, :, c], name=f'DENOISED {idx} ({marker})', colormap=color, blending='additive', scale=scale_zoom)\n",
    "    viewer_0.add_image(im_final_stack['Adjusted image'][:, :, :, c], name=f'CORRECTED {idx} ({marker})', colormap=color, blending='additive', scale=scale_zoom)\n",
    "    viewer_0.add_image(im_final_stack['Filtered image'][:, :, :, c], name=f'FILTERED {idx} ({marker})', colormap=color, blending='additive', scale=scale_zoom)\n",
    "    viewer_0.add_image(im_final_stack['Threshold image'][:, :, :, c].astype('uint8'), name=f'THRESHOLD {idx} ({marker})', contrast_limits=[0, 1], colormap=color, blending='additive', scale=scale_zoom)    \n",
    "viewer_0.scale_bar.visible = True\n",
    "viewer_0.scale_bar.unit = 'um'\n",
    "\n",
    "if ('NUCLEI' in stain_df.index)|('CYTOPLASM' in stain_df.index):\n",
    "    viewer_1 = napari.Viewer()\n",
    "\n",
    "    im_in=im_final_stack['Threshold image'].copy()\n",
    "    \n",
    "    for c in range(len(stain_complete_df.index)):\n",
    "        idx = stain_complete_df.index[c]\n",
    "        marker = stain_complete_df.loc[idx, 'Marker']\n",
    "        if stain_df.index[c] == 'NUCLEI':\n",
    "            viewer_1.add_labels(im_segmentation_stack['Nuclei'].astype('uint8'), name=f'{idx} ({marker})', blending='additive', scale=scale_zoom) #, colormap=colormaps_rand, contrast_limits=[0, np.max(im_nuclei_segmented)], blending='additive')\n",
    "        if stain_df.index[c] == 'CYTOPLASM':\n",
    "            viewer_1.add_labels(im_segmentation_stack['Cytoplasm'].astype('uint8'), blending='additive', name=f'{idx} ({marker})', scale=scale_zoom) #, colormap=colormaps_rand, contrast_limits=[0, np.max(im_nuclei_segmented)], blending='additive')\n",
    "            viewer_1.add_labels(im_segmentation_stack['PCM'].astype('uint8'), name=f'PCM', blending='additive', scale=scale_zoom) #, colormap=colormaps_rand, contrast_limits=[0, np.max(im_nuclei_segmented)], blending='additive')\n",
    "            viewer_1.add_labels(im_segmentation_stack['Aggregates'].astype('uint8'), name=f'AGGREGTES', blending='additive', scale=scale_zoom) #, colormap=colormaps_rand, contrast_limits=[0, np.max(im_aggregates)], blending='additive')\n",
    "        if (stain_df.index[c] != 'NUCLEI') & (stain_df.index[c] != 'CYTOPLASM') & (stain_df.index[c] != 'PCM'):\n",
    "            viewer_1.add_labels(im_segmentation_stack[stain_df.index[c]].astype('uint8'), name=f'{idx} ({marker})', blending='additive', scale=scale_zoom) #, colormap=colormaps_rand, contrast_limits=[0, np.max(im_nuclei_segmented)], blending='additive')\n",
    "    viewer_1.scale_bar.visible = True\n",
    "    viewer_1.scale_bar.unit = 'um'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aab820-7f42-4903-8132-d83edc9479d4",
   "metadata": {},
   "source": [
    "## QUANTIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf431e1f-94b5-4e66-aef5-accb0297f5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantify nuclei and cell properties\n",
    "im_mask = im_segmentation_stack['Nuclei'] > 0\n",
    "labels_dict = {}\n",
    "c_nuc = stain_complete_df.index.get_loc('NUCLEI')\n",
    "nuc_marker = stain_complete_df['Marker'][c_nuc]\n",
    "nuc_positions = []\n",
    "nuc_sizes=[]\n",
    "c_cyto = stain_complete_df.index.get_loc('CYTOPLASM')\n",
    "cyto_marker = stain_complete_df['Marker'][c_cyto]\n",
    "cyto_positions = []\n",
    "cyto_sizes=[]\n",
    "\n",
    "for n in range(1, int(np.max(im_segmentation_stack['Nuclei']))+1):\n",
    "    zN, yN, xN = np.where(im_segmentation_stack['Nuclei'] == n)\n",
    "    nuc_positions.append((np.mean(xN * r_X / zoom_factors[2]), np.mean(yN * r_Y / zoom_factors[1]), np.mean(zN * r_Z / zoom_factors[0])))\n",
    "    nuc_sizes.append(xN.size * r_X * r_Y * r_Z / np.prod(zoom_factors))\n",
    "    zC, yC, xC = np.where(im_segmentation_stack['Cytoplasm'] == n)\n",
    "    cyto_positions.append((np.mean(xC * r_X / zoom_factors[2]), np.mean(yC * r_Y / zoom_factors[1]), np.mean(zC * r_Z / zoom_factors[0])))\n",
    "    cyto_sizes.append(xC.size * r_X * r_Y * r_Z / np.prod(zoom_factors))\n",
    "\n",
    "labels_dict[stain_complete_df['Marker'].iloc[c_nuc]] = [\n",
    "    stain_complete_df.index[c_nuc],\n",
    "    stain_complete_df['Laser'][c_nuc],\n",
    "    stain_complete_df['Color'][c_nuc],\n",
    "    int(np.max(im_segmentation_stack['Nuclei'])),\n",
    "    (),\n",
    "    tuple(nuc_positions),\n",
    "    (), \n",
    "    tuple(nuc_sizes), \n",
    "    (), \n",
    "    ()\n",
    "]\n",
    "labels_dict[stain_complete_df['Marker'].iloc[c_cyto]] = [\n",
    "    stain_complete_df.index[c_cyto],\n",
    "    stain_complete_df['Laser'][c_cyto],\n",
    "    stain_complete_df['Color'][c_cyto],\n",
    "    int(np.max(im_segmentation_stack['Cytoplasm'])),\n",
    "    (),\n",
    "    (),\n",
    "    tuple(cyto_positions),\n",
    "    (),\n",
    "    tuple(cyto_sizes),\n",
    "    ()\n",
    "]\n",
    "\n",
    "for c in range(im_final_stack['Threshold image'].shape[3]):\n",
    "    if (c != c_nuc)&(c != c_cyto):\n",
    "        m_nuc_positions = []\n",
    "        m_nuc_sizes=[]\n",
    "        marker_sizes=[]\n",
    "        m_cyto_positions = []\n",
    "        m_cyto_sizes=[]\n",
    "        marker = stain_complete_df['Marker'][c]\n",
    "        for n in np.unique(im_segmentation_stack[stain_df.index[c]][1:, :, :])[1:]:\n",
    "            zN, yN, xN = np.where(im_segmentation_stack['Nuclei'] == n)\n",
    "            m_nuc_positions.append((np.mean(xN * r_X / zoom_factors[2]), np.mean(yN * r_Y / zoom_factors[1]), np.mean(zN * r_Z / zoom_factors[0])))\n",
    "            m_nuc_sizes.append(xN.size * r_X * r_Y * r_Z / np.prod(zoom_factors))\n",
    "\n",
    "            zC, yC, xC = np.where(im_segmentation_stack['Cytoplasm'] == n)\n",
    "            m_cyto_positions.append((np.mean(xC * r_X / zoom_factors[2]), np.mean(yC * r_Y / zoom_factors[1]), np.mean(zC * r_Z / zoom_factors[0])))\n",
    "            m_cyto_sizes.append(xC.size * r_X * r_Y * r_Z / np.prod(zoom_factors))\n",
    "            \n",
    "            zM, yM, xM = np.where(im_segmentation_stack[stain_df.index[c]] == n)\n",
    "            marker_sizes.append(xM.size * r_X * r_Y * r_Z / np.prod(zoom_factors))\n",
    "            \n",
    "        labels_dict[stain_complete_df['Marker'].iloc[c]] = [\n",
    "            stain_complete_df.index[c],\n",
    "            stain_complete_df['Laser'][c],\n",
    "            stain_complete_df['Color'][c],\n",
    "            len(np.unique(im_segmentation_stack[stain_df.index[c]][1:, :, :])[1:]),\n",
    "            tuple(np.unique(im_segmentation_stack[stain_df.index[c]][1:, :, :]).astype('int')[1:]),\n",
    "            tuple(m_nuc_positions),\n",
    "            tuple(m_cyto_positions), \n",
    "            tuple(m_nuc_sizes), \n",
    "            tuple(m_cyto_sizes), \n",
    "            tuple(marker_sizes)\n",
    "        ]\n",
    "\n",
    "if multilabel:\n",
    "    # All combinations of channels (2 or more)\n",
    "    layers_n = list(range(im_final_stack['Threshold image'].shape[3]))\n",
    "    layers_n.remove(c_nuc)\n",
    "    #layers_n.remove(c_cyto)\n",
    "    all_combinations = []\n",
    "    for k in range(2, len(layers_n) + 1):\n",
    "        all_combinations.extend(combinations(layers_n, k))\n",
    "    \n",
    "    for comb in all_combinations:\n",
    "        combo_labels=set(list(np.unique(im_segmentation_stack[stain_df.index[comb[0]]])[1:]))\n",
    "        for c in comb[1:]:\n",
    "            list2_set = set(list(np.unique(im_segmentation_stack[stain_df.index[c]])[1:]))\n",
    "            combo_labels = [x for x in combo_labels if x in list2_set]\n",
    "\n",
    "        combo_marker=[stain_complete_df['Marker'].iloc[idx] for idx in comb]\n",
    "        combo_condition=[stain_complete_df.index[idx] for idx in comb]\n",
    "\n",
    "        labels_dict[tuple(combo_marker)] = [\n",
    "            tuple(combo_condition),\n",
    "            (),\n",
    "            (),\n",
    "            len(combo_labels),\n",
    "            tuple(np.unique(combo_labels).astype('int')),\n",
    "            tuple(nuc_positions[int(i)-1] for i in combo_labels),\n",
    "            tuple(cyto_positions[int(i)-1] for i in combo_labels),\n",
    "            tuple(nuc_sizes[int(i)-1] for i in combo_labels),\n",
    "            tuple(cyto_sizes[int(i)-1] for i in combo_labels),\n",
    "            ()\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c5021b-f096-45e7-bd06-c5681ac18b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for quantification results and truncate long values for display\n",
    "labels_df = pd.DataFrame.from_dict(labels_dict, orient='index', columns=['Condition', 'Laser', 'Color', 'Number', 'Shared labels', 'Mean nuclei positions [um]', 'Mean cytoplasm positions [um]', 'Nuclei size [um3]', 'Cytoplasm size [um3]', 'Marker size [um3]'])\n",
    "labels_df.index.name = 'Combination'\n",
    "truncated_df = labels_df.copy()\n",
    "for col in [\"Shared labels\", \"Mean nuclei positions [um]\", \"Mean cytoplasm positions [um]\", \"Nuclei size [um3]\", \"Cytoplasm size [um3]\", \"Marker size [um3]\"]:\n",
    "    truncated_df[col] = truncated_df[col].apply(lambda x: truncate_cell(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51300a4f-a601-48a0-985c-eac8c68014b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display quantification DataFrame\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db857798-416e-4885-a89e-ec09e95003d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary statistics for nuclei and cell populations\n",
    "print('TOT CELLS =', labels_df['Number'][stain_complete_df['Marker']['NUCLEI']])\n",
    "print(\" \")\n",
    "for i, marker in enumerate(labels_df.index):\n",
    "    if (labels_df['Condition'][i] != 'NUCLEI') & (labels_df['Condition'][i] != 'CYTOPLASM') & (labels_df['Condition'][i] != 'NUCLEI + CYTOPLASM'):\n",
    "        print(f\" PERC {labels_df['Condition'][i]} ({marker}) = {100.0 * labels_df['Number'][i] / labels_df['Number'][0]} %\")\n",
    "print('_' * 80)\n",
    "print('MEAN SIZE NUCLEI =', np.mean(labels_df['Nuclei size [um3]'][stain_complete_df['Marker']['NUCLEI']]), 'um3')\n",
    "if 'CYTOPLASM' in stain_df.index:\n",
    "    print('MEAN SIZE CYTOPLASM =', np.mean(labels_df['Cytoplasm size [um3]'][stain_complete_df['Marker']['CYTOPLASM']]), 'um3')\n",
    "for i, marker in enumerate(labels_df.index):\n",
    "    if (labels_df['Condition'][i] != 'NUCLEI') & (labels_df['Condition'][i] != 'CYTOPLASM') & (labels_df['Condition'][i] != 'NUCLEI + CYTOPLASM'):\n",
    "        print(\" \")\n",
    "        print(f\" MEAN SIZE NUCLEI {labels_df['Condition'][i]} ({marker}) = {np.mean(labels_df['Nuclei size [um3]'][i])} um3\")\n",
    "        if 'CYTOPLASM' in stain_df.index:\n",
    "            print(f\" MEAN SIZE CYTOPLASM {labels_df['Condition'][i]} ({marker}) = {np.mean(labels_df['Cytoplasm size [um3]'][i])} um3\")\n",
    "print('_' * 80)\n",
    "for i, marker in enumerate(labels_df.index):\n",
    "    if (labels_df['Marker size [um3]'][i]!=()):\n",
    "        print(f\"MEAN SIZE {labels_df['Condition'][i]} ({marker}) = {np.mean(labels_df['Marker size [um3]'][i])} um3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8333a47d-9919-4bfe-ae8b-41706aec1673",
   "metadata": {},
   "source": [
    "## Evaluate cell distribution in the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef35bbdd-693f-45c5-8654-fd6c387a19e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot spatial distribution of nuclei and cells\n",
    "im_in=im_final_stack['Filtered image']\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(15, 15))\n",
    "for i, marker in enumerate(labels_df.index):   \n",
    "    xcoor = [t[0] for t in labels_df['Mean cytoplasm positions [um]'][i]]\n",
    "    ycoor = [t[1] for t in labels_df['Mean cytoplasm positions [um]'][i]]\n",
    "    zcoor = [t[2] for t in labels_df['Mean cytoplasm positions [um]'][i]] \n",
    "    xcount, xbins = np.histogram(xcoor, range=(0, im_in.shape[2] * r_X /zoom_factors[2]), bins=30)\n",
    "    ycount, ybins = np.histogram(ycoor, range=(0, im_in.shape[1] * r_Y /zoom_factors[1]), bins=30)\n",
    "    zcount, zbins = np.histogram(zcoor, range=(0, im_in.shape[0] * r_Z /zoom_factors[0]), bins=30)\n",
    "    xbin_centers = (xbins[:-1] + xbins[1:]) / 2\n",
    "    ybin_centers = (ybins[:-1] + ybins[1:]) / 2\n",
    "    zbin_centers = (zbins[:-1] + zbins[1:]) / 2\n",
    "    if (np.size(marker)==1):\n",
    "        color = stain_df.loc[str(labels_df['Condition'][i])]['Color']\n",
    "        if color == '':\n",
    "            color='BLUE'\n",
    "        if (labels_df['Condition'][i]!='NUCLEI'):\n",
    "            axs[0].plot(xbin_centers,xcount,label=str(labels_df['Condition'][i]),color=color)\n",
    "            axs[1].plot(ybin_centers,ycount,label=str(labels_df['Condition'][i]),color=color)\n",
    "            axs[2].plot(zbin_centers,zcount,label=str(labels_df['Condition'][i]),color=color)\n",
    "    else:\n",
    "        rgb_list=[]\n",
    "        for k in range(np.size(marker)):\n",
    "            if stain_df.loc[(labels_df['Condition'][i][k])]['Color']!='WHITE':\n",
    "                rgb_list.append(stain_df.loc[(labels_df['Condition'][i][k])]['Color'])\n",
    "            else:\n",
    "                rgb_list.append('GRAY')\n",
    "\n",
    "        colors_rgb = [to_rgb(name) for name in rgb_list]\n",
    "\n",
    "        r_total, g_total, b_total = 0.0, 0.0, 0.0\n",
    "\n",
    "        for r, g, b in colors_rgb:\n",
    "            r_total += r\n",
    "            g_total += g\n",
    "            b_total += b\n",
    "        \n",
    "        r_final = min(r_total, 1.0)\n",
    "        g_final = min(g_total, 1.0)\n",
    "        b_final = min(b_total, 1.0)\n",
    "    \n",
    "        final_rgb = (r_final, g_final, b_final)\n",
    "        \n",
    "        axs[0].plot(xbin_centers,xcount,label=str(labels_df['Condition'][i]),linestyle=(0, (2, np.size(marker)-1)), color=final_rgb)\n",
    "        axs[1].plot(ybin_centers,ycount,label=str(labels_df['Condition'][i]),linestyle=(0, (2, np.size(marker)-1)), color=final_rgb)\n",
    "        axs[2].plot(zbin_centers,zcount,label=str(labels_df['Condition'][i]),linestyle=(0, (2, np.size(marker)-1)), color=final_rgb)\n",
    "        \n",
    "axs[0].set_title('NUCLEI X DISTRIBUTION')\n",
    "axs[0].set_xlabel('[μm]')\n",
    "axs[0].legend(loc='upper right')\n",
    "axs[0].set_facecolor('black')\n",
    "axs[1].set_title('NUCLEI Y DISTRIBUTION')\n",
    "axs[1].set_xlabel('[μm]')\n",
    "axs[1].legend(loc='upper right')\n",
    "axs[1].set_facecolor('black')\n",
    "axs[2].set_title('NUCLEI Z DISTRIBUTION')\n",
    "axs[2].set_xlabel('[μm]')\n",
    "axs[2].legend(loc='upper right')\n",
    "axs[2].set_facecolor('black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d02b15-c10b-4b95-8882-ff6769eadbdb",
   "metadata": {},
   "source": [
    "## Evaluate cell size distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a02a90b-0bb0-46f7-875d-e438714bc22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot size distribution of nuclei and cells\n",
    "fig, axs = plt.subplots(2, 1, figsize=(15, 10))\n",
    "nuclei_max_size = max(x for t in labels_df['Nuclei size [um3]'] for x in t)\n",
    "cytoplasm_max_size = max(x for t in labels_df['Cytoplasm size [um3]'] for x in t)\n",
    "for i, marker in enumerate(labels_df.index):\n",
    "    nuclei_sizes = list(labels_df['Nuclei size [um3]'][i])\n",
    "    cell_sizes = list(labels_df['Cytoplasm size [um3]'][i])\n",
    "    if np.size(marker)==1:\n",
    "        if stain_df.loc[(labels_df['Condition'][i])]['Color']=='':\n",
    "            color = 'BLUE'\n",
    "        else:\n",
    "            if stain_df.loc[(labels_df['Condition'][i])]['Color']!='WHITE':\n",
    "                color = stain_df.loc[str(labels_df['Condition'][i])]['Color']\n",
    "            else:\n",
    "                color = 'GRAY'\n",
    "        #color = stain_df.loc[str(labels_df['Condition'][i])]['Color']\n",
    "        #axs[0].hist(nuclei_sizes, range=(0, nuclei_max_size), bins=30, label=str(labels_df['Condition'][i]), alpha=1/len(labels_df), color=color)\n",
    "    else:\n",
    "        rgb_list=[]\n",
    "        for k in range(np.size(marker)):\n",
    "            if stain_df.loc[(labels_df['Condition'][i][k])]['Color']!='WHITE':\n",
    "                rgb_list.append(stain_df.loc[(labels_df['Condition'][i][k])]['Color'])\n",
    "            else:\n",
    "                rgb_list.append('GRAY')\n",
    "\n",
    "        colors_rgb = [to_rgb(name) for name in rgb_list]\n",
    "\n",
    "        r_total, g_total, b_total = 0.0, 0.0, 0.0\n",
    "\n",
    "        for r, g, b in colors_rgb:\n",
    "            r_total += r\n",
    "            g_total += g\n",
    "            b_total += b\n",
    "        \n",
    "        r_final = min(r_total, 1.0)\n",
    "        g_final = min(g_total, 1.0)\n",
    "        b_final = min(b_total, 1.0)\n",
    "    \n",
    "        color = (r_final, g_final, b_final)\n",
    "        \n",
    "    if labels_df['Condition'][i] != 'CYTOPLASM':    \n",
    "        axs[0].hist(nuclei_sizes, range=(0, nuclei_max_size), bins=30, label=str(labels_df['Condition'][i]), alpha=1/len(labels_df), color=color)\n",
    "    if labels_df['Condition'][i] != 'NUCLEI':\n",
    "        axs[1].hist(cell_sizes, range=(0, cytoplasm_max_size), bins=30, label=str(labels_df['Condition'][i]), alpha=1/(len(labels_df)-1), color=color)\n",
    "axs[0].set_title('NUCLEI SIZE DISTRIBUTION')\n",
    "axs[0].set_xlabel('[μm3]')\n",
    "axs[0].legend(loc='upper right')\n",
    "axs[1].set_title('CELL SIZE DISTRIBUTION')\n",
    "axs[1].set_xlabel('[μm3]')\n",
    "axs[1].legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c710e23-4fc2-4dbe-8999-298bcff0190d",
   "metadata": {},
   "source": [
    "## CREATE .VTK VOLUME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6af6f0-3b6b-4514-bfc4-6f1c925af8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamond = ndi.generate_binary_structure(rank=3, connectivity=1)\n",
    "blocks_nuclei=pv.MultiBlock()\n",
    "blocks_cyto=pv.MultiBlock()\n",
    "nuclei_stl_old=mr.Mesh()\n",
    "cyto_stl_old=mr.Mesh()\n",
    "\n",
    "nuc_vol=np.zeros((np.max(im_segmentation_stack['Nuclei'])+1,))\n",
    "nuc_coord=np.zeros((np.max(im_segmentation_stack['Nuclei'])+1,3))\n",
    "nuc_list=np.zeros((np.max(im_segmentation_stack['Nuclei'])+1,))\n",
    "\n",
    "cyto_vol=np.zeros((np.max(im_segmentation_stack['Cytoplasm'])+1,))\n",
    "cyto_coord=np.zeros((np.max(im_segmentation_stack['Cytoplasm'])+1,3))\n",
    "cyto_list=np.zeros((np.max(im_segmentation_stack['Cytoplasm'])+1,))\n",
    "\n",
    "#agg_id=1\n",
    "\n",
    "k=0\n",
    "for j in range(1,np.max(im_segmentation_stack['Nuclei'])+1):\n",
    "    clear_output(wait=True)\n",
    "    print('NUCLEI ' + str(j) + ' / ' + str(np.max(im_segmentation_stack['Nuclei'])))\n",
    "    simpleVolume = mrn.simpleVolumeFrom3Darray(np.float32(im_segmentation_stack['Nuclei']==j))\n",
    "    floatGrid = mr.simpleVolumeToDenseGrid(simpleVolume)\n",
    "    mesh_stl = mr.gridToMesh(floatGrid , mr.Vector3f(1.0,1.0,1.0), 0.5)    \n",
    "    mr.saveMesh(mesh_stl, \"part_nuclei_mesh.stl\" )\n",
    "    \n",
    "    mesh_nuclei = pv.read(\"part_nuclei_mesh.stl\")\n",
    "    if mesh_nuclei.volume>0.0:\n",
    "        mesh_nuclei.decimate(target_reduction=0.8, inplace=True)\n",
    "\n",
    "        nuc_vol[k]=mesh_nuclei.volume\n",
    "        nuc_coord[k]=mesh_nuclei.center\n",
    "        nuc_list[k]=j\n",
    "\n",
    "        mesh_nuclei.cell_data['ID']=np.ones(mesh_nuclei.n_cells)*(k+1)\n",
    "        mesh_nuclei.cell_data['Nuclei volume (um3)']=np.ones(mesh_nuclei.n_cells)*nuc_vol[k] * r_X * r_Y * r_Z / np.prod(zoom_factors)\n",
    "        mesh_nuclei.cell_data['Z nuclei (um)']=np.ones(mesh_nuclei.n_cells)*nuc_coord[k][0] * r_Z /zoom_factors[0]\n",
    "        mesh_nuclei.cell_data['Y nuclei (um)']=np.ones(mesh_nuclei.n_cells)*nuc_coord[k][1] * r_Y /zoom_factors[1]\n",
    "        mesh_nuclei.cell_data['X nuclei (um)']=np.ones(mesh_nuclei.n_cells)*nuc_coord[k][2] * r_X /zoom_factors[2]\n",
    "        \n",
    "        blocks_nuclei.append(mesh_nuclei)\n",
    "        k=k+1\n",
    "\n",
    "\n",
    "    simpleVolume = mrn.simpleVolumeFrom3Darray(np.float32(im_segmentation_stack['Cytoplasm']==j))\n",
    "    floatGrid = mr.simpleVolumeToDenseGrid(simpleVolume)\n",
    "    mesh_stl = mr.gridToMesh(floatGrid , mr.Vector3f(1.0,1.0,1.0), 0.5)    \n",
    "    mr.saveMesh(mesh_stl, \"part_cyto_mesh.stl\" )\n",
    "    \n",
    "    mesh_cyto = pv.read(\"part_cyto_mesh.stl\")\n",
    "    if mesh_cyto.volume>0.0:\n",
    "        mesh_cyto.decimate(target_reduction=0.8, inplace=True)\n",
    "\n",
    "        cyto_vol[k]=mesh_cyto.volume\n",
    "        cyto_coord[k]=mesh_cyto.center\n",
    "        cyto_list[k]=j\n",
    "\n",
    "        mesh_cyto.cell_data['ID']=np.ones(mesh_cyto.n_cells)*(k+1)\n",
    "        mesh_cyto.cell_data['Cellular volume (um3)']=np.ones(mesh_cyto.n_cells)*cyto_vol[k] * r_X * r_Y * r_Z / np.prod(zoom_factors)\n",
    "        mesh_cyto.cell_data['Z cell (um)']=np.ones(mesh_cyto.n_cells)*cyto_coord[k][0] * r_Z /zoom_factors[0]\n",
    "        mesh_cyto.cell_data['Y cell (um)']=np.ones(mesh_cyto.n_cells)*cyto_coord[k][1] * r_Y /zoom_factors[1]\n",
    "        mesh_cyto.cell_data['X cell (um)']=np.ones(mesh_cyto.n_cells)*cyto_coord[k][2] * r_X /zoom_factors[2]\n",
    "        for i, marker in enumerate(labels_df.index):\n",
    "            if (labels_df['Condition'][i]!='NUCLEI') & (labels_df['Condition'][i]!='CYTOPLASM') & (np.size(marker)==1):\n",
    "                if j in list(labels_df['Shared labels'][i]):\n",
    "                    mesh_cyto.cell_data[marker+' expression (um3)']=np.ones(mesh_cyto.n_cells)*(labels_df['Marker size [um3]'][i][list(labels_df['Shared labels'][i]).index(j)])\n",
    "                    mesh_cyto.cell_data[marker+' rel. expr. (-)']=np.ones(mesh_cyto.n_cells)*((labels_df['Marker size [um3]'][i][list(labels_df['Shared labels'][i]).index(j)])/(cyto_vol[k] * r_X * r_Y * r_Z / np.prod(zoom_factors)))\n",
    "                else:\n",
    "                    mesh_cyto.cell_data[marker+' expression (um3)']=np.ones(mesh_cyto.n_cells)*(0.0)\n",
    "                    mesh_cyto.cell_data[marker+' rel. expr. (-)']=np.ones(mesh_cyto.n_cells)*(0.0)\n",
    "                # ass_channel_2=globals()[channel+'mag']*(NUCLEIlab==val)/np.max(globals()[channel+'mag'])\n",
    "                # mesh_cyto.cell_data[channel+'_perc_rel']=np.ones(mesh_nuclei.n_cells)*(np.sum(ass_channel_2)/np.sum(NUCLEIlab==val))\n",
    "        \n",
    "        blocks_cyto.append(mesh_cyto)\n",
    "        #k=k+1\n",
    "\n",
    "    #j=j-1\n",
    "\n",
    "# nuc_vol=nuc_vol[0:k-1]\n",
    "# nuc_coord=nuc_coord[0:k-1]\n",
    "# nuc_list=nuc_list[0:k-1]\n",
    "blocks_nuclei.extract_geometry().save(Path(input_file).stem+'_NUCLEI_labelled.vtk')\n",
    "blocks_cyto.extract_geometry().save(Path(input_file).stem+'_CYTOPLASM_labelled.vtk')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2bcca6-f1df-432c-b916-278fe84b44de",
   "metadata": {},
   "source": [
    "## and .STL for markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4966a994-8ef8-4b37-af9b-74a8e21452d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c, marker in enumerate(stain_complete_df.index):\n",
    "    if (stain_complete_df.index[c] != 'NUCLEI') & (stain_complete_df.index[c] != 'CYTOPLASM'):\n",
    "        simpleVolume = mrn.simpleVolumeFrom3Darray(np.float32(im_segmentation_stack[stain_df.index[c]]>0))\n",
    "        floatGrid = mr.simpleVolumeToDenseGrid(simpleVolume)\n",
    "        mesh_stl = mr.gridToMesh(floatGrid , mr.Vector3f(1.0,1.0,1.0), 0.5)    \n",
    "        mr.saveMesh(mesh_stl,Path(input_file).stem + \"_\" + stain_complete_df['Marker'][c] + \"_mesh.stl\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a070bde8-0355-4bec-a563-1f7740d942a2",
   "metadata": {},
   "source": [
    "### Create a complete report XSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c4282f-7756-4c49-8a50-fb7d69eb4ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export quantification results to Excel file\n",
    "with pd.ExcelWriter(Path(input_file).stem + '_nuclei_segmentation.xlsx', engine='xlsxwriter') as writer:\n",
    "    original_stain_complete_df.to_excel(writer, sheet_name='Staining', index=True)\n",
    "    xlsx_dict = {}\n",
    "    columns = ['X position [um]', 'Y position [um]', 'Z position [um]', 'Nuclei size [um3]']\n",
    "    # for i, marker in enumerate(labels_df.index):\n",
    "    #     if (labels_df['Condition'][i] != 'NUCLEI') & (labels_df['Condition'][i] != 'CYTOPLASM') & (np.size(labels_df['Condition'][i])==1):\n",
    "    #         columns.append(f\"{marker} ({labels_df['Condition'][i]})\")\n",
    "    #         columns.append(f\"{labels_df['Condition'][i]} marker size [um3]\")\n",
    "    for k in range(1, int(labels_df['Number'][0])):\n",
    "        row = [labels_df['Mean nuclei positions [um]'][0][k-1], labels_df['Nuclei size [um3]'][0][k-1]]\n",
    "        row = [row[0][0], row[0][1], row[0][2], row[1]]\n",
    "        # for i, marker in enumerate(labels_df.index):\n",
    "        #     if (labels_df['Condition'][i] != 'NUCLEI') & (labels_df['Condition'][i] != 'CYTOPLASM') & (np.size(labels_df['Condition'][i])==1):\n",
    "        #         shared = labels_df['Shared labels'][i]\n",
    "        #         if k in shared:\n",
    "        #             idx = list(shared).index(k)\n",
    "        #             #row.append(marker)\n",
    "        #             row.append(labels_df['Marker size [um3]'][marker][idx])\n",
    "        #         else:\n",
    "        #             row.extend(['', ''])\n",
    "        xlsx_dict[k] = row\n",
    "    cell_df = pd.DataFrame.from_dict(xlsx_dict, orient='index', columns=columns)\n",
    "    cell_df.to_excel(writer, sheet_name='NUCLEI', index=True)  \n",
    "    xlsx_dict = {}\n",
    "    columns = ['X position [um]', 'Y position [um]', 'Z position [um]', 'Cytoplasm size [um3]']\n",
    "    for i, marker in enumerate(labels_df.index):\n",
    "        if (labels_df['Condition'][i] != 'NUCLEI') & (labels_df['Condition'][i] != 'CYTOPLASM') & (np.size(labels_df['Condition'][i])==1):\n",
    "            #columns.append(f\"{marker} ({labels_df['Condition'][i]})\")\n",
    "            columns.append(f\"{labels_df.index[i]} marker size [um3]\")\n",
    "    for k in range(1, int(labels_df['Number'][0])):\n",
    "        row = [labels_df['Mean cytoplasm positions [um]'][1][k-1], labels_df['Cytoplasm size [um3]'][1][k-1]]\n",
    "        row = [row[0][0], row[0][1], row[0][2], row[1]]\n",
    "        for i, marker in enumerate(labels_df.index):\n",
    "            if (labels_df['Condition'][i] != 'NUCLEI') & (labels_df['Condition'][i] != 'CYTOPLASM') & (np.size(labels_df['Condition'][i])==1):\n",
    "                shared = labels_df['Shared labels'][i]\n",
    "                if k in shared:\n",
    "                    idx = list(shared).index(k)\n",
    "                    #row.append(marker)\n",
    "                    row.append(labels_df['Marker size [um3]'][marker][idx])\n",
    "                else:\n",
    "                    row.extend([0])\n",
    "        xlsx_dict[k] = row\n",
    "    cell_df = pd.DataFrame.from_dict(xlsx_dict, orient='index', columns=columns)\n",
    "    cell_df.to_excel(writer, sheet_name='CYTOPLASM', index=True)\n",
    "    resume_df = labels_df.drop(columns=['Shared labels', 'Mean nuclei positions [um]', 'Mean cytoplasm positions [um]', 'Nuclei size [um3]', 'Cytoplasm size [um3]', 'Marker size [um3]'])\n",
    "    resume_df['Laser'] = [\n",
    "        labels_df['Laser'][t] if (np.size(labels_df['Condition'][t])==1) else ''\n",
    "        for t in range(len(labels_df))\n",
    "    ]\n",
    "    resume_df['Color'] = [\n",
    "        labels_df['Color'][t] if (np.size(labels_df['Condition'][t])==1) else ''\n",
    "        for t in range(len(labels_df))\n",
    "    ]\n",
    "    resume_df['%'] = [\n",
    "        100.0 * labels_df['Number'][t] / labels_df['Number'][0] if labels_df['Condition'][t] != 'NUCLEI' else ''\n",
    "        for t in range(len(labels_df))\n",
    "    ]\n",
    "    resume_df['Mean nuclei size [um3]'] = [np.mean(t) for t in labels_df['Nuclei size [um3]']]\n",
    "    resume_df['Mean cytoplasm size [um3]'] = [np.mean(t) for t in labels_df['Cytoplasm size [um3]']]\n",
    "    resume_df['Mean marker size [um3]'] = [\n",
    "        np.mean(val) if (labels_df['Condition'][t] != 'NUCLEI') & (labels_df['Condition'][t] != 'CYTOPLASM') & (np.size(labels_df['Condition'][t])==1) else ''\n",
    "        for t, val in enumerate(labels_df['Marker size [um3]'])\n",
    "    ]\n",
    "    resume_df.to_excel(writer, sheet_name='RECAP', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2bf51e-260b-4374-934c-24464188ef5d",
   "metadata": {},
   "source": [
    "# CREATE .inp FOR FINITE ELEMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0136c70d-e8e3-48be-a6fe-609ed4e4ae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleVolume = mrn.simpleVolumeFrom3Darray(np.float32(im_segmentation_stack['Nuclei']))\n",
    "floatGrid = mr.simpleVolumeToDenseGrid(simpleVolume)\n",
    "mesh_stl = mr.gridToMesh(floatGrid , mr.Vector3f(1.0,1.0,1.0), 0.5)\n",
    "\n",
    "outVerts = mrn.getNumpyVerts(mesh_stl)\n",
    "#print(outVerts)\n",
    "\n",
    "outFaces = mrn.getNumpyFaces(mesh_stl.topology)\n",
    "\n",
    "tet = tetgen.TetGen(outVerts,outFaces)\n",
    "nodes,elems=tet.tetrahedralize(order=1, mindihedral=20, minratio=1.5)\n",
    "\n",
    "tet.write('FE_segmentation_full.vtk', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1305c4d7-ade4-4f5e-b377-18ae57041db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "meshel = meshio.read('FE_segmentation_full.vtk')\n",
    "meshel.write('FE_segmentation.inp')\n",
    "\n",
    "for c in range(1, np.max(im_segmentation_stack['Nuclei'])+1):\n",
    "    globals()[str(c)+'cell_el']=[]\n",
    "\n",
    "for ce, x in enumerate(elems):\n",
    "    #print(np.shape(np.uint16(np.mean(nodes[x],0))))\n",
    "    coord=np.int16(np.round(np.mean(nodes[x],0),0))\n",
    "    step=0\n",
    "    taken=False\n",
    "    while not(taken):\n",
    "        step+=1\n",
    "        coord[coord<step]=1\n",
    "        for k in [0,1,2]:\n",
    "            if coord[k]>=np.shape(im_segmentation_stack['Nuclei'])[k]+1-step:coord[k]=np.shape(im_segmentation_stack['Nuclei'])[k]-1\n",
    "        elemlist=im_segmentation_stack['Nuclei'][coord[0]-step:coord[0]+1+step,coord[1]-step:coord[1]+1+step,coord[2]-step:coord[2]+1+step].flatten()\n",
    "        #print(elemlist)\n",
    "        if sum(elemlist)>0:\n",
    "            c_el=st.mode(elemlist[elemlist!=0])\n",
    "            taken=True\n",
    "\n",
    "    #print(c_el)\n",
    "    if c_el!=0:\n",
    "        globals()[str(c_el)+'cell_el'].append(ce+1)\n",
    "\n",
    "f = open(\"FE_segmentation.inp\", \"a\")\n",
    "for c in range(1,np.max(im_segmentation_stack['Nuclei'])+1):\n",
    "    f.write(\"*Elset, elset=cell\" + str(c) + \"\\n\")\n",
    "    j=1\n",
    "    for t in range(1, np.size(globals()[str(c)+'cell_el'])):\n",
    "        f.write(str(globals()[str(c)+'cell_el'][t]) + \",\")\n",
    "        j+=1\n",
    "        if j>16:\n",
    "            f.write(\"\\n\")\n",
    "            j=1\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2513300b-4e15-4b54-bea3-b60a737b3727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now insert *PART header manually\n",
    "with open(\"FE_segmentation.inp\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with open(Path(input_file).stem + \"_FEA.inp\", \"w\") as f:\n",
    "    for line in lines:\n",
    "        if (line==\"*NODE\\n\"):\n",
    "            f.write(\"*PART, name=Part-1\\n\")\n",
    "        f.write(line)\n",
    "    f.write(\"*END PART\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab0a4d-5051-4a2a-972b-7e3a1c3d8ece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
