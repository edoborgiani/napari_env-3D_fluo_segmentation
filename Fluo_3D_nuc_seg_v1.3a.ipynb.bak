{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc0cffaa",
   "metadata": {},
   "source": [
    "# 3D Fluorescence Nuclei Segmentation (v1.3) - User-Friendly Workflow\n",
    "\n",
    "Welcome! This notebook guides you through 3D segmentation and quantification of nuclei and cells in fluorescence microscopy images. \n",
    "\n",
    "**How to use this notebook:**\n",
    "- Follow the numbered sections step by step.\n",
    "- Adjust parameters in the \"Setup\" section to match your experiment.\n",
    "- Each code cell includes comments and explanations.\n",
    "- Outputs and visualizations are clearly labeled.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af325be-1697-46f9-ad1f-39f2451d9614",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. Install Required Packages (run only once)\n",
    "# If you see errors about missing packages, run this cell.\n",
    "!pip install aicsimageio[nd2]\n",
    "!pip install nd2reader\n",
    "!pip install xlsxwriter\n",
    "# Add more as needed: napari[all] pyvista simpleitk csbdeep stardist meshio tetgen meshlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e1262a-3ccc-4c94-8f6e-8a5784ced14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check OpenCV version\n",
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61116848-a1b8-4dea-a7da-25a040cc7e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Import Required Libraries and Utility Functions\n",
    "# This cell imports libraries and defines utility functions used in the notebook.\n",
    "# If you see an ImportError, install the missing package using cell 1.\n",
    "from pathlib import Path\n",
    "import napari\n",
    "from napari.settings import get_settings\n",
    "import pandas as pd\n",
    "import os\n",
    "import pyvista as pv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import skimage\n",
    "from scipy import ndimage as ndi\n",
    "from scipy.ndimage import label #, find_objects\n",
    "from skimage.segmentation import relabel_sequential\n",
    "from itertools import combinations\n",
    "from skimage import filters, morphology\n",
    "from skimage.segmentation import watershed, relabel_sequential\n",
    "from skimage.feature import peak_local_max\n",
    "from vispy.color import Colormap\n",
    "from matplotlib.colors import to_rgb\n",
    "from csbdeep.utils import normalize\n",
    "from stardist.models import StarDist2D\n",
    "from collections import defaultdict\n",
    "from aicsimageio import AICSImage\n",
    "from nd2reader import ND2Reader\n",
    "from scipy.ndimage import zoom\n",
    "import meshlib.mrmeshpy as mr\n",
    "import meshlib.mrmeshnumpy as mrn\n",
    "from IPython.display import clear_output\n",
    "from scipy.ndimage import binary_dilation, generate_binary_structure\n",
    "import meshio\n",
    "import statistics as st\n",
    "import tetgen\n",
    "from skimage.morphology import ball\n",
    "from skimage.filters import threshold_otsu, threshold_niblack, threshold_sauvola\n",
    "import xlsxwriter\n",
    "from skimage.measure import regionprops\n",
    "# Enable interactive mode for napari in Jupyter\n",
    "settings = get_settings()\n",
    "settings.application.ipy_interactive = True\n",
    "\n",
    "# Image processing and utility functions\n",
    "\n",
    "def gamma_trans(im_in, gamma):\n",
    "    \"\"\"Apply gamma correction to an image.\"\"\"\n",
    "    val_c = 255.0 / (np.max(im_in)**gamma)\n",
    "    return (val_c * (im_in**gamma)).copy()\n",
    "\n",
    "\n",
    "def contr_limit(im_in, c_min=None, c_max=None):\n",
    "    \"\"\"\n",
    "    Stretch the contrast of the input image to the 0â€“255 range.\n",
    "    \"\"\"\n",
    "    im_in = im_in.astype(float)\n",
    "\n",
    "    if c_min is None:\n",
    "        c_min = im_in.min()\n",
    "    if c_max is None:\n",
    "        c_max = im_in.max()\n",
    "\n",
    "    if c_max == c_min:\n",
    "        return np.zeros_like(im_in, dtype=np.uint8)\n",
    "\n",
    "    alpha = 255.0 / (c_max - c_min)\n",
    "    beta = -c_min * alpha\n",
    "\n",
    "    im_out = alpha * im_in + beta\n",
    "    return np.clip(im_out, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def contr_stretch(im_in, c_min=None, c_max=None):\n",
    "    \"\"\"\n",
    "    Mimic Fiji's Brightness/Contrast adjustment.\n",
    "    \"\"\"\n",
    "    im_in = im_in.astype(float)\n",
    "\n",
    "    if c_min is None:\n",
    "        c_min = im_in.min()\n",
    "    if c_max is None:\n",
    "        c_max = im_in.max()\n",
    "\n",
    "    if c_max == c_min:\n",
    "        return np.zeros_like(im_in, dtype=np.uint8)\n",
    "\n",
    "    norm = (im_in - c_min) / (c_max - c_min)\n",
    "    norm = np.clip(norm, 0, 1)\n",
    "    return (norm * 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def hist_plot(im_in, stain_complete_df, thresh=0):\n",
    "    \"\"\"Plot histogram and CDF for each channel.\"\"\"\n",
    "    fig, axs = plt.subplots(1, im_in.shape[3], figsize=(15, 2))\n",
    "    for c in range(im_in.shape[3]):\n",
    "        hist, _ = np.histogram(im_in[:, :, :, c].flatten(), 256, [0, 256])\n",
    "        cdf = hist.cumsum()\n",
    "        cdf_normalized = cdf * hist.max() / cdf.max()\n",
    "        color = stain_complete_df.loc[stain_complete_df.index[c], 'Color']\n",
    "        axs[c].plot(cdf_normalized, color='b')\n",
    "        axs[c].hist(im_in[:, :, :, c].flatten(), 256, [0, 256], color=color if color != 'WHITE' else 'GRAY')\n",
    "        axs[c].set_xlim([0, 256])\n",
    "        axs[c].legend(('cdf', 'histogram'), loc='upper left')\n",
    "        if thresh > 0:\n",
    "            axs[c].plot([thresh, thresh], [0, cdf_normalized.max()], color='g')\n",
    "        axs[c].set_title(stain_complete_df.index[c])\n",
    "        axs[c].set_yscale('log')\n",
    "\n",
    "\n",
    "def truncate_cell(val, width=15):\n",
    "    \"\"\"Truncate long values for display in tables.\"\"\"\n",
    "    val_str = str(val)\n",
    "    return val_str if len(val_str) <= width else val_str[:width-3] + \"...\"\n",
    "\n",
    "\n",
    "def merge_touching_labels(label_matrix):\n",
    "    \"\"\"Merge touching labels in a 3D label matrix using union-find.\"\"\"\n",
    "    if label_matrix.max() == 0:\n",
    "        return label_matrix.copy()\n",
    "\n",
    "    padded = np.pad(label_matrix, 1, mode='constant', constant_values=0)\n",
    "    touching = defaultdict(set)\n",
    "\n",
    "    for z in range(1, padded.shape[0] - 1):\n",
    "        for y in range(1, padded.shape[1] - 1):\n",
    "            for x in range(1, padded.shape[2] - 1):\n",
    "                center = padded[z, y, x]\n",
    "                if center == 0:\n",
    "                    continue\n",
    "                neighborhood = padded[z-1:z+2, y-1:y+2, x-1:x+2].ravel()\n",
    "                for neighbor in neighborhood:\n",
    "                    if neighbor != center and neighbor != 0:\n",
    "                        touching[center].add(neighbor)\n",
    "\n",
    "    all_labels = set(np.unique(label_matrix)) - {0}\n",
    "    parent = {label: label for label in all_labels}\n",
    "\n",
    "    def find(u):\n",
    "        while parent[u] != u:\n",
    "            parent[u] = parent[parent[u]]\n",
    "            u = parent[u]\n",
    "        return u\n",
    "\n",
    "    def union(u, v):\n",
    "        pu, pv = find(u), find(v)\n",
    "        if pu != pv:\n",
    "            parent[pu] = pv\n",
    "\n",
    "    for u, neighbors in touching.items():\n",
    "        for v in neighbors:\n",
    "            if u in parent and v in parent:\n",
    "                union(u, v)\n",
    "\n",
    "    label_map = {label: find(label) for label in all_labels}\n",
    "\n",
    "    merged = np.zeros_like(label_matrix, dtype=np.int32)\n",
    "    for label, root in label_map.items():\n",
    "        merged[label_matrix == label] = root\n",
    "\n",
    "    merged, _, _ = relabel_sequential(merged)\n",
    "    return merged\n",
    "\n",
    "\n",
    "def remove_small_islands(binary_matrix, area_threshold):\n",
    "    \"\"\"Remove small connected components from a binary mask.\"\"\"\n",
    "    labeled_array, num_features = label(binary_matrix)\n",
    "    for i in range(1, num_features + 1):\n",
    "        component = (labeled_array == i)\n",
    "        if component.sum() < area_threshold:\n",
    "            binary_matrix[component] = 0\n",
    "    return binary_matrix\n",
    "\n",
    "\n",
    "def assign_labels(A, B, connectivity=1):\n",
    "    \"\"\"Assign labels from B to islands in A based on overlap (3D).\"\"\"\n",
    "    if connectivity == 2:\n",
    "        structure = np.ones((3, 3, 3))\n",
    "    else:\n",
    "        structure = None\n",
    "\n",
    "    labeled_A, num_features = label(A, structure=structure)\n",
    "    C = np.zeros_like(A, dtype=B.dtype)\n",
    "\n",
    "    for i in range(1, num_features + 1):\n",
    "        mask = labeled_A == i\n",
    "        overlapping_labels = np.unique(B[mask & (B > 0)])\n",
    "        C[mask] = overlapping_labels[0] if len(overlapping_labels) > 0 else 0\n",
    "\n",
    "    return C\n",
    "\n",
    "\n",
    "def grow_labels(label_matrix,volume_factor=5.0):\n",
    "    structure = ball(volume_factor)\n",
    "    output = label_matrix.copy()\n",
    "\n",
    "    labels = np.unique(label_matrix)\n",
    "    labels = labels[labels != 0]\n",
    "\n",
    "    volumes = {label: np.sum(label_matrix == label) for label in labels}\n",
    "    target_volumes = {label: volume_factor * vol for label, vol in volumes.items()}\n",
    "\n",
    "    label_masks = {label: (label_matrix == label) for label in labels}\n",
    "    grown_masks = label_masks.copy()\n",
    "\n",
    "    growing = {label: True for label in labels}\n",
    "\n",
    "    while any(growing.values()):\n",
    "        new_masks = {}\n",
    "        occupied = np.zeros_like(label_matrix, dtype=bool)\n",
    "\n",
    "        for label, mask in grown_masks.items():\n",
    "            occupied |= mask\n",
    "\n",
    "        for label in labels:\n",
    "            if not growing[label]:\n",
    "                continue\n",
    "            dilated = binary_dilation(grown_masks[label], structure)\n",
    "            new_mask = dilated & ~occupied\n",
    "            combined = grown_masks[label] | new_mask\n",
    "            if np.sum(combined) >= target_volumes[label]:\n",
    "                growing[label] = False\n",
    "            grown_masks[label] = combined\n",
    "            new_masks[label] = combined\n",
    "\n",
    "        output[:] = 0\n",
    "        for label, mask in grown_masks.items():\n",
    "            output[mask] = label\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def stardist3d_from_2d(\n",
    "    img_3d,\n",
    "    model_name=\"2D_versatile_fluo\",\n",
    "    nucleus_radius=5,\n",
    "    voxel_size=(1.0, 0.5, 0.5),\n",
    "    norm=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Apply StarDist2D slice-by-slice to a 3D stack, merge predictions,\n",
    "    and split weakly connected nuclei using distance-based watershed.\n",
    "    Handles anisotropic voxel spacing.\n",
    "    \"\"\"\n",
    "    assert img_3d.ndim == 3, \"Input must be 3D (Z, Y, X)\"\n",
    "    z_spacing, y_spacing, x_spacing = voxel_size\n",
    "\n",
    "    print(f\"Running StarDist2D on {img_3d.shape[0]} z-slices...\")\n",
    "    model = StarDist2D.from_pretrained(model_name)\n",
    "\n",
    "    labels_3d = np.zeros_like(img_3d, dtype=np.int32)\n",
    "    current_label = 1\n",
    "\n",
    "    for z in range(img_3d.shape[0]):\n",
    "        img = img_3d[z]\n",
    "        if norm:\n",
    "            img = normalize(img, 1, 99.8, axis=None)\n",
    "\n",
    "        labels2d, _ = model.predict_instances(img)\n",
    "        labels2d = np.where(labels2d > 0, labels2d + current_label, 0)\n",
    "        labels_3d[z] = labels2d\n",
    "        current_label = labels2d.max() + 1\n",
    "\n",
    "    labels_3d = skimage.measure.label(labels_3d > 0, connectivity=1)\n",
    "\n",
    "    print(\"Computing distance transform with anisotropic voxel spacing...\")\n",
    "    distance = ndi.distance_transform_edt(labels_3d > 0, sampling=voxel_size)\n",
    "\n",
    "    footprint = np.ones(\n",
    "        (\n",
    "            max(1, int(z_spacing / y_spacing)),\n",
    "            int(nucleus_radius),\n",
    "            int(nucleus_radius),\n",
    "        ),\n",
    "        dtype=bool,\n",
    "    )\n",
    "\n",
    "    local_max = peak_local_max(\n",
    "        distance,\n",
    "        footprint=footprint,\n",
    "        labels=labels_3d > 0,\n",
    "        exclude_border=False,\n",
    "    )\n",
    "\n",
    "    markers = np.zeros_like(labels_3d, dtype=int)\n",
    "    for i, coord in enumerate(local_max, start=1):\n",
    "        markers[tuple(coord)] = i\n",
    "\n",
    "    print(\"Running 3D watershed to split connected nuclei...\")\n",
    "    labels_split = watershed(-distance, markers, mask=labels_3d > 0)\n",
    "\n",
    "    print(f\"Done. Found {labels_split.max()} nuclei.\")\n",
    "    return labels_split\n",
    "\n",
    "\n",
    "def make_anisotropic_footprint(radius_Z, radius_Y, radius_X):\n",
    "    zz, yy, xx = np.ogrid[\n",
    "        -radius_Z:radius_Z+1,\n",
    "        -radius_Y:radius_Y+1,\n",
    "        -radius_X:radius_X+1\n",
    "    ]\n",
    "    ellipsoid = ((zz / radius_Z)**2 + (yy / radius_Y)**2 + (xx / radius_X)**2) <= 1\n",
    "    return ellipsoid\n",
    "\n",
    "\n",
    "def merge_small_touching_labels(label_matrix, size_threshold, z_weight=2.0):\n",
    "    \"\"\"\n",
    "    Merge small 3D labeled regions (< size_threshold) with touching neighbors,\n",
    "    preferentially merging into the largest touching label.\n",
    "    \"\"\"\n",
    "    if label_matrix.max() == 0:\n",
    "        return label_matrix.copy()\n",
    "\n",
    "    props = regionprops(label_matrix)\n",
    "    sizes = {p.label: p.area for p in props}\n",
    "    small_labels = {lbl for lbl, area in sizes.items() if area < size_threshold}\n",
    "\n",
    "    padded = np.pad(label_matrix, 1, mode='constant', constant_values=0)\n",
    "    touching = defaultdict(set)\n",
    "\n",
    "    z_range = [-1, 0, 1]\n",
    "    y_range = [-1, 0, 1]\n",
    "    x_range = [-1, 0, 1]\n",
    "\n",
    "    for z in range(1, padded.shape[0] - 1):\n",
    "        for y in range(1, padded.shape[1] - 1):\n",
    "            for x in range(1, padded.shape[2] - 1):\n",
    "                center = padded[z, y, x]\n",
    "                if center == 0:\n",
    "                    continue\n",
    "\n",
    "                for dz in z_range:\n",
    "                    for dy in y_range:\n",
    "                        for dx in x_range:\n",
    "                            if dz == dy == dx == 0:\n",
    "                                continue\n",
    "                            neighbor = padded[z + dz, y + dy, x + dx]\n",
    "                            if neighbor == 0 or neighbor == center:\n",
    "                                continue\n",
    "\n",
    "                            if abs(dz) == 1 and (abs(dx) + abs(dy)) == 0:\n",
    "                                if np.random.random() < 1 / z_weight:\n",
    "                                    touching[center].add(neighbor)\n",
    "                            else:\n",
    "                                touching[center].add(neighbor)\n",
    "\n",
    "    merged = label_matrix.copy()\n",
    "\n",
    "    for lbl in sorted(small_labels):\n",
    "        mask = (merged == lbl)\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "\n",
    "        neighbors = touching.get(lbl, set())\n",
    "        if not neighbors:\n",
    "            continue\n",
    "\n",
    "        neighbor_sizes = {n: sizes.get(n, 0) for n in neighbors if n not in small_labels}\n",
    "        if len(neighbor_sizes) == 0:\n",
    "            neighbor_sizes = {n: sizes.get(n, 0) for n in neighbors}\n",
    "\n",
    "        if len(neighbor_sizes) == 0:\n",
    "            continue\n",
    "\n",
    "        target_label = max(neighbor_sizes, key=neighbor_sizes.get)\n",
    "        merged[mask] = target_label\n",
    "\n",
    "    merged, _, _ = relabel_sequential(merged)\n",
    "    return merged\n",
    "\n",
    "\n",
    "def voxel_volume(ri_x, ri_y, ri_z, zooms):\n",
    "    return (ri_x * ri_y * ri_z) / np.prod(zooms)\n",
    "\n",
    "\n",
    "def compute_nuclei_cytoplasm_stats(seg_stack, r_xyz, zooms):\n",
    "    max_n = int(np.max(seg_stack['Nuclei']))\n",
    "    nuc_positions = []\n",
    "    nuc_sizes = []\n",
    "    cyto_positions = []\n",
    "    cyto_sizes = []\n",
    "\n",
    "    for n in range(1, max_n + 1):\n",
    "        zN, yN, xN = np.where(seg_stack['Nuclei'] == n)\n",
    "        if xN.size == 0:\n",
    "            nuc_positions.append((0.0, 0.0, 0.0))\n",
    "            nuc_sizes.append(0.0)\n",
    "        else:\n",
    "            nuc_positions.append((np.mean(xN * r_xyz[0] / zooms[2]), np.mean(yN * r_xyz[1] / zooms[1]), np.mean(zN * r_xyz[2] / zooms[0])))\n",
    "            nuc_sizes.append(xN.size * r_xyz[0] * r_xyz[1] * r_xyz[2] / np.prod(zooms))\n",
    "\n",
    "        zC, yC, xC = np.where(seg_stack['Cytoplasm'] == n)\n",
    "        if xC.size == 0:\n",
    "            cyto_positions.append((0.0, 0.0, 0.0))\n",
    "            cyto_sizes.append(0.0)\n",
    "        else:\n",
    "            cyto_positions.append((np.mean(xC * r_xyz[0] / zooms[2]), np.mean(yC * r_xyz[1] / zooms[1]), np.mean(zC * r_xyz[2] / zooms[0])))\n",
    "            cyto_sizes.append(xC.size * r_xyz[0] * r_xyz[1] * r_xyz[2] / np.prod(zooms))\n",
    "\n",
    "    return nuc_positions, nuc_sizes, cyto_positions, cyto_sizes\n",
    "\n",
    "\n",
    "def compute_marker_stats_for_marker(marker_idx, seg_stack, filtered_img, r_xyz, zooms):\n",
    "    \"\"\"Compute marker stats per nucleus for a single marker channel.\n",
    "    Returns: shared_labels (list of nucleus IDs), marker_sizes (list), avg_marker (list),\n",
    "    marker_cyto_sizes, avg_cyto_marker, marker_pcm_sizes, avg_pcm_marker\n",
    "    \"\"\"\n",
    "    # Identify marker names/keys used in seg_stack\n",
    "    condition = stain_complete_df.index[marker_idx]\n",
    "    marker_name = stain_complete_df['Marker'][marker_idx]\n",
    "\n",
    "    # Keys in im_segmentation_stack: use condition (e.g., 'MACRO') and suffixes\n",
    "    key_base = stain_df.index[marker_idx] if stain_df.index.name is not None else condition\n",
    "    # In this pipeline, im_segmentation_stack stores keys as condition names (same as stain_df.index)\n",
    "    seg_key = stain_df.index[marker_idx]\n",
    "\n",
    "    # If marker images were stored as intensity*mask earlier, use those\n",
    "    marker_img = seg_stack.get(seg_key, None)\n",
    "    marker_img_cyto = seg_stack.get(seg_key + '_cyto', None)\n",
    "    marker_img_pcm = seg_stack.get(seg_key + '_PCM', None)\n",
    "\n",
    "    max_n = int(np.max(seg_stack['Nuclei']))\n",
    "\n",
    "    shared_labels = []\n",
    "    marker_sizes = []\n",
    "    avg_marker = []\n",
    "    marker_cyto_sizes = []\n",
    "    avg_cyto_marker = []\n",
    "    marker_pcm_sizes = []\n",
    "    avg_pcm_marker = []\n",
    "\n",
    "    # If no marker images present, return empty lists\n",
    "    if marker_img is None:\n",
    "        return shared_labels, marker_sizes, avg_marker, marker_cyto_sizes, avg_cyto_marker, marker_pcm_sizes, avg_pcm_marker\n",
    "\n",
    "    # For intensity lookup, pick the same channel index in filtered_img\n",
    "    # Find which channel index corresponds to this condition\n",
    "    ch_idx = None\n",
    "    for i, idx in enumerate(stain_complete_df.index):\n",
    "        if idx == condition:\n",
    "            ch_idx = i\n",
    "            break\n",
    "\n",
    "    for n in range(1, max_n + 1):\n",
    "        nuc_mask = (seg_stack['Nuclei'] == n)\n",
    "        # Marker presence in the nucleus/cell region\n",
    "        mask_marker_in_nucleus = (marker_img > 0) & nuc_mask\n",
    "        if np.any(mask_marker_in_nucleus):\n",
    "            shared_labels.append(n)\n",
    "            # marker_total (cytoplasm+PCM) measured on marker_img\n",
    "            voxels = np.where(mask_marker_in_nucleus)\n",
    "            count = voxels[0].size\n",
    "            vol = count * voxel_volume(r_xyz[0], r_xyz[1], r_xyz[2], zooms)\n",
    "            marker_sizes.append(vol)\n",
    "            if ch_idx is not None:\n",
    "                vals = filtered_img[voxels[0], voxels[1], voxels[2], ch_idx]\n",
    "                avg_marker.append(float(np.mean(vals)) if vals.size>0 else 0.0)\n",
    "            else:\n",
    "                avg_marker.append(0.0)\n",
    "\n",
    "            # cytoplasm-only\n",
    "            if marker_img_cyto is not None:\n",
    "                mask_marker_cyto = (marker_img_cyto > 0) & nuc_mask\n",
    "                vox_c = np.where(mask_marker_cyto)\n",
    "                count_c = vox_c[0].size\n",
    "                marker_cyto_sizes.append(count_c * voxel_volume(r_xyz[0], r_xyz[1], r_xyz[2], zooms))\n",
    "                if ch_idx is not None and count_c>0:\n",
    "                    vals_c = filtered_img[vox_c[0], vox_c[1], vox_c[2], ch_idx]\n",
    "                    avg_cyto_marker.append(float(np.mean(vals_c)))\n",
    "                else:\n",
    "                    avg_cyto_marker.append(0.0)\n",
    "            else:\n",
    "                marker_cyto_sizes.append(0.0)\n",
    "                avg_cyto_marker.append(0.0)\n",
    "\n",
    "            # pcm-only\n",
    "            if marker_img_pcm is not None:\n",
    "                mask_marker_pcm = (marker_img_pcm > 0) & nuc_mask\n",
    "                vox_p = np.where(mask_marker_pcm)\n",
    "                count_p = vox_p[0].size\n",
    "                marker_pcm_sizes.append(count_p * voxel_volume(r_xyz[0], r_xyz[1], r_xyz[2], zooms))\n",
    "                if ch_idx is not None and count_p>0:\n",
    "                    vals_p = filtered_img[vox_p[0], vox_p[1], vox_p[2], ch_idx]\n",
    "                    avg_pcm_marker.append(float(np.mean(vals_p)))\n",
    "                else:\n",
    "                    avg_pcm_marker.append(0.0)\n",
    "            else:\n",
    "                marker_pcm_sizes.append(0.0)\n",
    "                avg_pcm_marker.append(0.0)\n",
    "\n",
    "    return shared_labels, marker_sizes, avg_marker, marker_cyto_sizes, avg_cyto_marker, marker_pcm_sizes, avg_pcm_marker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388a39a6-25b4-497e-bfe1-5250ba3ad7bc",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b528e5d3-4be6-4c08-bd1a-521791c65756",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utility functions moved\n",
    "\n",
    "The functions that were previously defined in this cell have been moved to the initial import cell (Cell 2) for easier reuse and discovery. Continue the workflow from the next cells; all helper functions are available in Cell 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f9ed9d-96d7-4068-9b7c-f2ec17a58aa4",
   "metadata": {},
   "source": [
    "# 3. Inputs and Setup\n",
    "\n",
    "In this section, you will:\n",
    "- Set the path to your image file (e.g., `.nd2` or `.tif`)\n",
    "- Define sample and staining information\n",
    "- Adjust region of interest (ROI) and scaling\n",
    "- Configure experiment-specific parameters\n",
    "\n",
    "**Edit the variables in the next code cells to match your data and experiment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7688f7-5b17-498f-86b8-90e4a13226f3",
   "metadata": {},
   "source": [
    "### File upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41837bd-55ba-4b37-affd-bc756542813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to your input file (edit this line)\n",
    "input_file = 'AGG_COLIV-INTEGRIN-CUBES_.nd2'  # Example: 'your_file.nd2' or 'your_file.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fabebf-7945-48e6-97a8-7683caed6219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image and extract metadata\n",
    "# This cell loads your image and prints basic info. If you see errors, check your file path and format.\n",
    "meta = AICSImage(input_file)\n",
    "img = meta.get_image_data(\"XYZ\", T=0) \n",
    "print('Image shape (Z, Y, X):', img.shape)\n",
    "\n",
    "# Get physical pixel sizes\n",
    "r_X = meta.physical_pixel_sizes.X # um/px\n",
    "r_Y = meta.physical_pixel_sizes.Y # um/px\n",
    "r_Z = meta.physical_pixel_sizes.Z # um/px\n",
    "print('Pixel sizes [um]:', [r_X, r_Y, r_Z])\n",
    "\n",
    "imdata = meta.get_image_data()\n",
    "imtype = imdata.dtype\n",
    "bdepth = imtype.itemsize * 8\n",
    "print('Image dtype:', imtype)\n",
    "\n",
    "with ND2Reader(input_file) as nd2:\n",
    "    print('Acquisition date:', nd2.metadata.get('date'))\n",
    "    print('Channels:', nd2.metadata.get('channels'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e47b986-7d7b-4a57-a8ed-0473e4601c40",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c105211-8565-4b07-8add-dec175f71881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set sample and staining information\n",
    "# Adjust these parameters to match your experiment\n",
    "nuclei_diameter = 10  # um\n",
    "cell_diameter = 30    # um\n",
    "\n",
    "cyto_factor = 3.0     # Factor for cytoplasm region growing\n",
    "PCM_factor = 4.0      # Factor for PCM region growing\n",
    "\n",
    "# Define your staining dictionary: channel name, fluorophore, color\n",
    "stain_dict = {\n",
    "    'NUCLEI': ['DAPI', 'DAPI', 'Blue'],\n",
    "    'MACRO': ['F4_80', 'AF488', 'Green'],\n",
    "    'M1': ['CD80', 'AF555', 'Red'],\n",
    "    'M2': ['CD206', 'AF647', 'White']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4afa3b-4101-4f6a-9632-11933a75c444",
   "metadata": {},
   "source": [
    "### Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b103b005-2497-4954-a829-2884c6bff02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set region of interest (ROI) and scaling\n",
    "# ROI = [x0, x1, y0, y1, z0, z1] (set 0 to keep full range)\n",
    "ROI = [0, 1000, 0, 1000, 0, 50]  # Example: crop to 1000x1000x50\n",
    "\n",
    "scale_factor = 0.5  # Downsample for speed (1.0 = no scaling)\n",
    "zoom_factors = [1.0, 1.0, 1.0]  # XYZ\n",
    "zoom_factors = [x * scale_factor for x in zoom_factors]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957d1a10-4f9e-41ca-9785-ca2bae4302fd",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee8fc80-6be8-4ba6-b29f-f630c2648295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup options\n",
    "name_setup = 'AYSE_CHIP'  # Name for saving/loading setup CSV\n",
    "use_setup = True          # Use saved setup if available\n",
    "trig_stardist = False     # Set True to use StarDist model for nuclei\n",
    "multilabel = True         # Enable multi-marker quantification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fa8737-3bbf-4ad5-a5af-5e4d20ffb197",
   "metadata": {},
   "source": [
    "## INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2fa518-bb33-4a94-92c0-9a9e932f8c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate derived parameters and crop image\n",
    "nuclei_radius = nuclei_diameter * 0.5 * scale_factor  # um\n",
    "cell_radius = cell_diameter * 0.5 * scale_factor      # um\n",
    "\n",
    "nuclei_volume = np.ceil(4.0 * (nuclei_radius ** 3.0) * np.pi / 3.0)  # um^3\n",
    "cell_volume = np.ceil(4.0 * (cell_radius ** 3.0) * np.pi / 3.0)      # um^3\n",
    "\n",
    "x0, x1, y0, y1, z0, z1 = ROI\n",
    "if x1 == 0:\n",
    "    x1 = img.shape[0]\n",
    "if y1 == 0:\n",
    "    y1 = img.shape[1]\n",
    "if z1 == 0:\n",
    "    z1 = img.shape[2]\n",
    "\n",
    "im_original = meta.get_image_data(\"ZYXC\", S=0, T=0).astype('float32')\n",
    "im_original_ROI = im_original[z0:z1, y0:y1, x0:x1, :]\n",
    "im_final_stack = {'Original image': im_original_ROI}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24701d78-90c0-4df3-a9ac-0f9098776dc0",
   "metadata": {},
   "source": [
    "### Information about the staining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157d0505-c5fb-4b93-b130-254add588d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and display staining DataFrame\n",
    "# This maps your channels to markers and colors for visualization and quantification\n",
    "stain_dict = {k.upper(): [item.upper() if isinstance(item, str) else item for item in v] for k, v in stain_dict.items()}\n",
    "stain_df = pd.DataFrame.from_dict(stain_dict, orient='index', columns=['Marker', 'Laser', 'Color'])\n",
    "laser_order = nd2.metadata.get('channels')\n",
    "\n",
    "# Map fluorophore to its order index\n",
    "order_map = {name.strip().upper(): i for i, name in enumerate(laser_order)}\n",
    "stain_df['order'] = stain_df['Laser'].map(order_map)\n",
    "\n",
    "# Sort and clean up\n",
    "stain_df = stain_df.sort_values('order').drop(columns='order')\n",
    "stain_df.index.name = 'Condition'\n",
    "\n",
    "if 'NUCLEI' not in stain_df.index:\n",
    "    print('No nuclei condition!')\n",
    "\n",
    "stain_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32d257a-9efb-44c3-8228-2be4978e9c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize each channel using napari\n",
    "# This cell opens an interactive viewer for your channels\n",
    "im_in = im_final_stack['Original image'].copy()\n",
    "\n",
    "viewer_0 = napari.Viewer()\n",
    "for c, c_name in enumerate(stain_df['Marker']):\n",
    "    im_channel = im_in[:, :, :, c]\n",
    "    # Stretch to [0, 255] for display\n",
    "    im_8b = ((im_channel - im_channel.min()) / (im_channel.max() - im_channel.min()) * 255).clip(0, 255).astype('uint8')\n",
    "    viewer_0.add_image(im_8b, name=f\"{stain_df.index[c]} ({c_name})\", colormap=stain_df['Color'][c], blending='additive')\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d63bd45-32c7-45be-8c8e-d1644df8e94c",
   "metadata": {},
   "source": [
    "### Acquisition processing setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a2d9c9-3a3b-4f03-ab0d-85d806558cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for acquisition and contrast/gamma settings\n",
    "im_in=im_final_stack['Original image'].copy()\n",
    "\n",
    "stain_df = stain_df.reset_index(drop=False)\n",
    "stain_initial_df = stain_df.copy()\n",
    "stain_initial_df.set_index(['Condition', 'Marker', 'Laser'], inplace=True)\n",
    "stain_initial_df[['Cont_min', 'Cont_max', 'Gamma']] = [0, 255, 1]\n",
    "stain_complete_df=stain_initial_df.copy()\n",
    "\n",
    "setup_path = f\"{name_setup}_setup.csv\"\n",
    "if use_setup and os.path.exists(setup_path):\n",
    "    stain_setup_df = pd.read_csv(setup_path)\n",
    "    stain_setup_df.set_index(['Condition', 'Marker', 'Laser'], inplace=True)\n",
    "    for idx in stain_complete_df.index:\n",
    "        if idx in stain_setup_df.index:\n",
    "            stain_complete_df.loc[idx] = stain_setup_df.loc[idx]\n",
    "            stain_complete_df['Color'] = stain_initial_df['Color']\n",
    "        else:\n",
    "            use_setup = False\n",
    "\n",
    "if not use_setup or not os.path.exists(setup_path):\n",
    "    stain_complete_df=stain_initial_df.copy()\n",
    "    settings.application.ipy_interactive = False\n",
    "    viewer_1 = napari.Viewer()\n",
    "    for c, idx in enumerate(stain_complete_df.index):\n",
    "        im_channel = im_in[:,:,:,c]\n",
    "        im_channel = ((im_channel - im_channel.min()) / (im_channel.max() - im_channel.min()) * 255).clip(0, 255).astype('uint8')\n",
    "        viewer_1.add_image(im_channel, name=f\"{idx[0]} ({idx[1]})\", colormap=stain_initial_df.loc[idx]['Color'], blending='additive')\n",
    "    napari.run()\n",
    "    image_layers = [layer for layer in viewer_1.layers if isinstance(layer, napari.layers.Image)]\n",
    "    contrast_limits = {layer.name: layer.contrast_limits for layer in image_layers}\n",
    "    gamma_val = {layer.name: layer.gamma for layer in image_layers}\n",
    "    stain_complete_df.sort_index(inplace=True)\n",
    "    for c, idx in enumerate(stain_complete_df.index):\n",
    "        name = f\"{idx[0]} ({idx[1]})\"\n",
    "        stain_complete_df.loc[idx, 'Cont_min'] = int(contrast_limits[name][0])\n",
    "        stain_complete_df.loc[idx, 'Cont_max'] = int(contrast_limits[name][1])\n",
    "        stain_complete_df.loc[idx, 'Gamma'] = gamma_val[name]\n",
    "    if os.path.exists(setup_path):\n",
    "        stain_setup_df = pd.read_csv(setup_path)\n",
    "        stain_setup_df.set_index(['Condition', 'Marker', 'Laser'], inplace=True)\n",
    "        for idx in stain_complete_df.index:\n",
    "            stain_setup_df.loc[idx] = stain_complete_df.loc[idx]\n",
    "    else:\n",
    "        stain_setup_df = stain_complete_df.copy()\n",
    "    stain_csv_setup_df = stain_setup_df.reset_index().sort_values(by='Condition')\n",
    "    stain_csv_setup_df = stain_csv_setup_df[['Condition', 'Marker', 'Laser', 'Cont_min', 'Cont_max', 'Gamma']]\n",
    "    stain_csv_setup_df.to_csv(setup_path, index=False)\n",
    "\n",
    "stain_df = stain_df.set_index('Condition')\n",
    "stain_complete_df = stain_complete_df.reset_index().set_index('Condition')\n",
    "stain_complete_df = stain_complete_df.loc[stain_df.index]\n",
    "stain_complete_df = stain_complete_df[['Marker', 'Laser', 'Color', 'Cont_min', 'Cont_max', 'Gamma']]\n",
    "original_stain_complete_df=stain_complete_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c459fc7-429e-4592-b5eb-9cedb37c8fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display stain settings DataFrame\n",
    "stain_complete_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d61176-9e49-4c94-8f04-b4fa2a16219f",
   "metadata": {},
   "source": [
    "# 5. Segmentation and Quantification\n",
    "\n",
    "This section performs thresholding, segmentation (nuclei, cytoplasm, PCM), and quantification. Each step is explained and visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b679eb17-77b9-4454-b807-e2a074f239d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and normalize image data for all channels\n",
    "im_in=im_final_stack['Original image'].copy()\n",
    "im_out = ((im_in - im_in.min()) / (im_in.max() - im_in.min()) * 255).clip(0, 255).astype('uint8')\n",
    "im_final_stack['Normalized image']=im_out.copy()\n",
    "\n",
    "# Plot histogram for each channel\n",
    "hist_plot(im_final_stack['Normalized image'], stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1863a4-8080-41ed-bec3-1c0aa0a13686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample image to isotropic spacing (if needed)\n",
    "im_in = im_final_stack['Normalized image'].copy()\n",
    "im_out = np.zeros((round(np.shape(im_in)[0] * (zoom_factors[0])),\n",
    "                   round(np.shape(im_in)[1] * (zoom_factors[1])),\n",
    "                   round(np.shape(im_in)[2] * (zoom_factors[2])),\n",
    "                   np.shape(im_in)[3]))\n",
    "\n",
    "# Compute zoom factors to get isotropic spacing (same as Y and X)\n",
    "for c in range(im_in.shape[3]):\n",
    "    im_out[:, :, :, c] = zoom(im_in[:, :, :, c], zoom=zoom_factors, order=1)\n",
    "im_final_stack['Zoomed image'] = im_out.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92171d9e-4dde-4f95-ba32-07d8cd4940e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise removal using median filter\n",
    "im_in = im_final_stack['Zoomed image'].copy()\n",
    "for c in range(im_in.shape[3]):\n",
    "    im_out[:, :, :, c] = filters.median(im_in[:, :, :, c])\n",
    "im_final_stack['Denoised image'] = im_out.copy()\n",
    "hist_plot(im_final_stack['Denoised image'], stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1216ae01-cee5-4d8a-8e9b-14069a0fc92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrast and gamma adjustment for each channel\n",
    "im_in = im_final_stack['Denoised image'].copy()\n",
    "for c, idx in enumerate(stain_complete_df.index):\n",
    "    im_out[:, :, :, c] = contr_stretch(im_in[:, :, :, c], stain_complete_df.loc[idx, 'Cont_min'], stain_complete_df.loc[idx, 'Cont_max'])\n",
    "    im_out[:, :, :, c] = gamma_trans(im_in[:, :, :, c], stain_complete_df.loc[idx, 'Gamma'])\n",
    "im_final_stack['Adjusted image'] = im_out.copy()\n",
    "hist_plot(im_final_stack['Adjusted image'], stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2464bd2-a092-4e4b-a903-a76f22969c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian filter for smoothing\n",
    "im_in = im_final_stack['Adjusted image'].copy()\n",
    "for c in range(im_in.shape[3]):\n",
    "    im_out[:, :, :, c] = filters.gaussian(im_in[:, :, :, c], 0.5, preserve_range=True)\n",
    "im_final_stack['Filtered image'] = im_out.copy()\n",
    "hist_plot(im_final_stack['Filtered image'], stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3d119a-a4e3-41ad-8de5-b91c110d3300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export histograms to Excel for each channel\n",
    "output_path = Path(input_file).stem + '_histograms.xlsx'\n",
    "im_in = im_final_stack['Filtered image'].copy()\n",
    "\n",
    "with pd.ExcelWriter(output_path, engine=\"xlsxwriter\") as writer:\n",
    "    for c in range(im_in.shape[3]):\n",
    "        im3d = im_in[:, :, :, c].copy()\n",
    "        values, counts = np.unique(im3d.astype('int'), return_counts=True)\n",
    "        hist = np.zeros(256, dtype=int)\n",
    "        hist[values] = counts\n",
    "        total = hist.sum()\n",
    "        percentage = (hist / total) * 100\n",
    "        cumulative = np.cumsum(hist)\n",
    "        cumulative_percentage = np.cumsum(percentage)\n",
    "        df = pd.DataFrame({\n",
    "            \"Pixel_Value\": np.arange(256),\n",
    "            \"Count\": hist,\n",
    "            \"Percentage\": percentage,\n",
    "            \"Cumulative_Count\": cumulative,\n",
    "            \"Cumulative_Percentage\": cumulative_percentage\n",
    "        })\n",
    "        idx = stain_complete_df.index[c]\n",
    "        marker = stain_complete_df.loc[idx, 'Marker']\n",
    "        df.to_excel(writer, sheet_name=marker, index=False)\n",
    "print(f\"Saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b7708-b305-4442-82d8-56378f7e31ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding using Otsu, Sauvola, statistical background, gain filtering\n",
    "im_in = im_final_stack[\"Filtered image\"].copy()\n",
    "im_out = im_in.copy()\n",
    "\n",
    "for c in range(im_in.shape[3]):\n",
    "    img = sitk.GetImageFromArray(im_in[:, :, :, c])\n",
    "    rescaler = sitk.RescaleIntensityImageFilter()\n",
    "    rescaler.SetOutputMinimum(0)\n",
    "    rescaler.SetOutputMaximum(255)\n",
    "    stretched = rescaler.Execute(img)\n",
    "    th_filter = sitk.OtsuThresholdImageFilter()\n",
    "    _ = th_filter.Execute(stretched)\n",
    "    otsu_value = th_filter.GetThreshold()\n",
    "    _ = th_filter.Execute(img)\n",
    "    otsu_value2 = th_filter.GetThreshold()\n",
    "    nuclei_size = int(nuclei_diameter * scale_factor / (np.mean([r_X, r_Y])))\n",
    "    cell_size = int(cell_diameter * scale_factor / (np.mean([r_X, r_Y])))\n",
    "    if stain_complete_df.index[c] == \"NUCLEI\":\n",
    "        window_size = 4 * nuclei_size + 1\n",
    "    else:\n",
    "        window_size = 4 * cell_size + 1\n",
    "    arr = sitk.GetArrayFromImage(img).astype(np.float32)\n",
    "    sauvola_value = threshold_sauvola(arr, window_size=int(window_size))\n",
    "    hist, bins = np.histogram(arr, bins=256, range=(0, arr.max()))\n",
    "    mode_bin = bins[np.argmax(hist)]\n",
    "    bg_mask = (arr >= mode_bin - 5) & (arr <= mode_bin + 5)\n",
    "    bg_vals = arr[bg_mask]\n",
    "    if bg_vals.size < 50:\n",
    "        bg_vals = arr\n",
    "    bg_mean = bg_vals.mean()\n",
    "    bg_std = bg_vals.std() + 1e-6\n",
    "    z = 3.0\n",
    "    statistical_thr = bg_mean + z * bg_std\n",
    "    final_thr = (\n",
    "        0.60 * sauvola_value +\n",
    "        0.25 * statistical_thr +\n",
    "        0.15 * otsu_value2\n",
    "    )\n",
    "    gain = arr / (bg_mean + 1e-6)\n",
    "    mask_gain = gain > 2.0\n",
    "    arrayseg = (arr > final_thr) & mask_gain\n",
    "    min_size = np.ceil(0.8 * np.pi * ((nuclei_size / 2) ** 2))\n",
    "    im_out[:, :, :, c] = remove_small_islands(arrayseg, min_size)\n",
    "im_final_stack[\"Threshold image\"] = im_out.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e22fad8-8e61-4701-be76-e79d6f67c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation of nuclei using watershed or StarDist\n",
    "if 'NUCLEI' in stain_df.index:\n",
    "    im_in = im_final_stack['Threshold image'].copy()\n",
    "    for c in range(im_in.shape[3]):\n",
    "        if stain_complete_df.index[c] == 'NUCLEI':\n",
    "            if trig_stardist:\n",
    "                im_in = im_final_stack['Filtered image'].copy()\n",
    "                transl = stardist3d_from_2d(img_3d=im_in[:, :, :, c], nucleus_radius=nuclei_diameter*scale_factor/2.0, voxel_size=(r_Z, r_Y, r_X))\n",
    "                im_mask = transl > 0\n",
    "                im_mask = morphology.binary_erosion(im_mask, footprint=np.ones((2, 2, 2))).astype(im_mask.dtype)\n",
    "                im_out, num = label((transl * im_mask) > 0)\n",
    "            else:\n",
    "                distance = ndi.distance_transform_edt(im_in[:, :, :, c], sampling=[r_Z, r_Y, r_X])\n",
    "                radius_X = int((nuclei_diameter / 2) * scale_factor / r_X)\n",
    "                radius_Y = int((nuclei_diameter / 2) * scale_factor / r_Y)\n",
    "                radius_Z = int((nuclei_diameter / 2) * scale_factor / r_Z)\n",
    "                coords = peak_local_max(distance, footprint=make_anisotropic_footprint(radius_Z, radius_Y, radius_X), labels=im_in[:, :, :, c].astype(np.int32))\n",
    "                mask = np.zeros(distance.shape, dtype=bool)\n",
    "                mask[tuple(coords.T)] = True\n",
    "                markers, _ = label(mask)\n",
    "                im_out = watershed(-distance, markers, mask=im_in[:, :, :, c])\n",
    "                size_nuclei = np.pi * 0.75 * radius_X * radius_Y * radius_Z\n",
    "                im_out = merge_small_touching_labels(im_out, size_nuclei, z_weight=r_Z/r_X)\n",
    "            im_segmentation_stack = {'Nuclei': im_out}\n",
    "            cm_rand = np.random.rand(int(np.max(im_segmentation_stack['Nuclei'])), 3)\n",
    "            cm_rand[0, :] = [0.0, 0.0, 0.0]\n",
    "            colormaps_rand = Colormap(cm_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b740f045-770f-4c81-99c1-c96e4ab0134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation of cytoplasm\n",
    "im_in = im_final_stack['Threshold image'].copy()\n",
    "if ('NUCLEI' in stain_df.index) | ('CYTOPLASM' in stain_df.index):\n",
    "    im_out = np.zeros_like(im_in[:, :, :, 0], dtype=np.int32)\n",
    "    for c in range(im_in.shape[3]):\n",
    "        if stain_complete_df.index[c] == 'CYTOPLASM':\n",
    "            distance = ndi.distance_transform_edt(im_in[:, :, :, c], sampling=[r_Z, r_Y, r_X])\n",
    "            radius_X = int((cell_diameter / 2) * scale_factor / r_X)\n",
    "            radius_Y = int((cell_diameter / 2) * scale_factor / r_Y)\n",
    "            radius_Z = int((cell_diameter / 2) * scale_factor / r_Z)\n",
    "            coords = peak_local_max(distance, footprint=make_anisotropic_footprint(radius_Z, radius_Y, radius_X), labels=im_in[:, :, :, c].astype(np.int32))\n",
    "            mask = np.zeros(distance.shape, dtype=bool)\n",
    "            mask[tuple(coords.T)] = True\n",
    "            markers, _ = label(mask)\n",
    "            im_out = watershed(-distance, im_nuclei_segmented, mask=im_in[:, :, :, c])\n",
    "    if 'CYTOPLASM' not in stain_df.index:\n",
    "        im_out = grow_labels(im_segmentation_stack['Nuclei'], cyto_factor)\n",
    "        stain_df.loc['CYTOPLASM'] = ['', '', '']\n",
    "        stain_complete_df.loc['CYTOPLASM'] = ['', '', '', '', '', '']\n",
    "    im_segmentation_stack['Cytoplasm'] = im_out.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b6ffa5-b9c9-4b3a-8a99-468b3fee2fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation of the pericellular matrix (PCM)\n",
    "im_in = im_final_stack['Threshold image'].copy()\n",
    "if ('NUCLEI' in stain_df.index) | ('CYTOPLASM' in stain_df.index):\n",
    "    im_out = np.zeros_like(im_in[:, :, :, 0], dtype=np.int32)\n",
    "    im_out = grow_labels(im_segmentation_stack['Nuclei'], PCM_factor)\n",
    "    im_out = im_out - im_segmentation_stack['Cytoplasm']\n",
    "    im_segmentation_stack['PCM'] = im_out.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcc09a6-7acd-4e89-94ef-341b69728685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign segmented nuclei labels to other channels (cell assignment)\n",
    "im_in = im_final_stack['Threshold image'].copy()\n",
    "if ('NUCLEI' in stain_df.index) | ('CYTOPLASM' in stain_df.index):\n",
    "    for c in range(im_in.shape[3]):\n",
    "        if (stain_df.index[c] != 'NUCLEI') & (stain_df.index[c] != 'CYTOPLASM') & (stain_df.index[c] != 'PCM'):\n",
    "            im_segmentation_stack[stain_df.index[c]] = im_in[:, :, :, c] * (im_segmentation_stack['Cytoplasm'] + im_segmentation_stack['PCM'])\n",
    "            im_segmentation_stack[stain_df.index[c] + '_cyto'] = im_in[:, :, :, c] * (im_segmentation_stack['Cytoplasm'])\n",
    "            im_segmentation_stack[stain_df.index[c] + '_PCM'] = im_in[:, :, :, c] * (im_segmentation_stack['PCM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b657ebe4-8d4a-49c8-bb13-962b669d83f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate aggregates\n",
    "if ('NUCLEI' in stain_df.index) | ('CYTOPLASM' in stain_df.index):\n",
    "    im_out, num_aggregates = label(grow_labels(im_segmentation_stack['Cytoplasm'], 2.0) > 0)\n",
    "    im_segmentation_stack['Aggregates'] = im_out * (im_segmentation_stack['Cytoplasm'] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435cff7e-fe98-48d5-b32a-bbe0fabd7929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize original, denoised, filtered, corrected, thresholded, assigned, and segmented images\n",
    "viewer_0 = napari.Viewer()\n",
    "scale_zoom = (r_Z / zoom_factors[2], r_Y / zoom_factors[1], r_X / zoom_factors[0])\n",
    "for c in range(im_in.shape[3]):\n",
    "    idx = stain_complete_df.index[c]\n",
    "    marker = stain_complete_df.loc[idx, 'Marker']\n",
    "    color = stain_complete_df['Color'].iloc[c]\n",
    "    viewer_0.add_image(im_final_stack['Zoomed image'][:, :, :, c], name=f'ORIGINAL {idx} ({marker})', colormap=color, blending='additive', scale=scale_zoom)\n",
    "    viewer_0.add_image(im_final_stack['Denoised image'][:, :, :, c], name=f'DENOISED {idx} ({marker})', colormap=color, blending='additive', scale=scale_zoom)\n",
    "    viewer_0.add_image(im_final_stack['Adjusted image'][:, :, :, c], name=f'CORRECTED {idx} ({marker})', colormap=color, blending='additive', scale=scale_zoom)\n",
    "    viewer_0.add_image(im_final_stack['Filtered image'][:, :, :, c], name=f'FILTERED {idx} ({marker})', colormap=color, blending='additive', scale=scale_zoom)\n",
    "    viewer_0.add_image(im_final_stack['Threshold image'][:, :, :, c].astype('uint8'), name=f'THRESHOLD {idx} ({marker})', contrast_limits=[0, 1], colormap=color, blending='additive', scale=scale_zoom)\n",
    "viewer_0.scale_bar.visible = True\n",
    "viewer_0.scale_bar.unit = 'um'\n",
    "\n",
    "if ('NUCLEI' in stain_df.index) | ('CYTOPLASM' in stain_df.index):\n",
    "    viewer_1 = napari.Viewer()\n",
    "    im_in = im_final_stack['Threshold image'].copy()\n",
    "    for c in range(len(stain_complete_df.index)):\n",
    "        idx = stain_complete_df.index[c]\n",
    "        marker = stain_complete_df.loc[idx, 'Marker']\n",
    "        if stain_df.index[c] == 'NUCLEI':\n",
    "            viewer_1.add_labels(im_segmentation_stack['Nuclei'].astype('uint8'), name=f'{idx} ({marker})', blending='additive', scale=scale_zoom)\n",
    "        if stain_df.index[c] == 'CYTOPLASM':\n",
    "            viewer_1.add_labels(im_segmentation_stack['Cytoplasm'].astype('uint8'), blending='additive', name=f'{idx} ({marker})', scale=scale_zoom)\n",
    "            viewer_1.add_labels(im_segmentation_stack['PCM'].astype('uint8'), name=f'PCM', blending='additive', scale=scale_zoom)\n",
    "            viewer_1.add_labels(im_segmentation_stack['Aggregates'].astype('uint8'), name=f'AGGREGTES', blending='additive', scale=scale_zoom)\n",
    "        if (stain_df.index[c] != 'NUCLEI') & (stain_df.index[c] != 'CYTOPLASM') & (stain_df.index[c] != 'PCM'):\n",
    "            viewer_1.add_labels(im_segmentation_stack[stain_df.index[c]].astype('uint8'), name=f'{idx} ({marker})', blending='additive', scale=scale_zoom)\n",
    "    viewer_1.scale_bar.visible = True\n",
    "    viewer_1.scale_bar.unit = 'um'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aab820-7f42-4903-8132-d83edc9479d4",
   "metadata": {},
   "source": [
    "# 6. Quantification and Analysis\n",
    "\n",
    "This section quantifies nuclei and cell properties, computes statistics, and visualizes distributions. Results are exported for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf431e1f-94b5-4e66-aef5-accb0297f5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {}\n",
    "\n",
    "# 1) Nuclei and Cytoplasm base stats\n",
    "r_xyz = (r_X, r_Y, r_Z)\n",
    "zooms = zoom_factors\n",
    "nuc_positions, nuc_sizes, cyto_positions, cyto_sizes = compute_nuclei_cytoplasm_stats(im_segmentation_stack, r_xyz, zooms)\n",
    "\n",
    "c_nuc = None\n",
    "c_cyto = None\n",
    "# find indices into stain_complete_df for NUCLEI and CYTOPLASM if present\n",
    "if 'NUCLEI' in stain_complete_df.index:\n",
    "    c_nuc = stain_complete_df.index.get_loc('NUCLEI')\n",
    "if 'CYTOPLASM' in stain_complete_df.index:\n",
    "    c_cyto = stain_complete_df.index.get_loc('CYTOPLASM')\n",
    "\n",
    "# Fill nuclei entry\n",
    "if c_nuc is not None:\n",
    "    nuc_marker = stain_complete_df['Marker'][c_nuc]\n",
    "    labels_dict[nuc_marker] = [\n",
    "        stain_complete_df.index[c_nuc],\n",
    "        stain_complete_df['Laser'][c_nuc],\n",
    "        stain_complete_df['Color'][c_nuc],\n",
    "        int(np.max(im_segmentation_stack['Nuclei'])),\n",
    "        (),  # Shared labels placeholder\n",
    "        tuple(nuc_positions),\n",
    "        (),\n",
    "        tuple(nuc_sizes),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        ()\n",
    "    ]\n",
    "\n",
    "# Fill cytoplasm entry\n",
    "if c_cyto is not None:\n",
    "    cyto_marker = stain_complete_df['Marker'][c_cyto]\n",
    "    labels_dict[cyto_marker] = [\n",
    "        stain_complete_df.index[c_cyto],\n",
    "        stain_complete_df['Laser'][c_cyto],\n",
    "        stain_complete_df['Color'][c_cyto],\n",
    "        int(np.max(im_segmentation_stack['Cytoplasm'])),\n",
    "        (),\n",
    "        (),\n",
    "        tuple(cyto_positions),\n",
    "        (),\n",
    "        tuple(cyto_sizes),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        (),\n",
    "        ()\n",
    "    ]\n",
    "\n",
    "# 2) Per-marker stats\n",
    "filtered_img = im_final_stack['Filtered image']\n",
    "num_channels = filtered_img.shape[3]\n",
    "\n",
    "# iterate through channels and compute stats for non-NUCLEI/CYTOPLASM markers\n",
    "for c in range(num_channels):\n",
    "    condition = stain_complete_df.index[c]\n",
    "    if condition in ['NUCLEI', 'CYTOPLASM', 'PCM']:\n",
    "        continue\n",
    "    marker = stain_complete_df['Marker'][c]\n",
    "\n",
    "    shared_labels, m_sizes, m_avg, m_cyto_sizes, m_cyto_avg, m_pcm_sizes, m_pcm_avg = compute_marker_stats_for_marker(c, im_segmentation_stack, filtered_img, r_xyz, zooms)\n",
    "\n",
    "    labels_dict[marker] = [\n",
    "        condition,\n",
    "        stain_complete_df['Laser'][c],\n",
    "        stain_complete_df['Color'][c],\n",
    "        len(shared_labels),\n",
    "        tuple(sorted(shared_labels)),\n",
    "        tuple(nuc_positions[i-1] for i in shared_labels) if len(shared_labels)>0 else (),\n",
    "        tuple(cyto_positions[i-1] for i in shared_labels) if len(shared_labels)>0 else (),\n",
    "        tuple(nuc_sizes[i-1] for i in shared_labels) if len(shared_labels)>0 else (),\n",
    "        tuple(cyto_sizes[i-1] for i in shared_labels) if len(shared_labels)>0 else (),\n",
    "        tuple(m_sizes),\n",
    "        tuple(m_avg),\n",
    "        tuple(m_cyto_sizes),\n",
    "        tuple(m_cyto_avg),\n",
    "        tuple(m_pcm_sizes),\n",
    "        tuple(m_pcm_avg)\n",
    "    ]\n",
    "\n",
    "# 3) Multi-label combinations (limit combo size to avoid explosion)\n",
    "max_combo_size = min(3, max(2, num_channels - 1))\n",
    "non_nuc_channels = [i for i in range(num_channels) if stain_complete_df.index[i] not in ['NUCLEI', 'CYTOPLASM', 'PCM']]\n",
    "\n",
    "marker_index_to_shared = {}\n",
    "for c in non_nuc_channels:\n",
    "    mname = stain_complete_df['Marker'][c]\n",
    "    marker_index_to_shared[c] = set(labels_dict[mname][4]) if mname in labels_dict else set()\n",
    "\n",
    "for k in range(2, max_combo_size + 1):\n",
    "    for comb in combinations(non_nuc_channels, k):\n",
    "        combo_markers = tuple(stain_complete_df['Marker'][i] for i in comb)\n",
    "        # intersect shared label sets\n",
    "        sets = [marker_index_to_shared[i] for i in comb]\n",
    "        if len(sets) == 0:\n",
    "            continue\n",
    "        combo_labels = set.intersection(*sets)\n",
    "        combo_labels = sorted(combo_labels)\n",
    "        if len(combo_labels) == 0:\n",
    "            continue\n",
    "        # build entry similar to single markers\n",
    "        labels_dict[tuple(combo_markers)] = [\n",
    "            tuple(stain_complete_df.index[i] for i in comb),\n",
    "            (),\n",
    "            (),\n",
    "            len(combo_labels),\n",
    "            tuple(combo_labels),\n",
    "            tuple(nuc_positions[i-1] for i in combo_labels) if len(combo_labels)>0 else (),\n",
    "            tuple(cyto_positions[i-1] for i in combo_labels) if len(combo_labels)>0 else (),\n",
    "            tuple(nuc_sizes[i-1] for i in combo_labels) if len(combo_labels)>0 else (),\n",
    "            tuple(cyto_sizes[i-1] for i in combo_labels) if len(combo_labels)>0 else (),\n",
    "            (),\n",
    "            (),\n",
    "            (),\n",
    "            (),\n",
    "            (),\n",
    "            ()\n",
    "        ]\n",
    "\n",
    "# labels_dict populated with nuclei, cytoplasm, per-marker and some multilabel combos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c5021b-f096-45e7-bd06-c5681ac18b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for quantification results and truncate long values for display\n",
    "labels_df = pd.DataFrame.from_dict(labels_dict, orient='index', columns=['Condition', 'Laser', 'Color', 'Number', 'Shared labels', 'Mean nuclei positions [um]', 'Mean cytoplasm positions [um]', 'Nuclei size [um3]', 'Cytoplasm size [um3]', 'Marker size [um3]', 'Avg. marker intensity', 'Marker size cytoplasm [um3]', 'Avg. marker intensity cytoplasm', 'Marker size PCM [um3]', 'Avg. marker intensity PCM'])\n",
    "labels_df.index.name = 'Combination'\n",
    "truncated_df = labels_df.copy()\n",
    "for col in [\"Shared labels\", \"Mean nuclei positions [um]\", \"Mean cytoplasm positions [um]\", \"Nuclei size [um3]\", \"Cytoplasm size [um3]\", 'Marker size [um3]', 'Avg. marker intensity', 'Marker size cytoplasm [um3]', 'Avg. marker intensity cytoplasm', 'Marker size PCM [um3]', 'Avg. marker intensity PCM']:\n",
    "    truncated_df[col] = truncated_df[col].apply(lambda x: truncate_cell(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51300a4f-a601-48a0-985c-eac8c68014b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display quantification DataFrame\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db857798-416e-4885-a89e-ec09e95003d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary statistics for nuclei and cell populations\n",
    "print('TOT CELLS =', labels_df['Number'][stain_complete_df['Marker']['NUCLEI']])\n",
    "print(\" \")\n",
    "for i, marker in enumerate(labels_df.index):\n",
    "    if (labels_df['Condition'][i] != 'NUCLEI') & (labels_df['Condition'][i] != 'CYTOPLASM') & (labels_df['Condition'][i] != 'NUCLEI + CYTOPLASM'):\n",
    "        print(f\" PERC {labels_df['Condition'][i]} ({marker}) = {100.0 * labels_df['Number'][i] / labels_df['Number'][0]} %\")\n",
    "print('_' * 80)\n",
    "print('MEAN SIZE NUCLEI =', np.mean(labels_df['Nuclei size [um3]'][stain_complete_df['Marker']['NUCLEI']]), 'um3')\n",
    "if 'CYTOPLASM' in stain_df.index:\n",
    "    print('MEAN SIZE CYTOPLASM =', np.mean(labels_df['Cytoplasm size [um3]'][stain_complete_df['Marker']['CYTOPLASM']]), 'um3')\n",
    "for i, marker in enumerate(labels_df.index):\n",
    "    if (labels_df['Condition'][i] != 'NUCLEI') & (labels_df['Condition'][i] != 'CYTOPLASM') & (labels_df['Condition'][i] != 'NUCLEI + CYTOPLASM'):\n",
    "        print(\" \")\n",
    "        print(f\" MEAN SIZE NUCLEI {labels_df['Condition'][i]} ({marker}) = {np.mean(labels_df['Nuclei size [um3]'][i])} um3\")\n",
    "        if 'CYTOPLASM' in stain_df.index:\n",
    "            print(f\" MEAN SIZE CYTOPLASM {labels_df['Condition'][i]} ({marker}) = {np.mean(labels_df['Cytoplasm size [um3]'][i])} um3\")\n",
    "print('_' * 80)\n",
    "for i, marker in enumerate(labels_df.index):\n",
    "    if (labels_df['Marker size [um3]'][i]!=()):\n",
    "        print(f\"MEAN SIZE {labels_df['Condition'][i]} ({marker}) = {np.mean(labels_df['Marker size [um3]'][i])} um3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8333a47d-9919-4bfe-ae8b-41706aec1673",
   "metadata": {},
   "source": [
    "## Evaluate cell distribution in the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef35bbdd-693f-45c5-8654-fd6c387a19e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot spatial distribution of nuclei and cells\n",
    "im_in = im_final_stack['Filtered image']\n",
    "fig, axs = plt.subplots(3, 1, figsize=(15, 15))\n",
    "for i, marker in enumerate(labels_df.index):\n",
    "    xcoor = [t[0] for t in labels_df['Mean cytoplasm positions [um]'][i]]\n",
    "    ycoor = [t[1] for t in labels_df['Mean cytoplasm positions [um]'][i]]\n",
    "    zcoor = [t[2] for t in labels_df['Mean cytoplasm positions [um]'][i]]\n",
    "    xcount, xbins = np.histogram(xcoor, range=(0, im_in.shape[2] * r_X / zoom_factors[2]), bins=30)\n",
    "    ycount, ybins = np.histogram(ycoor, range=(0, im_in.shape[1] * r_Y / zoom_factors[1]), bins=30)\n",
    "    zcount, zbins = np.histogram(zcoor, range=(0, im_in.shape[0] * r_Z / zoom_factors[0]), bins=30)\n",
    "    xbin_centers = (xbins[:-1] + xbins[1:]) / 2\n",
    "    ybin_centers = (ybins[:-1] + ybins[1:]) / 2\n",
    "    zbin_centers = (zbins[:-1] + zbins[1:]) / 2\n",
    "    # ...existing code for color and plotting...\n",
    "axs[0].set_title('NUCLEI X DISTRIBUTION')\n",
    "axs[0].set_xlabel('[Î¼m]')\n",
    "axs[0].legend(loc='upper right')\n",
    "axs[0].set_facecolor('black')\n",
    "axs[1].set_title('NUCLEI Y DISTRIBUTION')\n",
    "axs[1].set_xlabel('[Î¼m]')\n",
    "axs[1].legend(loc='upper right')\n",
    "axs[1].set_facecolor('black')\n",
    "axs[2].set_title('NUCLEI Z DISTRIBUTION')\n",
    "axs[2].set_xlabel('[Î¼m]')\n",
    "axs[2].legend(loc='upper right')\n",
    "axs[2].set_facecolor('black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d02b15-c10b-4b95-8882-ff6769eadbdb",
   "metadata": {},
   "source": [
    "## Evaluate cell size distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a02a90b-0bb0-46f7-875d-e438714bc22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot size distribution of nuclei and cells\n",
    "fig, axs = plt.subplots(2, 1, figsize=(15, 10))\n",
    "nuclei_max_size = max(x for t in labels_df['Nuclei size [um3]'] for x in t)\n",
    "cytoplasm_max_size = max(x for t in labels_df['Cytoplasm size [um3]'] for x in t)\n",
    "for i, marker in enumerate(labels_df.index):\n",
    "    nuclei_sizes = list(labels_df['Nuclei size [um3]'][i])\n",
    "    cell_sizes = list(labels_df['Cytoplasm size [um3]'][i])\n",
    "    # ...existing code for color and plotting...\n",
    "axs[0].set_title('NUCLEI SIZE DISTRIBUTION')\n",
    "axs[0].set_xlabel('[Î¼m3]')\n",
    "axs[0].legend(loc='upper right')\n",
    "axs[1].set_title('CELL SIZE DISTRIBUTION')\n",
    "axs[1].set_xlabel('[Î¼m3]')\n",
    "axs[1].legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c710e23-4fc2-4dbe-8999-298bcff0190d",
   "metadata": {},
   "source": [
    "# 7. 3D Export and Reporting\n",
    "\n",
    "This section exports 3D meshes, quantification results, and prepares files for further analysis or finite element modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6af6f0-3b6b-4514-bfc4-6f1c925af8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamond = ndi.generate_binary_structure(rank=3, connectivity=1)\n",
    "blocks_nuclei=pv.MultiBlock()\n",
    "blocks_cyto=pv.MultiBlock()\n",
    "blocks_PCM=pv.MultiBlock()\n",
    "nuclei_stl_old=mr.Mesh()\n",
    "cyto_stl_old=mr.Mesh()\n",
    "PCM_stl_old=mr.Mesh()\n",
    "\n",
    "nuc_vol=np.zeros((np.max(im_segmentation_stack['Nuclei'])+1,))\n",
    "nuc_coord=np.zeros((np.max(im_segmentation_stack['Nuclei'])+1,3))\n",
    "nuc_list=np.zeros((np.max(im_segmentation_stack['Nuclei'])+1,))\n",
    "\n",
    "cyto_vol=np.zeros((np.max(im_segmentation_stack['Cytoplasm'])+1,))\n",
    "cyto_coord=np.zeros((np.max(im_segmentation_stack['Cytoplasm'])+1,3))\n",
    "cyto_list=np.zeros((np.max(im_segmentation_stack['Cytoplasm'])+1,))\n",
    "\n",
    "PCM_vol=np.zeros((np.max(im_segmentation_stack['PCM'])+1,))\n",
    "PCM_coord=np.zeros((np.max(im_segmentation_stack['PCM'])+1,3))\n",
    "PCM_list=np.zeros((np.max(im_segmentation_stack['PCM'])+1,))\n",
    "\n",
    "#agg_id=1\n",
    "\n",
    "k=0\n",
    "for j in range(1,np.max(im_segmentation_stack['Nuclei'])+1):\n",
    "    clear_output(wait=True)\n",
    "    print('NUCLEI ' + str(j) + ' / ' + str(np.max(im_segmentation_stack['Nuclei'])))\n",
    "    \n",
    "    simpleVolume = mrn.simpleVolumeFrom3Darray(np.float32(im_segmentation_stack['Nuclei']==j))\n",
    "    floatGrid = mr.simpleVolumeToDenseGrid(simpleVolume)\n",
    "    mesh_stl = mr.gridToMesh(floatGrid , mr.Vector3f(1.0,1.0,1.0), 0.5)    \n",
    "    mr.saveMesh(mesh_stl, \"part_nuclei_mesh.stl\" )\n",
    "    \n",
    "    mesh_nuclei = pv.read(\"part_nuclei_mesh.stl\")\n",
    "    if mesh_nuclei.volume>0.0:\n",
    "        mesh_nuclei.decimate(target_reduction=0.8, inplace=True)\n",
    "\n",
    "        nuc_vol[k]=mesh_nuclei.volume\n",
    "        nuc_coord[k]=mesh_nuclei.center\n",
    "        nuc_list[k]=j\n",
    "\n",
    "        mesh_nuclei.cell_data['ID']=np.ones(mesh_nuclei.n_cells)*(k+1)\n",
    "        mesh_nuclei.cell_data['Nuclei volume (um3)']=np.ones(mesh_nuclei.n_cells)*nuc_vol[k] * r_X * r_Y * r_Z / np.prod(zoom_factors)\n",
    "        mesh_nuclei.cell_data['Z nuclei (um)']=np.ones(mesh_nuclei.n_cells)*nuc_coord[k][0] * r_Z /zoom_factors[0]\n",
    "        mesh_nuclei.cell_data['Y nuclei (um)']=np.ones(mesh_nuclei.n_cells)*nuc_coord[k][1] * r_Y /zoom_factors[1]\n",
    "        mesh_nuclei.cell_data['X nuclei (um)']=np.ones(mesh_nuclei.n_cells)*nuc_coord[k][2] * r_X /zoom_factors[2]\n",
    "        \n",
    "        blocks_nuclei.append(mesh_nuclei)\n",
    "        k=k+1\n",
    "\n",
    "\n",
    "    simpleVolume = mrn.simpleVolumeFrom3Darray(np.float32(im_segmentation_stack['Cytoplasm']==j))\n",
    "    floatGrid = mr.simpleVolumeToDenseGrid(simpleVolume)\n",
    "    mesh_stl = mr.gridToMesh(floatGrid , mr.Vector3f(1.0,1.0,1.0), 0.5)    \n",
    "    mr.saveMesh(mesh_stl, \"part_cyto_mesh.stl\" )\n",
    "    \n",
    "    mesh_cyto = pv.read(\"part_cyto_mesh.stl\")\n",
    "\n",
    "    simpleVolume = mrn.simpleVolumeFrom3Darray(np.float32(im_segmentation_stack['PCM']==j))\n",
    "    floatGrid = mr.simpleVolumeToDenseGrid(simpleVolume)\n",
    "    mesh_stl = mr.gridToMesh(floatGrid , mr.Vector3f(1.0,1.0,1.0), 0.5)    \n",
    "    mr.saveMesh(mesh_stl, \"part_PCM_mesh.stl\" )\n",
    "    \n",
    "    mesh_PCM = pv.read(\"part_PCM_mesh.stl\")\n",
    "    \n",
    "    if mesh_cyto.volume>0.0:\n",
    "        mesh_cyto.decimate(target_reduction=0.8, inplace=True)\n",
    "        mesh_PCM.decimate(target_reduction=0.8, inplace=True)\n",
    "\n",
    "        cyto_vol[k]=mesh_cyto.volume\n",
    "        cyto_coord[k]=mesh_cyto.center\n",
    "        cyto_list[k]=j\n",
    "\n",
    "        PCM_vol[k]=mesh_PCM.volume\n",
    "        PCM_coord[k]=mesh_PCM.center\n",
    "        PCM_list[k]=j\n",
    "\n",
    "        mesh_cyto.cell_data['ID']=np.ones(mesh_cyto.n_cells)*(k+1)\n",
    "        mesh_PCM.cell_data['ID']=np.ones(mesh_PCM.n_cells)*(k+1)\n",
    "        mesh_cyto.cell_data['Cellular volume (um3)']=np.ones(mesh_cyto.n_cells)*cyto_vol[k] * r_X * r_Y * r_Z / np.prod(zoom_factors)\n",
    "        mesh_PCM.cell_data['PCM volume (um3)']=np.ones(mesh_PCM.n_cells)*PCM_vol[k] * r_X * r_Y * r_Z / np.prod(zoom_factors)\n",
    "        mesh_cyto.cell_data['Z cell (um)']=np.ones(mesh_cyto.n_cells)*cyto_coord[k][0] * r_Z /zoom_factors[0]\n",
    "        mesh_cyto.cell_data['Y cell (um)']=np.ones(mesh_cyto.n_cells)*cyto_coord[k][1] * r_Y /zoom_factors[1]\n",
    "        mesh_cyto.cell_data['X cell (um)']=np.ones(mesh_cyto.n_cells)*cyto_coord[k][2] * r_X /zoom_factors[2]\n",
    "        mesh_PCM.cell_data['Z PCM (um)']=np.ones(mesh_PCM.n_cells)*PCM_coord[k][0] * r_Z /zoom_factors[0]\n",
    "        mesh_PCM.cell_data['Y PCM (um)']=np.ones(mesh_PCM.n_cells)*PCM_coord[k][1] * r_Y /zoom_factors[1]\n",
    "        mesh_PCM.cell_data['X PCM (um)']=np.ones(mesh_PCM.n_cells)*PCM_coord[k][2] * r_X /zoom_factors[2]\n",
    "        for i, marker in enumerate(labels_df.index):\n",
    "            if (labels_df['Condition'][i]!='NUCLEI') & (labels_df['Condition'][i]!='CYTOPLASM') & (np.size(marker)==1):\n",
    "                if j in list(labels_df['Shared labels'][i]):\n",
    "                    mesh_cyto.cell_data[marker+' volume (um3)']=np.ones(mesh_cyto.n_cells)*(labels_df['Marker size [um3]'][i][list(labels_df['Shared labels'][i]).index(j)])\n",
    "                    mesh_PCM.cell_data[marker+' volume (um3)']=np.ones(mesh_PCM.n_cells)*(labels_df['Marker size [um3]'][i][list(labels_df['Shared labels'][i]).index(j)])\n",
    "                    mesh_cyto.cell_data[marker+' volume cytoplasm (um3)']=np.ones(mesh_cyto.n_cells)*(labels_df['Marker size cytoplasm [um3]'][i][list(labels_df['Shared labels'][i]).index(j)])\n",
    "                    mesh_PCM.cell_data[marker+' volume PCM (um3)']=np.ones(mesh_PCM.n_cells)*(labels_df['Marker size PCM [um3]'][i][list(labels_df['Shared labels'][i]).index(j)])\n",
    "                    mesh_cyto.cell_data[marker+' rel. vol. (-)']=np.ones(mesh_cyto.n_cells)*((labels_df['Marker size [um3]'][i][list(labels_df['Shared labels'][i]).index(j)])/((cyto_vol[k]+PCM_vol[k]) * r_X * r_Y * r_Z / np.prod(zoom_factors)))\n",
    "                    mesh_PCM.cell_data[marker+' rel. vol. (-)']=np.ones(mesh_PCM.n_cells)*((labels_df['Marker size [um3]'][i][list(labels_df['Shared labels'][i]).index(j)])/((cyto_vol[k]+PCM_vol[k]) * r_X * r_Y * r_Z / np.prod(zoom_factors)))\n",
    "                    mesh_cyto.cell_data[marker+' rel. vol. cytoplasm (-)']=np.ones(mesh_cyto.n_cells)*((labels_df['Marker size cytoplasm [um3]'][i][list(labels_df['Shared labels'][i]).index(j)])/(cyto_vol[k] * r_X * r_Y * r_Z / np.prod(zoom_factors)))\n",
    "                    mesh_PCM.cell_data[marker+' rel. vol. PCM (-)']=np.ones(mesh_PCM.n_cells)*((labels_df['Marker size PCM [um3]'][i][list(labels_df['Shared labels'][i]).index(j)])/(PCM_vol[k] * r_X * r_Y * r_Z / np.prod(zoom_factors)))\n",
    "                    mesh_cyto.cell_data[marker+' avg. intensity (-)']=np.ones(mesh_cyto.n_cells)*(labels_df['Avg. marker intensity'][i][list(labels_df['Shared labels'][i]).index(j)])\n",
    "                    mesh_PCM.cell_data[marker+' avg. intensity (-)']=np.ones(mesh_PCM.n_cells)*(labels_df['Avg. marker intensity'][i][list(labels_df['Shared labels'][i]).index(j)])\n",
    "                    mesh_cyto.cell_data[marker+' avg. cytoplasm int. (-)']=np.ones(mesh_cyto.n_cells)*(labels_df['Avg. marker intensity cytoplasm'][i][list(labels_df['Shared labels'][i]).index(j)])\n",
    "                    mesh_PCM.cell_data[marker+' avg. PCM int. (-)']=np.ones(mesh_PCM.n_cells)*(labels_df['Avg. marker intensity PCM'][i][list(labels_df['Shared labels'][i]).index(j)])\n",
    "                else:\n",
    "                    mesh_cyto.cell_data[marker+' expression (um3)']=np.ones(mesh_cyto.n_cells)*(0.0)\n",
    "                    mesh_cyto.cell_data[marker+' rel. expr. (-)']=np.ones(mesh_cyto.n_cells)*(0.0)\n",
    "                # ass_channel_2=globals()[channel+'mag']*(NUCLEIlab==val)/np.max(globals()[channel+'mag'])\n",
    "                # mesh_cyto.cell_data[channel+'_perc_rel']=np.ones(mesh_nuclei.n_cells)*(np.sum(ass_channel_2)/np.sum(NUCLEIlab==val))\n",
    "        \n",
    "        blocks_cyto.append(mesh_cyto)\n",
    "        blocks_PCM.append(mesh_PCM)\n",
    "        #k=k+1\n",
    "\n",
    "    #j=j-1\n",
    "\n",
    "# nuc_vol=nuc_vol[0:k-1]\n",
    "# nuc_coord=nuc_coord[0:k-1]\n",
    "# nuc_list=nuc_list[0:k-1]\n",
    "blocks_nuclei.extract_geometry().save(Path(input_file).stem+'_NUCLEI_labelled.vtk')\n",
    "blocks_cyto.extract_geometry().save(Path(input_file).stem+'_CYTOPLASM_labelled.vtk')\n",
    "blocks_PCM.extract_geometry().save(Path(input_file).stem+'_PCM_labelled.vtk')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2bcca6-f1df-432c-b916-278fe84b44de",
   "metadata": {},
   "source": [
    "## and .STL for markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4966a994-8ef8-4b37-af9b-74a8e21452d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c, marker in enumerate(stain_complete_df.index):\n",
    "    if (stain_complete_df.index[c] != 'NUCLEI') & (stain_complete_df.index[c] != 'CYTOPLASM') & (stain_complete_df.index[c] != 'PCM'):\n",
    "        simpleVolume = mrn.simpleVolumeFrom3Darray(np.float32(im_segmentation_stack[stain_df.index[c]]>0))\n",
    "        floatGrid = mr.simpleVolumeToDenseGrid(simpleVolume)\n",
    "        mesh_stl = mr.gridToMesh(floatGrid , mr.Vector3f(1.0,1.0,1.0), 0.5)    \n",
    "        mr.saveMesh(mesh_stl,Path(input_file).stem + \"_\" + stain_complete_df['Marker'][c] + \"_mesh.stl\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a070bde8-0355-4bec-a563-1f7740d942a2",
   "metadata": {},
   "source": [
    "### Create a complete report XSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c4282f-7756-4c49-8a50-fb7d69eb4ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export quantification results to Excel file\n",
    "with pd.ExcelWriter(Path(input_file).stem + '_segmentation.xlsx', engine='xlsxwriter') as writer:\n",
    "    original_stain_complete_df.to_excel(writer, sheet_name='Staining', index=True)\n",
    "    xlsx_dict = {}\n",
    "    columns = ['X position [um]', 'Y position [um]', 'Z position [um]', 'Nuclei size [um3]']\n",
    "    # for i, marker in enumerate(labels_df.index):\n",
    "    #     if (labels_df['Condition'][i] != 'NUCLEI') & (labels_df['Condition'][i] != 'CYTOPLASM') & (np.size(labels_df['Condition'][i])==1):\n",
    "    #         columns.append(f\"{marker} ({labels_df['Condition'][i]})\")\n",
    "    #         columns.append(f\"{labels_df['Condition'][i]} marker size [um3]\")\n",
    "    for k in range(1, int(labels_df['Number'][0])):\n",
    "        row = [labels_df['Mean nuclei positions [um]'][0][k-1], labels_df['Nuclei size [um3]'][0][k-1]]\n",
    "        row = [row[0][0], row[0][1], row[0][2], row[1]]\n",
    "        # for i, marker in enumerate(labels_df.index):\n",
    "        #     if (labels_df['Condition'][i] != 'NUCLEI') & (labels_df['Condition'][i] != 'CYTOPLASM') & (np.size(labels_df['Condition'][i])==1):\n",
    "        #         shared = labels_df['Shared labels'][i]\n",
    "        #         if k in shared:\n",
    "        #             idx = list(shared).index(k)\n",
    "        #             #row.append(marker)\n",
    "        #             row.append(labels_df['Marker size [um3]'][marker][idx])\n",
    "        #         else:\n",
    "        #             row.extend(['', ''])\n",
    "        xlsx_dict[k] = row\n",
    "    cell_df = pd.DataFrame.from_dict(xlsx_dict, orient='index', columns=columns)\n",
    "    cell_df.to_excel(writer, sheet_name='NUCLEI', index=True)  \n",
    "    xlsx_dict = {}\n",
    "    columns = ['X position [um]', 'Y position [um]', 'Z position [um]', 'Cytoplasm size [um3]']  \n",
    "    for i, marker in enumerate(labels_df.index):\n",
    "        if (labels_df['Condition'][i] != 'NUCLEI') & (labels_df['Condition'][i] != 'CYTOPLASM') & (np.size(labels_df['Condition'][i])==1):\n",
    "            #columns.append(f\"{marker} ({labels_df['Condition'][i]})\")\n",
    "            columns.append(f\"{labels_df.index[i]} marker size [um3]\")\n",
    "            columns.append(f\"{labels_df.index[i]} marker size cytoplasm [um3]\")\n",
    "            columns.append(f\"{labels_df.index[i]} marker size PCM [um3]\")\n",
    "            columns.append(f\"{labels_df.index[i]} intensity [-]\")\n",
    "            columns.append(f\"{labels_df.index[i]} intensity cytoplasm [-]\")\n",
    "            columns.append(f\"{labels_df.index[i]} intensity PCM [-]\")\n",
    "    for k in range(1, int(labels_df['Number'][0])):\n",
    "        row = [labels_df['Mean cytoplasm positions [um]'][1][k-1], labels_df['Cytoplasm size [um3]'][1][k-1]]\n",
    "        row = [row[0][0], row[0][1], row[0][2], row[1]]\n",
    "        for i, marker in enumerate(labels_df.index):\n",
    "            if (labels_df['Condition'][i] != 'NUCLEI') & (labels_df['Condition'][i] != 'CYTOPLASM') & (np.size(labels_df['Condition'][i])==1):\n",
    "                shared = labels_df['Shared labels'][i]\n",
    "                if k in shared:\n",
    "                    idx = list(shared).index(k)\n",
    "                    #row.append(marker)\n",
    "                    row.append(labels_df['Marker size [um3]'][marker][idx])\n",
    "                    row.append(labels_df['Marker size cytoplasm [um3]'][marker][idx])\n",
    "                    row.append(labels_df['Marker size PCM [um3]'][marker][idx])\n",
    "                    row.append(labels_df['Avg. marker intensity'][marker][idx])\n",
    "                    row.append(labels_df['Avg. marker intensity cytoplasm'][marker][idx])\n",
    "                    row.append(labels_df['Avg. marker intensity PCM'][marker][idx])\n",
    "                else:\n",
    "                    row.extend([' ',' ',' ',' ',' ',' '])\n",
    "        xlsx_dict[k] = row\n",
    "    cell_df = pd.DataFrame.from_dict(xlsx_dict, orient='index', columns=columns)\n",
    "    cell_df.to_excel(writer, sheet_name='CYTOPLASM', index=True)\n",
    "    resume_df = labels_df.drop(columns=['Shared labels', 'Mean nuclei positions [um]', 'Mean cytoplasm positions [um]', 'Nuclei size [um3]', 'Cytoplasm size [um3]', 'Marker size [um3]', 'Avg. marker intensity', 'Marker size cytoplasm [um3]', 'Avg. marker intensity cytoplasm', 'Marker size PCM [um3]', 'Avg. marker intensity PCM'])\n",
    "    resume_df['Laser'] = [\n",
    "        labels_df['Laser'][t] if (np.size(labels_df['Condition'][t])==1) else ''\n",
    "        for t in range(len(labels_df))\n",
    "    ]\n",
    "    resume_df['Color'] = [\n",
    "        labels_df['Color'][t] if (np.size(labels_df['Condition'][t])==1) else ''\n",
    "        for t in range(len(labels_df))\n",
    "    ]\n",
    "    resume_df['%'] = [\n",
    "        100.0 * labels_df['Number'][t] / labels_df['Number'][0] if labels_df['Condition'][t] != 'NUCLEI' else ''\n",
    "        for t in range(len(labels_df))\n",
    "    ]\n",
    "    resume_df['Mean nuclei size [um3]'] = [np.mean(t) for t in labels_df['Nuclei size [um3]']]\n",
    "    resume_df['Mean cytoplasm size [um3]'] = [np.mean(t) for t in labels_df['Cytoplasm size [um3]']]\n",
    "    resume_df['Mean marker size [um3]'] = [\n",
    "        np.mean(val) if (labels_df['Condition'][t] != 'NUCLEI') & (labels_df['Condition'][t] != 'CYTOPLASM') & (np.size(labels_df['Condition'][t])==1) else ''\n",
    "        for t, val in enumerate(labels_df['Marker size [um3]'])\n",
    "    ]\n",
    "    resume_df.to_excel(writer, sheet_name='RECAP', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2bf51e-260b-4374-934c-24464188ef5d",
   "metadata": {},
   "source": [
    "# CREATE .inp FOR FINITE ELEMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0136c70d-e8e3-48be-a6fe-609ed4e4ae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleVolume = mrn.simpleVolumeFrom3Darray(np.float32(im_segmentation_stack['Nuclei']))\n",
    "floatGrid = mr.simpleVolumeToDenseGrid(simpleVolume)\n",
    "mesh_stl = mr.gridToMesh(floatGrid , mr.Vector3f(1.0,1.0,1.0), 0.5)\n",
    "\n",
    "outVerts = mrn.getNumpyVerts(mesh_stl)\n",
    "#print(outVerts)\n",
    "\n",
    "outFaces = mrn.getNumpyFaces(mesh_stl.topology)\n",
    "\n",
    "tet = tetgen.TetGen(outVerts,outFaces)\n",
    "nodes,elems=tet.tetrahedralize(order=1, mindihedral=20, minratio=1.5)\n",
    "\n",
    "tet.write('FE_segmentation_full.vtk', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1305c4d7-ade4-4f5e-b377-18ae57041db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "meshel = meshio.read('FE_segmentation_full.vtk')\n",
    "meshel.write('FE_segmentation.inp')\n",
    "\n",
    "for c in range(1, np.max(im_segmentation_stack['Nuclei'])+1):\n",
    "    globals()[str(c)+'cell_el']=[]\n",
    "\n",
    "for ce, x in enumerate(elems):\n",
    "    #print(np.shape(np.uint16(np.mean(nodes[x],0))))\n",
    "    coord=np.int16(np.round(np.mean(nodes[x],0),0))\n",
    "    step=0\n",
    "    taken=False\n",
    "    while not(taken):\n",
    "        step+=1\n",
    "        coord[coord<step]=1\n",
    "        for k in [0,1,2]:\n",
    "            if coord[k]>=np.shape(im_segmentation_stack['Nuclei'])[k]+1-step:coord[k]=np.shape(im_segmentation_stack['Nuclei'])[k]-1\n",
    "        elemlist=im_segmentation_stack['Nuclei'][coord[0]-step:coord[0]+1+step,coord[1]-step:coord[1]+1+step,coord[2]-step:coord[2]+1+step].flatten()\n",
    "        #print(elemlist)\n",
    "        if sum(elemlist)>0:\n",
    "            c_el=st.mode(elemlist[elemlist!=0])\n",
    "            taken=True\n",
    "\n",
    "    #print(c_el)\n",
    "    if c_el!=0:\n",
    "        globals()[str(c_el)+'cell_el'].append(ce+1)\n",
    "\n",
    "f = open(\"FE_segmentation.inp\", \"a\")\n",
    "for c in range(1,np.max(im_segmentation_stack['Nuclei'])+1):\n",
    "    f.write(\"*Elset, elset=cell\" + str(c) + \"\\n\")\n",
    "    j=1\n",
    "    for t in range(1, np.size(globals()[str(c)+'cell_el'])):\n",
    "        f.write(str(globals()[str(c)+'cell_el'][t]) + \",\")\n",
    "        j+=1\n",
    "        if j>16:\n",
    "            f.write(\"\\n\")\n",
    "            j=1\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2513300b-4e15-4b54-bea3-b60a737b3727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now insert *PART header manually\n",
    "with open(\"FE_segmentation.inp\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with open(Path(input_file).stem + \"_FEA.inp\", \"w\") as f:\n",
    "    for line in lines:\n",
    "        if (line==\"*NODE\\n\"):\n",
    "            f.write(\"*PART, name=Part-1\\n\")\n",
    "        f.write(line)\n",
    "    f.write(\"*END PART\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab0a4d-5051-4a2a-972b-7e3a1c3d8ece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}