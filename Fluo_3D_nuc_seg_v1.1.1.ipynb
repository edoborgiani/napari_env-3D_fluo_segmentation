{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af325be-1697-46f9-ad1f-39f2451d9614",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install aicsimageio[nd2]\n",
    "!pip install nd2reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e1262a-3ccc-4c94-8f6e-8a5784ced14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check OpenCV version\n",
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61116848-a1b8-4dea-a7da-25a040cc7e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from pathlib import Path\n",
    "import napari\n",
    "from napari.settings import get_settings\n",
    "import pandas as pd\n",
    "import os\n",
    "import pyvista as pv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "from scipy import ndimage as ndi\n",
    "from scipy.ndimage import label #, find_objects\n",
    "from skimage.segmentation import relabel_sequential\n",
    "from itertools import combinations\n",
    "from skimage import filters\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from vispy.color import Colormap\n",
    "from matplotlib.colors import to_rgb\n",
    "from csbdeep.utils import normalize\n",
    "from stardist.models import StarDist2D\n",
    "from collections import defaultdict\n",
    "from aicsimageio import AICSImage\n",
    "from nd2reader import ND2Reader\n",
    "from scipy.ndimage import zoom\n",
    "import meshlib.mrmeshpy as mr\n",
    "import meshlib.mrmeshnumpy as mrn\n",
    "from IPython.display import clear_output\n",
    "from scipy.ndimage import binary_dilation, generate_binary_structure\n",
    "import meshio\n",
    "import statistics as st\n",
    "import tetgen\n",
    "from skimage.morphology import ball\n",
    "from skimage.filters import threshold_otsu, threshold_niblack, threshold_sauvola\n",
    "\n",
    "# Enable interactive mode for napari in Jupyter\n",
    "settings = get_settings()\n",
    "settings.application.ipy_interactive = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388a39a6-25b4-497e-bfe1-5250ba3ad7bc",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b528e5d3-4be6-4c08-bd1a-521791c65756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image processing and utility functions\n",
    "\n",
    "def gamma_trans(im_in, gamma):\n",
    "    \"\"\"Apply gamma correction to an image.\"\"\"\n",
    "    val_c = 255.0 / (np.max(im_in)**gamma)\n",
    "    return (val_c * (im_in**gamma)).copy()\n",
    "\n",
    "def contr_limit(im_in, c_min=None, c_max=None):\n",
    "    \"\"\"\n",
    "    Stretch the contrast of the input image to the 0–255 range.\n",
    "    \n",
    "    Parameters:\n",
    "    - im_in: Input image (NumPy array).\n",
    "    - c_min: Minimum intensity to map to 0. If None, uses im_in.min().\n",
    "    - c_max: Maximum intensity to map to 255. If None, uses im_in.max().\n",
    "    \n",
    "    Returns:\n",
    "    - Contrast-stretched image (uint8).\n",
    "    \"\"\"\n",
    "    im_in = im_in.astype(float)\n",
    "    \n",
    "    if c_min is None:\n",
    "        c_min = im_in.min()\n",
    "    if c_max is None:\n",
    "        c_max = im_in.max()\n",
    "    \n",
    "    if c_max == c_min:\n",
    "        return np.zeros_like(im_in, dtype=np.uint8)  # avoid division by zero\n",
    "\n",
    "    alpha = 255.0 / (c_max - c_min)\n",
    "    beta = -c_min * alpha\n",
    "\n",
    "    im_out = alpha * im_in + beta\n",
    "    return np.clip(im_out, 0, 255).astype(np.uint8)\n",
    "\n",
    "def contr_stretch(im_in, c_min=None, c_max=None):\n",
    "    \"\"\"\n",
    "    Mimic Fiji's Brightness/Contrast adjustment.\n",
    "    Values below min_input become 0.\n",
    "    Values above max_input become 255.\n",
    "    Values in between are linearly scaled to 0–255.\n",
    "    \n",
    "    Parameters:\n",
    "    - im_in: Input image (NumPy array).\n",
    "    - min_input: Input value to be mapped to 0.\n",
    "    - max_input: Input value to be mapped to 255.\n",
    "    \n",
    "    Returns:\n",
    "    - Adjusted image (uint8).\n",
    "    \"\"\"\n",
    "    im_in = im_in.astype(float)\n",
    "\n",
    "    if c_min is None:\n",
    "        c_min = im_in.min()\n",
    "    if c_max is None:\n",
    "        c_max = im_in.max()\n",
    "    \n",
    "    if c_max == c_min:\n",
    "        return np.zeros_like(im_in, dtype=np.uint8)  # avoid division by zero\n",
    "\n",
    "    # Normalize: subtract min and divide by (max - min)\n",
    "    norm = (im_in - c_min) / (c_max - c_min)\n",
    "    \n",
    "    # Clip to [0, 1] so values outside range are fixed to 0 or 1\n",
    "    norm = np.clip(norm, 0, 1)\n",
    "    \n",
    "    return (norm * 255).astype(np.uint8)\n",
    "\n",
    "def hist_plot(im_in, stain_complete_df, thresh=0):\n",
    "    \"\"\"Plot histogram and CDF for each channel.\"\"\"\n",
    "    fig, axs = plt.subplots(1, im_in.shape[3], figsize=(15, 2))\n",
    "    for c in range(im_in.shape[3]):\n",
    "        hist, _ = np.histogram(im_in[:, :, :, c].flatten(), 256, [0, 256])\n",
    "        cdf = hist.cumsum()\n",
    "        cdf_normalized = cdf * hist.max() / cdf.max()\n",
    "        color = stain_complete_df.loc[stain_complete_df.index[c], 'Color']\n",
    "        axs[c].plot(cdf_normalized, color='b')\n",
    "        axs[c].hist(im_in[:, :, :, c].flatten(), 256, [0, 256], color=color if color != 'WHITE' else 'GRAY')\n",
    "        axs[c].set_xlim([0, 256])\n",
    "        axs[c].legend(('cdf', 'histogram'), loc='upper left')\n",
    "        if thresh > 0:\n",
    "            axs[c].plot([thresh, thresh], [0, cdf_normalized.max()], color='g')\n",
    "        axs[c].set_title(stain_complete_df.index[c])\n",
    "        axs[c].set_yscale('log')\n",
    "\n",
    "def truncate_cell(val, width=15):\n",
    "    \"\"\"Truncate long values for display in tables.\"\"\"\n",
    "    val_str = str(val)\n",
    "    return val_str if len(val_str) <= width else val_str[:width-3] + \"...\"\n",
    "\n",
    "def merge_touching_labels(label_matrix):\n",
    "    \"\"\"Merge touching labels in a 3D label matrix using union-find.\"\"\"\n",
    "    if label_matrix.max() == 0:\n",
    "        return label_matrix.copy()\n",
    "\n",
    "    padded = np.pad(label_matrix, 1, mode='constant', constant_values=0)\n",
    "    touching = defaultdict(set)\n",
    "\n",
    "    # Iterate over the inner volume (excluding padding)\n",
    "    for z in range(1, padded.shape[0] - 1):\n",
    "        for y in range(1, padded.shape[1] - 1):\n",
    "            for x in range(1, padded.shape[2] - 1):\n",
    "                center = padded[z, y, x]\n",
    "                if center == 0:\n",
    "                    continue\n",
    "                neighborhood = padded[z-1:z+2, y-1:y+2, x-1:x+2].ravel()\n",
    "                for neighbor in neighborhood:\n",
    "                    if neighbor != center and neighbor != 0:\n",
    "                        touching[center].add(neighbor)\n",
    "\n",
    "    # Union-Find to merge touching labels\n",
    "    all_labels = set(np.unique(label_matrix)) - {0}\n",
    "    parent = {label: label for label in all_labels}\n",
    "\n",
    "    def find(u):\n",
    "        while parent[u] != u:\n",
    "            parent[u] = parent[parent[u]]\n",
    "            u = parent[u]\n",
    "        return u\n",
    "\n",
    "    def union(u, v):\n",
    "        pu, pv = find(u), find(v)\n",
    "        if pu != pv:\n",
    "            parent[pu] = pv\n",
    "\n",
    "    for u, neighbors in touching.items():\n",
    "        for v in neighbors:\n",
    "            if u in parent and v in parent:\n",
    "                union(u, v)\n",
    "\n",
    "    label_map = {label: find(label) for label in all_labels}\n",
    "\n",
    "    # Apply merged labels\n",
    "    merged = np.zeros_like(label_matrix, dtype=np.int32)\n",
    "    for label, root in label_map.items():\n",
    "        merged[label_matrix == label] = root\n",
    "\n",
    "    # Re-label to get sequential labels starting from 1\n",
    "    merged, _, _ = relabel_sequential(merged)\n",
    "    return merged\n",
    "\n",
    "def remove_small_islands(binary_matrix, area_threshold):\n",
    "    \"\"\"Remove small connected components from a binary mask.\"\"\"\n",
    "    labeled_array, num_features = label(binary_matrix)\n",
    "    for i in range(1, num_features + 1):\n",
    "        component = (labeled_array == i)\n",
    "        if component.sum() < area_threshold:\n",
    "            binary_matrix[component] = 0\n",
    "    return binary_matrix\n",
    "\n",
    "def assign_labels(A, B, connectivity=1):\n",
    "    \"\"\"Assign labels from B to islands in A based on overlap (3D).\"\"\"\n",
    "    if connectivity == 2:\n",
    "        structure = np.ones((3, 3, 3))  # 26-connectivity\n",
    "    else:\n",
    "        structure = None  # default is 6-connectivity for 3D\n",
    "\n",
    "    labeled_A, num_features = label(A, structure=structure)\n",
    "    C = np.zeros_like(A, dtype=B.dtype)\n",
    "\n",
    "    for i in range(1, num_features + 1):\n",
    "        mask = labeled_A == i\n",
    "        overlapping_labels = np.unique(B[mask & (B > 0)])\n",
    "        C[mask] = overlapping_labels[0] if len(overlapping_labels) > 0 else 0\n",
    "\n",
    "    return C\n",
    "\n",
    "def grow_labels(label_matrix,volume_factor=5.0):\n",
    "    structure = ball(3.0) #generate_binary_structure(3, 1)  # 6-connectivity in 3D\n",
    "    output = label_matrix.copy()\n",
    "    \n",
    "    labels = np.unique(label_matrix)\n",
    "    labels = labels[labels != 0]  # exclude background\n",
    "\n",
    "    # Compute original volumes\n",
    "    volumes = {label: np.sum(label_matrix == label) for label in labels}\n",
    "    target_volumes = {label: volume_factor * vol for label, vol in volumes.items()}\n",
    "\n",
    "    # Create masks for each label\n",
    "    label_masks = {label: (label_matrix == label) for label in labels}\n",
    "    grown_masks = label_masks.copy()\n",
    "\n",
    "    # Initialize growing flags\n",
    "    growing = {label: True for label in labels}\n",
    "\n",
    "    # Start growing iterations\n",
    "    while any(growing.values()):\n",
    "        new_masks = {}\n",
    "        occupied = np.zeros_like(label_matrix, dtype=bool)\n",
    "\n",
    "        # Prepare current occupied space\n",
    "        for label, mask in grown_masks.items():\n",
    "            occupied |= mask\n",
    "\n",
    "        for label in labels:\n",
    "            if not growing[label]:\n",
    "                continue\n",
    "            # Grow\n",
    "            dilated = binary_dilation(grown_masks[label], structure)\n",
    "            # Only grow into free space\n",
    "            new_mask = dilated & ~occupied\n",
    "            combined = grown_masks[label] | new_mask\n",
    "            if np.sum(combined) >= target_volumes[label]:\n",
    "                growing[label] = False\n",
    "            grown_masks[label] = combined\n",
    "            new_masks[label] = combined\n",
    "\n",
    "        # Update output matrix\n",
    "        output[:] = 0\n",
    "        for label, mask in grown_masks.items():\n",
    "            output[mask] = label\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7688f7-5b17-498f-86b8-90e4a13226f3",
   "metadata": {},
   "source": [
    "## File upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41837bd-55ba-4b37-affd-bc756542813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TIFF file and extract image data\n",
    "input_file = 'SN BX 12008-1_CTRL_002.nd2'\n",
    "meta = AICSImage(input_file)\n",
    "img = meta.get_image_data(\"XYZ\", T=0) \n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f021b76a-2cee-40a6-a26b-f39fcbee5c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get physical pixel sizes\n",
    "r_X = meta.physical_pixel_sizes.X\n",
    "r_Y = meta.physical_pixel_sizes.Y\n",
    "r_Z = meta.physical_pixel_sizes.Z\n",
    "print([r_X, r_Y, r_Z])\n",
    "\n",
    "imdata=meta.get_image_data()\n",
    "imtype=imdata.dtype\n",
    "bdepth=imtype.itemsize*8\n",
    "print(imtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c105211-8565-4b07-8add-dec175f71881",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei_diameter=10 #um\n",
    "cell_diameter=30 #um\n",
    "nuclei_size=np.ceil(nuclei_diameter/np.mean([r_X,r_Y]))\n",
    "cell_size=np.ceil(cell_diameter/np.mean([r_X,r_Y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62883205-6f36-4bf1-9e7b-a7da41dd72e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ND2Reader(input_file) as nd2:\n",
    "    print(\"Date:\", nd2.metadata.get(\"date\"))\n",
    "    print(\"Channels:\", nd2.metadata.get(\"channels\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2fa518-bb33-4a94-92c0-9a9e932f8c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_in = meta.get_image_data(\"ZYXC\", S=0, T=0).astype('float32')\n",
    "im_in = im_in[:,:,:1024,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24701d78-90c0-4df3-a9ac-0f9098776dc0",
   "metadata": {},
   "source": [
    "### Information about the staining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157d0505-c5fb-4b93-b130-254add588d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define staining dictionary and create DataFrame\n",
    "stain_dict = {\n",
    "    'NUCLEI': ['DAPI', 'DAPI', 'Blue'],\n",
    "    'AGGRECAN': ['AGG', 'AF488', 'Green'],\n",
    "    'COLLAGEN': ['COLII', 'AF555', 'Red'],\n",
    "    'NFKB': ['NFKB', 'AF647', 'White']\n",
    "}\n",
    "\n",
    "stain_dict = {k.upper(): [item.upper() if isinstance(item, str) else item for item in v] for k, v in stain_dict.items()}\n",
    "stain_df = pd.DataFrame.from_dict(stain_dict, orient='index', columns=['Marker', 'Laser', 'Color'])\n",
    "laser_order=nd2.metadata.get(\"channels\")\n",
    "\n",
    "# Map fluorophore to its order index\n",
    "order_map = {name.strip().upper(): i for i, name in enumerate(laser_order)}\n",
    "stain_df['order'] = stain_df['Laser'].map(order_map)\n",
    "\n",
    "# Sort by that and drop helper column\n",
    "stain_df = stain_df.sort_values('order').drop(columns='order')\n",
    "\n",
    "stain_df.index.name = 'Condition'\n",
    "\n",
    "if 'NUCLEI' not in stain_df.index:\n",
    "    print('No nuclei condition!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32d257a-9efb-44c3-8228-2be4978e9c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize each channel using napari\n",
    "viewer_0 = napari.Viewer()\n",
    "for c, c_name in enumerate(stain_df['Marker']):\n",
    "    #im_in = meta.get_image_data(\"ZYX\", C=c, S=0, T=0).astype('float32')\n",
    "    im_channel = im_in[:,:,:,c]\n",
    "\n",
    "    # Stretch to [0, 255]\n",
    "    im_8b = ((im_channel - im_channel.min()) / (im_channel.max() - im_channel.min()) * 255).clip(0, 255).astype('uint8')\n",
    "    \n",
    "    viewer_0.add_image(im_8b, name=f\"{stain_df.index[c]} ({c_name})\", \n",
    "                        colormap=stain_df['Color'][c], blending='additive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d63bd45-32c7-45be-8c8e-d1644df8e94c",
   "metadata": {},
   "source": [
    "### Acquisition processing setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a2d9c9-3a3b-4f03-ab0d-85d806558cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for acquisition and contrast/gamma settings\n",
    "name_setup = 'AYSE_CHIP'\n",
    "use_setup = True\n",
    "\n",
    "stain_df = stain_df.reset_index(drop=False)\n",
    "stain_initial_df = stain_df.copy()\n",
    "stain_initial_df.set_index(['Condition', 'Marker', 'Laser'], inplace=True)\n",
    "stain_initial_df[['Cont_min', 'Cont_max', 'Gamma']] = [0, 255, 1]\n",
    "stain_complete_df=stain_initial_df.copy()\n",
    "\n",
    "setup_path = f\"{name_setup}_setup.csv\"\n",
    "if use_setup and os.path.exists(setup_path):\n",
    "    stain_setup_df = pd.read_csv(setup_path)\n",
    "    stain_setup_df.set_index(['Condition', 'Marker', 'Laser'], inplace=True)\n",
    "    for idx in stain_complete_df.index:\n",
    "        if idx in stain_setup_df.index:\n",
    "            stain_complete_df.loc[idx] = stain_setup_df.loc[idx]\n",
    "            stain_complete_df['Color'] = stain_initial_df['Color']\n",
    "        else:\n",
    "            use_setup = False\n",
    "\n",
    "if not use_setup or not os.path.exists(setup_path):\n",
    "    stain_complete_df=stain_initial_df.copy()\n",
    "    settings.application.ipy_interactive = False\n",
    "    viewer_1 = napari.Viewer()\n",
    "    for c, idx in enumerate(stain_complete_df.index):\n",
    "        im_channel = im_in[:,:,:,c]\n",
    "        im_channel = ((im_channel - im_channel.min()) / (im_channel.max() - im_channel.min()) * 255).clip(0, 255).astype('uint8')\n",
    "        viewer_1.add_image(im_channel, name=f\"{idx[0]} ({idx[1]})\", colormap=stain_initial_df.loc[idx]['Color'], blending='additive')\n",
    "    napari.run()\n",
    "    image_layers = [layer for layer in viewer_1.layers if isinstance(layer, napari.layers.Image)]\n",
    "    contrast_limits = {layer.name: layer.contrast_limits for layer in image_layers}\n",
    "    gamma_val = {layer.name: layer.gamma for layer in image_layers}\n",
    "    stain_complete_df.sort_index(inplace=True)\n",
    "    for c, idx in enumerate(stain_complete_df.index):\n",
    "        name = f\"{idx[0]} ({idx[1]})\"\n",
    "        stain_complete_df.loc[idx, 'Cont_min'] = int(contrast_limits[name][0])\n",
    "        stain_complete_df.loc[idx, 'Cont_max'] = int(contrast_limits[name][1])\n",
    "        stain_complete_df.loc[idx, 'Gamma'] = gamma_val[name]\n",
    "    if os.path.exists(setup_path):\n",
    "        stain_setup_df = pd.read_csv(setup_path)\n",
    "        stain_setup_df.set_index(['Condition', 'Marker', 'Laser'], inplace=True)\n",
    "        for idx in stain_complete_df.index:\n",
    "            stain_setup_df.loc[idx] = stain_complete_df.loc[idx]\n",
    "    else:\n",
    "        stain_setup_df = stain_complete_df.copy()\n",
    "    stain_csv_setup_df = stain_setup_df.reset_index().sort_values(by='Condition')\n",
    "    stain_csv_setup_df = stain_csv_setup_df[['Condition', 'Marker', 'Laser', 'Cont_min', 'Cont_max', 'Gamma']]\n",
    "    stain_csv_setup_df.to_csv(setup_path, index=False)\n",
    "\n",
    "stain_df = stain_df.set_index('Condition')\n",
    "stain_complete_df = stain_complete_df.reset_index().set_index('Condition')\n",
    "stain_complete_df = stain_complete_df.loc[stain_df.index]\n",
    "stain_complete_df = stain_complete_df[['Marker', 'Laser', 'Color', 'Cont_min', 'Cont_max', 'Gamma']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c459fc7-429e-4592-b5eb-9cedb37c8fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display stain settings DataFrame\n",
    "stain_complete_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d61176-9e49-4c94-8f04-b4fa2a16219f",
   "metadata": {},
   "source": [
    "## IMAGE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1863a4-8080-41ed-bec3-1c0aa0a13686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt resolution to isotropic\n",
    "scale_factor=0.5\n",
    "#zoom_factors = [1.0, r_Y/r_Z, r_X/r_Z]  # ZYX order\n",
    "zoom_factors = [1.0, 1.0, 1.0] \n",
    "zoom_factors = [x * scale_factor for x in zoom_factors]\n",
    "print(zoom_factors)\n",
    "\n",
    "im_out = np.zeros((round(np.shape(im_in)[0] * (zoom_factors[0])),round(np.shape(im_in)[1] * (zoom_factors[1])),round(np.shape(im_in)[2] * (zoom_factors[2])),np.shape(im_in)[3]))\n",
    "\n",
    "# Compute zoom factors to get isotropic spacing (same as Y and X)\n",
    "\n",
    "# Resample image to isotropic spacing\n",
    "for c in range(im_in.shape[3]):\n",
    "    im_out[:, :, :, c] = zoom(im_in[:, :, :, c], zoom=zoom_factors, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b679eb17-77b9-4454-b807-e2a074f239d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and normalize image data for all channels\n",
    "#im_in = meta.get_image_data(\"ZYXC\", S=0, T=0)\n",
    "im_in=im_out.copy()\n",
    "im_in = ((im_in - im_in.min()) / (im_in.max() - im_in.min()) * 255).clip(0, 255).astype('uint8')\n",
    "im_original = im_in.copy()\n",
    "im_out = im_original.copy()\n",
    "im_trans = im_out.copy()\n",
    "\n",
    "# Plot histogram for each channel\n",
    "hist_plot(im_out, stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92171d9e-4dde-4f95-ba32-07d8cd4940e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise removal using median filter\n",
    "im_in = im_out.copy()\n",
    "for c in range(im_in.shape[3]):\n",
    "    im_out[:, :, :, c] = filters.median(im_in[:, :, :, c])\n",
    "im_denoised = im_out.copy()\n",
    "hist_plot(im_out, stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1216ae01-cee5-4d8a-8e9b-14069a0fc92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrast and gamma adjustment for each channel\n",
    "im_in = im_out.copy()\n",
    "for c, idx in enumerate(stain_complete_df.index):\n",
    "    im_out[:, :, :, c] = gamma_trans(im_in[:, :, :, c], stain_complete_df.loc[idx, 'Gamma'])\n",
    "    im_out[:, :, :, c] = contr_stretch(im_in[:, :, :, c], stain_complete_df.loc[idx, 'Cont_min'], stain_complete_df.loc[idx, 'Cont_max'])\n",
    "im_trans = im_out.copy()\n",
    "hist_plot(im_out, stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2464bd2-a092-4e4b-a903-a76f22969c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian filter for smoothing\n",
    "im_in = im_out.copy()\n",
    "for c in range(im_in.shape[3]):\n",
    "    im_out[:, :, :, c] = filters.gaussian(im_in[:, :, :, c], 0.5, preserve_range=True)\n",
    "im_filtered = im_out.copy()\n",
    "hist_plot(im_out, stain_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b7708-b305-4442-82d8-56378f7e31ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding using Otsu's method and small island removal\n",
    "im_in = im_out.copy()\n",
    "for c in range(im_in.shape[3]):\n",
    "    img = sitk.GetImageFromArray(im_in[:, :, :, c])\n",
    "    rescaler = sitk.RescaleIntensityImageFilter() \n",
    "    rescaler.SetOutputMinimum(0) \n",
    "    rescaler.SetOutputMaximum(255) \n",
    "    stretched = rescaler.Execute(img)\n",
    "    \n",
    "    th_filter = sitk.OtsuThresholdImageFilter()\n",
    "    seg = th_filter.Execute(stretched)\n",
    "    otsu_value = th_filter.GetThreshold() \n",
    "    print(otsu_value) \n",
    "    \n",
    "    window_size=nuclei_size \n",
    "    sauvola_value = threshold_sauvola(sitk.GetArrayFromImage(stretched), window_size=window_size)\n",
    "    \n",
    "    arrayseg = sitk.GetArrayFromImage(stretched) > np.ceil(0.3*sauvola_value+0.7*otsu_value) \n",
    "    im_out[:, :, :, c] = remove_small_islands(arrayseg, np.ceil(0.8*nuclei_size)) \n",
    "    \n",
    "im_threshold = im_out.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f6ca68-af3b-4ca6-8d08-cfe24a5444f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Thresholding using Otsu's method and small island removal\n",
    "# im_in = im_out.copy()\n",
    "# for c in range(im_in.shape[3]):\n",
    "#     th_filter = sitk.OtsuThresholdImageFilter()\n",
    "#     th_filter.SetInsideValue(0)\n",
    "#     th_filter.SetOutsideValue(200)\n",
    "#     seg = th_filter.Execute(sitk.GetImageFromArray(im_in[:, :, :, c]))\n",
    "#     arrayseg = sitk.GetArrayFromImage(seg)\n",
    "#     #filtered = remove_small_islands(arrayseg, 30)\n",
    "#     im_out[:, :, :, c] = arrayseg\n",
    "# im_threshold = im_out.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e22fad8-8e61-4701-be76-e79d6f67c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation of nuclei using watershed or StarDist\n",
    "if 'NUCLEI' in stain_df.index:\n",
    "    im_in = im_out.copy()\n",
    "    im_out = np.zeros_like(im_in, dtype=np.int32)\n",
    "    trig_stardist = False  # Set to True to use StarDist model\n",
    "    \n",
    "    for c in range(im_in.shape[3]):\n",
    "        if stain_complete_df.index[c] == 'NUCLEI':\n",
    "            if trig_stardist:\n",
    "                model = StarDist2D.from_pretrained('3D_versatile_fluo')\n",
    "                img_te = normalize(im_filtered[:, :, :, c], 1.0, 99.8)\n",
    "                im_out[:, :, :, c], _ = model.predict_instances(img_te)\n",
    "                im_mask = im_in[:, :, :, c] / np.max(im_in[:, :, :, c])\n",
    "                im_mask = filters.binary_erosion(im_mask, footprint=np.ones((2, 2, 2))).astype(im_mask.dtype)\n",
    "                im_positive = im_out[:, :, :, c] * im_mask\n",
    "            else:\n",
    "                distance = ndi.distance_transform_edt(im_in[:, :, :, c],sampling=[r_Z,r_Y,r_X])\n",
    "                coords = peak_local_max(distance, footprint=np.ones((3, 3, 3)), labels=im_in[:, :, :, c].astype(np.int32))\n",
    "                mask = np.zeros(distance.shape, dtype=bool)\n",
    "                mask[tuple(coords.T)] = True\n",
    "                markers, _ = label(mask)\n",
    "                transl = watershed(-distance, markers, mask=im_in[:, :, :, c])\n",
    "                #im_out[:, :, :, c] = merge_touching_labels(transl)\n",
    "                im_out[:, :, :, c] = transl.copy()\n",
    "            \n",
    "            cm_rand = np.random.rand(int(np.max(im_out[:, :, :, c])), 3)\n",
    "            cm_rand[0, :] = [0.0, 0.0, 0.0]\n",
    "            colormaps_rand = Colormap(cm_rand)\n",
    "            im_nuclei_segmented = im_out[:, :, :, c].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b740f045-770f-4c81-99c1-c96e4ab0134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation of cytoplasm\n",
    "if ('NUCLEI' in stain_df.index)|('CYTOPLASM' in stain_df.index):\n",
    "    im_out = np.zeros_like(im_in[:,:,:,0], dtype=np.int32)\n",
    "    trig_stardist = False  # Set to True to use StarDist model\n",
    "    im_final=im_in.copy()\n",
    "    \n",
    "    for c in range(im_in.shape[3]):\n",
    "        if stain_complete_df.index[c] == 'CYTOPLASM':\n",
    "            distance = ndi.distance_transform_edt(im_final[:, :, :, c],sampling=[r_Z,r_Y,r_X])\n",
    "            coords = peak_local_max(distance, footprint=ball(5), labels=im_final[:, :, :, c].astype(bool))\n",
    "            mask = np.zeros(distance.shape, dtype=bool)\n",
    "            mask[tuple(coords.T)] = True\n",
    "            markers, _ = label(mask)\n",
    "            transl = watershed(-distance, im_nuclei_segmented, mask=im_final[:, :, :, c])\n",
    "            im_out = transl\n",
    "    \n",
    "    if 'CYTOPLASM' not in stain_df.index:\n",
    "        cyto_factor=2.0\n",
    "        im_out=grow_labels(im_nuclei_segmented, cyto_factor)\n",
    "        im_final = np.concatenate((im_in, np.expand_dims(im_out, axis=-1)), axis=-1)\n",
    "        stain_df.loc['CYTOPLASM']=['', '', '']\n",
    "        stain_complete_df.loc['CYTOPLASM']=['', '', '', '', '', '']\n",
    "        \n",
    "    im_cyto_segmented = im_out.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcc09a6-7acd-4e89-94ef-341b69728685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign segmented nuclei labels to other channels (cell assignment)\n",
    "if ('NUCLEI' in stain_df.index)|('CYTOPLASM' in stain_df.index):\n",
    "    im_assigned = np.zeros_like(im_final, dtype=np.int32)\n",
    "    for c in range(im_final.shape[3]):\n",
    "        if (stain_df.index[c] != 'NUCLEI') & (stain_df.index[c] != 'CYTOPLASM'):\n",
    "            im_assigned[:, :, :, c] = im_threshold[:, :, :, c] * im_cyto_segmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435cff7e-fe98-48d5-b32a-bbe0fabd7929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize original, denoised, filtered, corrected, thresholded, assigned, and segmented images\n",
    "viewer_0 = napari.Viewer()\n",
    "\n",
    "for c in range(im_in.shape[3]):\n",
    "    idx = stain_complete_df.index[c]\n",
    "    marker = stain_complete_df.loc[idx, 'Marker']\n",
    "    color = stain_complete_df['Color'].iloc[c]\n",
    "    viewer_0.add_image(im_original[:, :, :, c], name=f'ORIGINAL {idx} ({marker})', colormap=color, blending='additive')\n",
    "    viewer_0.add_image(im_denoised[:, :, :, c], name=f'DENOISED {idx} ({marker})', colormap=color, blending='additive')\n",
    "    viewer_0.add_image(im_filtered[:, :, :, c], name=f'FILTERED {idx} ({marker})', colormap=color, blending='additive')\n",
    "    viewer_0.add_image(im_trans[:, :, :, c], name=f'CORRECTED {idx} ({marker})', colormap=color, blending='additive')\n",
    "    viewer_0.add_image(im_threshold[:, :, :, c].astype('uint8'), name=f'THRESHOLD {idx} ({marker})', contrast_limits=[0, 1], colormap=color, blending='additive')    \n",
    "viewer_0.scale_bar.visible = True\n",
    "viewer_0.scale_bar.unit = 'um'\n",
    "\n",
    "if ('NUCLEI' in stain_df.index)|('CYTOPLASM' in stain_df.index):\n",
    "    viewer_1 = napari.Viewer()\n",
    "    \n",
    "    for c in range(im_final.shape[3]):\n",
    "        idx = stain_complete_df.index[c]\n",
    "        marker = stain_complete_df.loc[idx, 'Marker']\n",
    "        if stain_df.index[c] == 'NUCLEI':\n",
    "            viewer_1.add_image(im_nuclei_segmented.astype('uint8'), name=f'SEGMENTED {idx} ({marker})', colormap=colormaps_rand, contrast_limits=[0, np.max(im_nuclei_segmented)], blending='additive')\n",
    "        if stain_df.index[c] == 'CYTOPLASM':\n",
    "            viewer_1.add_image(im_cyto_segmented.astype('uint8'), name=f'{idx} ({marker})', colormap=colormaps_rand, contrast_limits=[0, np.max(im_nuclei_segmented)], blending='additive')\n",
    "        if (stain_df.index[c] != 'NUCLEI') & (stain_df.index[c] != 'CYTOPLASM'):\n",
    "            viewer_1.add_image(im_assigned[:, :, :, c].astype('uint8'), name=f'ASSIGNED {idx} ({marker})', colormap=colormaps_rand, contrast_limits=[0, np.max(im_nuclei_segmented)], blending='additive')\n",
    "    viewer_1.scale_bar.visible = True\n",
    "    viewer_1.scale_bar.unit = 'um'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aab820-7f42-4903-8132-d83edc9479d4",
   "metadata": {},
   "source": [
    "## QUANTIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf431e1f-94b5-4e66-aef5-accb0297f5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel=True\n",
    "\n",
    "# Quantify nuclei and cell properties\n",
    "im_mask = im_nuclei_segmented > 0\n",
    "labels_dict = {}\n",
    "c_nuc = stain_complete_df.index.get_loc('NUCLEI')\n",
    "nuc_marker = stain_complete_df['Marker'][c_nuc]\n",
    "nuc_positions = []\n",
    "nuc_sizes=[]\n",
    "c_cyto = stain_complete_df.index.get_loc('CYTOPLASM')\n",
    "cyto_marker = stain_complete_df['Marker'][c_cyto]\n",
    "cyto_positions = []\n",
    "cyto_sizes=[]\n",
    "\n",
    "for n in range(1, int(np.max(im_nuclei_segmented))):\n",
    "    zN, yN, xN = np.where(im_nuclei_segmented == n)\n",
    "    nuc_positions.append((np.mean(xN * r_X / zoom_factors[2]), np.mean(yN * r_Y / zoom_factors[1]), np.mean(zN * r_Z / zoom_factors[0])))\n",
    "    nuc_sizes.append(xN.size * r_X * r_Y * r_Z / np.prod(zoom_factors))\n",
    "    zC, yC, xC = np.where(im_cyto_segmented == n)\n",
    "    cyto_positions.append((np.mean(xC * r_X / zoom_factors[2]), np.mean(yC * r_Y / zoom_factors[1]), np.mean(zC * r_Z / zoom_factors[0])))\n",
    "    cyto_sizes.append(xC.size * r_X * r_Y * r_Z / np.prod(zoom_factors))\n",
    "\n",
    "labels_dict[stain_complete_df['Marker'].iloc[c_nuc]] = [\n",
    "    stain_complete_df.index[c_nuc],\n",
    "    stain_complete_df['Laser'][c_nuc],\n",
    "    stain_complete_df['Color'][c_nuc],\n",
    "    int(np.max(im_nuclei_segmented)),\n",
    "    (),\n",
    "    tuple(nuc_positions),\n",
    "    (), \n",
    "    tuple(nuc_sizes), \n",
    "    (), \n",
    "    ()\n",
    "]\n",
    "labels_dict[stain_complete_df['Marker'].iloc[c_cyto]] = [\n",
    "    stain_complete_df.index[c_cyto],\n",
    "    stain_complete_df['Laser'][c_cyto],\n",
    "    stain_complete_df['Color'][c_cyto],\n",
    "    int(np.max(im_cyto_segmented)),\n",
    "    (),\n",
    "    (),\n",
    "    tuple(cyto_positions),\n",
    "    (),\n",
    "    tuple(cyto_sizes),\n",
    "    ()\n",
    "]\n",
    "\n",
    "for c in range(im_original.shape[3]):\n",
    "    if (c != c_nuc)&(c != c_cyto):\n",
    "        m_nuc_positions = []\n",
    "        m_nuc_sizes=[]\n",
    "        marker_sizes=[]\n",
    "        m_cyto_positions = []\n",
    "        m_cyto_sizes=[]\n",
    "        marker = stain_complete_df['Marker'][c]\n",
    "        for n in np.unique(im_assigned[1:, :, :, c])[1:]:\n",
    "            zN, yN, xN = np.where(im_nuclei_segmented == n)\n",
    "            m_nuc_positions.append((np.mean(xN * r_X / zoom_factors[2]), np.mean(yN * r_Y / zoom_factors[1]), np.mean(zN * r_Z / zoom_factors[0])))\n",
    "            m_nuc_sizes.append(xN.size * r_X * r_Y * r_Z / np.prod(zoom_factors))\n",
    "\n",
    "            zC, yC, xC = np.where(im_cyto_segmented == n)\n",
    "            m_cyto_positions.append((np.mean(xC * r_X / zoom_factors[2]), np.mean(yC * r_Y / zoom_factors[1]), np.mean(zC * r_Z / zoom_factors[0])))\n",
    "            m_cyto_sizes.append(xC.size * r_X * r_Y * r_Z / np.prod(zoom_factors))\n",
    "            \n",
    "            zM, yM, xM = np.where(im_assigned[:,:,:,c] == n)\n",
    "            marker_sizes.append(xM.size * r_X * r_Y * r_Z / np.prod(zoom_factors))\n",
    "            \n",
    "        labels_dict[stain_complete_df['Marker'].iloc[c]] = [\n",
    "            stain_complete_df.index[c],\n",
    "            stain_complete_df['Laser'][c],\n",
    "            stain_complete_df['Color'][c],\n",
    "            len(np.unique(im_assigned[1:, :, :, c])[1:]),\n",
    "            tuple(np.unique(im_assigned[1:, :, :, c])[1:]),\n",
    "            tuple(m_nuc_positions),\n",
    "            tuple(m_cyto_positions), \n",
    "            tuple(m_nuc_sizes), \n",
    "            tuple(m_cyto_sizes), \n",
    "            tuple(marker_sizes)\n",
    "        ]\n",
    "\n",
    "if multilabel:\n",
    "    # All combinations of channels (2 or more)\n",
    "    layers_n = list(range(im_final.shape[3]))\n",
    "    layers_n.remove(c_nuc)\n",
    "    layers_n.remove(c_cyto)\n",
    "    all_combinations = []\n",
    "    for k in range(2, len(layers_n) + 1):\n",
    "        all_combinations.extend(combinations(layers_n, k))\n",
    "    \n",
    "    for comb in all_combinations:\n",
    "        combo_labels=list(np.unique(im_assigned[1:, :, :, comb[0]])[1:])\n",
    "        for c in comb[1:]:\n",
    "            list2_set = set(list(np.unique(im_assigned[1:, :, :, c])[1:]))\n",
    "            combo_labels = [x for x in combo_labels if x in list2_set]\n",
    "\n",
    "        combo_marker=[stain_complete_df['Marker'].iloc[idx] for idx in comb]\n",
    "        combo_condition=[stain_complete_df.index[idx] for idx in comb]\n",
    "\n",
    "        labels_dict[tuple(combo_marker)] = [\n",
    "            tuple(combo_condition),\n",
    "            (),\n",
    "            (),\n",
    "            len(combo_labels),\n",
    "            tuple(combo_labels),\n",
    "            tuple(nuc_positions[i-1] for i in combo_labels),\n",
    "            tuple(cyto_positions[i-1] for i in combo_labels),\n",
    "            tuple(nuc_sizes[i-1] for i in combo_labels),\n",
    "            tuple(cyto_sizes[i-1] for i in combo_labels),\n",
    "            ()\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c5021b-f096-45e7-bd06-c5681ac18b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for quantification results and truncate long values for display\n",
    "labels_df = pd.DataFrame.from_dict(labels_dict, orient='index', columns=['Condition', 'Laser', 'Color', 'Number', 'Shared labels', 'Mean nuclei positions [um]', 'Mean cytoplasm positions [um]', 'Nuclei size [um3]', 'Cytoplasm size [um3]', 'Marker size [um3]'])\n",
    "labels_df.index.name = 'Combination'\n",
    "truncated_df = labels_df.copy()\n",
    "for col in [\"Shared labels\", \"Mean nuclei positions [um]\", \"Mean cytoplasm positions [um]\", \"Nuclei size [um3]\", \"Cytoplasm size [um3]\", \"Marker size [um3]\"]:\n",
    "    truncated_df[col] = truncated_df[col].apply(lambda x: truncate_cell(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51300a4f-a601-48a0-985c-eac8c68014b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display quantification DataFrame\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db857798-416e-4885-a89e-ec09e95003d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary statistics for nuclei and cell populations\n",
    "print('TOT CELLS =', labels_df['Number'][stain_complete_df['Marker']['NUCLEI']])\n",
    "print(\" \")\n",
    "for i, marker in enumerate(labels_df.index):\n",
    "    if (labels_df['Condition'][i] != 'NUCLEI') & (labels_df['Condition'][i] != 'CYTOPLASM') & (labels_df['Condition'][i] != 'NUCLEI + CYTOPLASM'):\n",
    "        print(f\" PERC {labels_df['Condition'][i]} ({marker}) = {100.0 * labels_df['Number'][i] / labels_df['Number'][0]} %\")\n",
    "print('_' * 80)\n",
    "print('MEAN SIZE NUCLEI =', np.mean(labels_df['Nuclei size [um3]'][stain_complete_df['Marker']['NUCLEI']]), 'um3')\n",
    "if 'CYTOPLASM' in stain_df.index:\n",
    "    print('MEAN SIZE CYTOPLASM =', np.mean(labels_df['Cytoplasm size [um3]'][stain_complete_df['Marker']['CYTOPLASM']]), 'um3')\n",
    "for i, marker in enumerate(labels_df.index):\n",
    "    if (labels_df['Condition'][i] != 'NUCLEI') & (labels_df['Condition'][i] != 'CYTOPLASM') & (labels_df['Condition'][i] != 'NUCLEI + CYTOPLASM'):\n",
    "        print(\" \")\n",
    "        print(f\" MEAN SIZE NUCLEI {labels_df['Condition'][i]} ({marker}) = {np.mean(labels_df['Nuclei size [um3]'][i])} um3\")\n",
    "        if 'CYTOPLASM' in stain_df.index:\n",
    "            print(f\" MEAN SIZE CYTOPLASM {labels_df['Condition'][i]} ({marker}) = {np.mean(labels_df['Cytoplasm size [um3]'][i])} um3\")\n",
    "print('_' * 80)\n",
    "for i, marker in enumerate(labels_df.index):\n",
    "    if (labels_df['Marker size [um3]'][i]!=()):\n",
    "        print(f\"MEAN SIZE {labels_df['Condition'][i]} ({marker}) = {np.mean(labels_df['Marker size [um3]'][i])} um3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8333a47d-9919-4bfe-ae8b-41706aec1673",
   "metadata": {},
   "source": [
    "## Evaluate cell distribution in the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef35bbdd-693f-45c5-8654-fd6c387a19e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot spatial distribution of nuclei and cells\n",
    "fig, axs = plt.subplots(3, 1, figsize=(15, 15))\n",
    "for i, marker in enumerate(labels_df.index):   \n",
    "    xcoor = [t[0] for t in labels_df['Mean cytoplasm positions [um]'][i]]\n",
    "    ycoor = [t[1] for t in labels_df['Mean cytoplasm positions [um]'][i]]\n",
    "    zcoor = [t[2] for t in labels_df['Mean cytoplasm positions [um]'][i]] \n",
    "    xcount, xbins = np.histogram(xcoor, range=(0, im_original.shape[2] * r_X /zoom_factors[2]), bins=30)\n",
    "    ycount, ybins = np.histogram(ycoor, range=(0, im_original.shape[1] * r_Y /zoom_factors[1]), bins=30)\n",
    "    zcount, zbins = np.histogram(zcoor, range=(0, im_original.shape[0] * r_Z /zoom_factors[0]), bins=30)\n",
    "    xbin_centers = (xbins[:-1] + xbins[1:]) / 2\n",
    "    ybin_centers = (ybins[:-1] + ybins[1:]) / 2\n",
    "    zbin_centers = (zbins[:-1] + zbins[1:]) / 2\n",
    "    if (np.size(marker)==1):\n",
    "        color = stain_df.loc[str(labels_df['Condition'][i])]['Color']\n",
    "        if color == '':\n",
    "            color='BLUE'\n",
    "        if (labels_df['Condition'][i]!='NUCLEI'):\n",
    "            axs[0].plot(xbin_centers,xcount,label=str(labels_df['Condition'][i]),color=color)\n",
    "            axs[1].plot(ybin_centers,ycount,label=str(labels_df['Condition'][i]),color=color)\n",
    "            axs[2].plot(zbin_centers,zcount,label=str(labels_df['Condition'][i]),color=color)\n",
    "    else:\n",
    "        rgb_list=[]\n",
    "        for k in range(np.size(marker)):\n",
    "            if stain_df.loc[(labels_df['Condition'][i][k])]['Color']!='WHITE':\n",
    "                rgb_list.append(stain_df.loc[(labels_df['Condition'][i][k])]['Color'])\n",
    "            else:\n",
    "                rgb_list.append('GRAY')\n",
    "\n",
    "        colors_rgb = [to_rgb(name) for name in rgb_list]\n",
    "\n",
    "        r_total, g_total, b_total = 0.0, 0.0, 0.0\n",
    "\n",
    "        for r, g, b in colors_rgb:\n",
    "            r_total += r\n",
    "            g_total += g\n",
    "            b_total += b\n",
    "        \n",
    "        r_final = min(r_total, 1.0)\n",
    "        g_final = min(g_total, 1.0)\n",
    "        b_final = min(b_total, 1.0)\n",
    "    \n",
    "        final_rgb = (r_final, g_final, b_final)\n",
    "        \n",
    "        axs[0].plot(xbin_centers,xcount,label=str(labels_df['Condition'][i]),linestyle=(0, (2, np.size(marker)-1)), color=final_rgb)\n",
    "        axs[1].plot(ybin_centers,ycount,label=str(labels_df['Condition'][i]),linestyle=(0, (2, np.size(marker)-1)), color=final_rgb)\n",
    "        axs[2].plot(zbin_centers,zcount,label=str(labels_df['Condition'][i]),linestyle=(0, (2, np.size(marker)-1)), color=final_rgb)\n",
    "        \n",
    "axs[0].set_title('NUCLEI X DISTRIBUTION')\n",
    "axs[0].set_xlabel('[μm]')\n",
    "axs[0].legend(loc='upper right')\n",
    "axs[0].set_facecolor('black')\n",
    "axs[1].set_title('NUCLEI Y DISTRIBUTION')\n",
    "axs[1].set_xlabel('[μm]')\n",
    "axs[1].legend(loc='upper right')\n",
    "axs[1].set_facecolor('black')\n",
    "axs[2].set_title('NUCLEI Z DISTRIBUTION')\n",
    "axs[2].set_xlabel('[μm]')\n",
    "axs[2].legend(loc='upper right')\n",
    "axs[2].set_facecolor('black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d02b15-c10b-4b95-8882-ff6769eadbdb",
   "metadata": {},
   "source": [
    "## Evaluate cell size distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a02a90b-0bb0-46f7-875d-e438714bc22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot size distribution of nuclei and cells\n",
    "fig, axs = plt.subplots(2, 1, figsize=(15, 10))\n",
    "nuclei_max_size = max(x for t in labels_df['Nuclei size [um3]'] for x in t)\n",
    "cytoplasm_max_size = max(x for t in labels_df['Cytoplasm size [um3]'] for x in t)\n",
    "for i, marker in enumerate(labels_df.index):\n",
    "    nuclei_sizes = list(labels_df['Nuclei size [um3]'][i])\n",
    "    cell_sizes = list(labels_df['Cytoplasm size [um3]'][i])\n",
    "    if np.size(marker)==1:\n",
    "        if stain_df.loc[(labels_df['Condition'][i])]['Color']=='':\n",
    "            color = 'BLUE'\n",
    "        else:\n",
    "            if stain_df.loc[(labels_df['Condition'][i])]['Color']!='WHITE':\n",
    "                color = stain_df.loc[str(labels_df['Condition'][i])]['Color']\n",
    "            else:\n",
    "                color = 'GRAY'\n",
    "        #color = stain_df.loc[str(labels_df['Condition'][i])]['Color']\n",
    "        #axs[0].hist(nuclei_sizes, range=(0, nuclei_max_size), bins=30, label=str(labels_df['Condition'][i]), alpha=1/len(labels_df), color=color)\n",
    "    else:\n",
    "        rgb_list=[]\n",
    "        for k in range(np.size(marker)):\n",
    "            if stain_df.loc[(labels_df['Condition'][i][k])]['Color']!='WHITE':\n",
    "                rgb_list.append(stain_df.loc[(labels_df['Condition'][i][k])]['Color'])\n",
    "            else:\n",
    "                rgb_list.append('GRAY')\n",
    "\n",
    "        colors_rgb = [to_rgb(name) for name in rgb_list]\n",
    "\n",
    "        r_total, g_total, b_total = 0.0, 0.0, 0.0\n",
    "\n",
    "        for r, g, b in colors_rgb:\n",
    "            r_total += r\n",
    "            g_total += g\n",
    "            b_total += b\n",
    "        \n",
    "        r_final = min(r_total, 1.0)\n",
    "        g_final = min(g_total, 1.0)\n",
    "        b_final = min(b_total, 1.0)\n",
    "    \n",
    "        color = (r_final, g_final, b_final)\n",
    "        \n",
    "    if labels_df['Condition'][i] != 'CYTOPLASM':    \n",
    "        axs[0].hist(nuclei_sizes, range=(0, nuclei_max_size), bins=30, label=str(labels_df['Condition'][i]), alpha=1/len(labels_df), color=color)\n",
    "    if labels_df['Condition'][i] != 'NUCLEI':\n",
    "        axs[1].hist(cell_sizes, range=(0, cytoplasm_max_size), bins=30, label=str(labels_df['Condition'][i]), alpha=1/(len(labels_df)-1), color=color)\n",
    "axs[0].set_title('NUCLEI SIZE DISTRIBUTION')\n",
    "axs[0].set_xlabel('[μm3]')\n",
    "axs[0].legend(loc='upper right')\n",
    "axs[1].set_title('CELL SIZE DISTRIBUTION')\n",
    "axs[1].set_xlabel('[μm3]')\n",
    "axs[1].legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c710e23-4fc2-4dbe-8999-298bcff0190d",
   "metadata": {},
   "source": [
    "## CREATE .VTK VOLUME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6af6f0-3b6b-4514-bfc4-6f1c925af8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamond = ndi.generate_binary_structure(rank=3, connectivity=1)\n",
    "blocks_nuclei=pv.MultiBlock()\n",
    "blocks_cyto=pv.MultiBlock()\n",
    "nuclei_stl_old=mr.Mesh()\n",
    "cyto_stl_old=mr.Mesh()\n",
    "\n",
    "nuc_vol=np.zeros((np.max(im_nuclei_segmented)+1,))\n",
    "nuc_coord=np.zeros((np.max(im_nuclei_segmented)+1,3))\n",
    "nuc_list=np.zeros((np.max(im_nuclei_segmented)+1,))\n",
    "\n",
    "cyto_vol=np.zeros((np.max(im_nuclei_segmented)+1,))\n",
    "cyto_coord=np.zeros((np.max(im_nuclei_segmented)+1,3))\n",
    "cyto_list=np.zeros((np.max(im_nuclei_segmented)+1,))\n",
    "\n",
    "#agg_id=1\n",
    "\n",
    "k=0\n",
    "for j in range(1,np.max(im_nuclei_segmented)+1):\n",
    "    clear_output(wait=True)\n",
    "    print('NUCLEI ' + str(j) + ' / ' + str(np.max(im_nuclei_segmented)))\n",
    "    simpleVolume = mrn.simpleVolumeFrom3Darray(np.float32(im_nuclei_segmented==j))\n",
    "    floatGrid = mr.simpleVolumeToDenseGrid(simpleVolume)\n",
    "    mesh_stl = mr.gridToMesh(floatGrid , mr.Vector3f(1.0,1.0,1.0), 0.5)    \n",
    "    mr.saveMesh(mesh_stl, \"part_nuclei_mesh.stl\" )\n",
    "    \n",
    "    mesh_nuclei = pv.read(\"part_nuclei_mesh.stl\")\n",
    "    if mesh_nuclei.volume>0.0:\n",
    "        mesh_nuclei.decimate(target_reduction=0.8, inplace=True)\n",
    "\n",
    "        nuc_vol[k]=mesh_nuclei.volume\n",
    "        nuc_coord[k]=mesh_nuclei.center\n",
    "        nuc_list[k]=j\n",
    "\n",
    "        mesh_nuclei.cell_data['ID']=np.ones(mesh_nuclei.n_cells)*(k+1)\n",
    "        mesh_nuclei.cell_data['nuclei_vol']=np.ones(mesh_nuclei.n_cells)*nuc_vol[k] * r_X * r_Y * r_Z / np.prod(zoom_factors)\n",
    "        mesh_nuclei.cell_data['nuclei_Z']=np.ones(mesh_nuclei.n_cells)*nuc_coord[k][0] * r_Z /zoom_factors[0]\n",
    "        mesh_nuclei.cell_data['nuclei_Y']=np.ones(mesh_nuclei.n_cells)*nuc_coord[k][1] * r_Y /zoom_factors[1]\n",
    "        mesh_nuclei.cell_data['nuclei_X']=np.ones(mesh_nuclei.n_cells)*nuc_coord[k][2] * r_X /zoom_factors[2]\n",
    "        \n",
    "        blocks_nuclei.append(mesh_nuclei)\n",
    "        k=k+1\n",
    "\n",
    "\n",
    "    simpleVolume = mrn.simpleVolumeFrom3Darray(np.float32(im_cyto_segmented==j))\n",
    "    floatGrid = mr.simpleVolumeToDenseGrid(simpleVolume)\n",
    "    mesh_stl = mr.gridToMesh(floatGrid , mr.Vector3f(1.0,1.0,1.0), 0.5)    \n",
    "    mr.saveMesh(mesh_stl, \"part_cyto_mesh.stl\" )\n",
    "    \n",
    "    mesh_cyto = pv.read(\"part_cyto_mesh.stl\")\n",
    "    if mesh_cyto.volume>0.0:\n",
    "        mesh_cyto.decimate(target_reduction=0.8, inplace=True)\n",
    "\n",
    "        cyto_vol[k]=mesh_cyto.volume\n",
    "        cyto_coord[k]=mesh_cyto.center\n",
    "        cyto_list[k]=j\n",
    "\n",
    "        mesh_cyto.cell_data['ID']=np.ones(mesh_cyto.n_cells)*(k+1)\n",
    "        mesh_cyto.cell_data['cyto_vol']=np.ones(mesh_cyto.n_cells)*cyto_vol[k] * r_X * r_Y * r_Z / np.prod(zoom_factors)\n",
    "        mesh_cyto.cell_data['cyto_Z']=np.ones(mesh_cyto.n_cells)*cyto_coord[k][0] * r_Z /zoom_factors[0]\n",
    "        mesh_cyto.cell_data['cyto_Y']=np.ones(mesh_cyto.n_cells)*cyto_coord[k][1] * r_Y /zoom_factors[1]\n",
    "        mesh_cyto.cell_data['cyto_X']=np.ones(mesh_cyto.n_cells)*cyto_coord[k][2] * r_X /zoom_factors[2]\n",
    "        for i, marker in enumerate(labels_df.index):\n",
    "            if (labels_df['Condition'][i]!='NUCLEI') & (labels_df['Condition'][i]!='CYTOPLASM') & (np.size(marker)==1):\n",
    "                if j in list(labels_df['Shared labels'][i]):\n",
    "                    mesh_cyto.cell_data[marker+'_abs']=np.ones(mesh_cyto.n_cells)*(labels_df['Marker size [um3]'][i][list(labels_df['Shared labels'][i]).index(j)])\n",
    "                    mesh_cyto.cell_data[marker+'_rel']=np.ones(mesh_cyto.n_cells)*((labels_df['Marker size [um3]'][i][list(labels_df['Shared labels'][i]).index(j)])/(cyto_vol[k] * r_X * r_Y * r_Z / np.prod(zoom_factors)))\n",
    "                else:\n",
    "                    mesh_cyto.cell_data[marker+'_abs']=np.ones(mesh_cyto.n_cells)*(0.0)\n",
    "                    mesh_cyto.cell_data[marker+'_rel']=np.ones(mesh_cyto.n_cells)*(0.0)\n",
    "                # ass_channel_2=globals()[channel+'mag']*(NUCLEIlab==val)/np.max(globals()[channel+'mag'])\n",
    "                # mesh_cyto.cell_data[channel+'_perc_rel']=np.ones(mesh_nuclei.n_cells)*(np.sum(ass_channel_2)/np.sum(NUCLEIlab==val))\n",
    "        \n",
    "        blocks_cyto.append(mesh_cyto)\n",
    "        #k=k+1\n",
    "\n",
    "    #j=j-1\n",
    "\n",
    "# nuc_vol=nuc_vol[0:k-1]\n",
    "# nuc_coord=nuc_coord[0:k-1]\n",
    "# nuc_list=nuc_list[0:k-1]\n",
    "blocks_nuclei.extract_geometry().save(Path(input_file).stem+'_NUCLEI_labelled.vtk')\n",
    "blocks_cyto.extract_geometry().save(Path(input_file).stem+'_CYTOPLASM_labelled.vtk')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2bcca6-f1df-432c-b916-278fe84b44de",
   "metadata": {},
   "source": [
    "## and .STL for markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4966a994-8ef8-4b37-af9b-74a8e21452d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c, marker in enumerate(stain_complete_df.index):\n",
    "    if (stain_complete_df.index[c] != 'NUCLEI') & (stain_complete_df.index[c] != 'CYTOPLASM'):\n",
    "        simpleVolume = mrn.simpleVolumeFrom3Darray(np.float32(im_assigned[:, :, :, c]>0))\n",
    "        floatGrid = mr.simpleVolumeToDenseGrid(simpleVolume)\n",
    "        mesh_stl = mr.gridToMesh(floatGrid , mr.Vector3f(1.0,1.0,1.0), 0.5)    \n",
    "        mr.saveMesh(mesh_stl,Path(input_file).stem + \"_\" + marker + \"_mesh.stl\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a070bde8-0355-4bec-a563-1f7740d942a2",
   "metadata": {},
   "source": [
    "### Create a complete report XSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c4282f-7756-4c49-8a50-fb7d69eb4ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export quantification results to Excel file\n",
    "with pd.ExcelWriter(Path(input_file).stem + '_nuclei_segmentation.xlsx', engine='xlsxwriter') as writer:\n",
    "    stain_complete_df.to_excel(writer, sheet_name='Staining', index=True)\n",
    "    xlsx_dict = {}\n",
    "    columns = ['X position [um]', 'Y position [um]', 'Z position [um]', 'Nuclei size [um3]']\n",
    "    for i, marker in enumerate(labels_df.index):\n",
    "        if (labels_df['Condition'][i] != 'NUCLEI') & (labels_df['Condition'][i] != 'CYTOPLASM') & (np.size(labels_df['Condition'][i])==1):\n",
    "            columns.append(f\"{marker} ({labels_df['Condition'][i]})\")\n",
    "            columns.append(f\"{labels_df['Condition'][i]} marker size [um3]\")\n",
    "    for k in range(1, int(labels_df['Number'][0])):\n",
    "        row = [labels_df['Mean nuclei positions [um]'][0][k-1], labels_df['Nuclei size [um3]'][0][k-1]]\n",
    "        row = [row[0][0], row[0][1], row[0][2], row[1]]\n",
    "        for i, marker in enumerate(labels_df.index):\n",
    "            if (labels_df['Condition'][i] != 'NUCLEI') & (labels_df['Condition'][i] != 'CYTOPLASM') & (np.size(labels_df['Condition'][i])==1):\n",
    "                shared = labels_df['Shared labels'][i]\n",
    "                if k in shared:\n",
    "                    idx = list(shared).index(k)\n",
    "                    row.append(marker)\n",
    "                    row.append(labels_df['Marker size [um3]'][marker][idx])\n",
    "                else:\n",
    "                    row.extend(['', ''])\n",
    "        xlsx_dict[k] = row\n",
    "    cell_df = pd.DataFrame.from_dict(xlsx_dict, orient='index', columns=columns)\n",
    "    cell_df.to_excel(writer, sheet_name='NUCLEI', index=True)  \n",
    "    xlsx_dict = {}\n",
    "    columns = ['X position [um]', 'Y position [um]', 'Z position [um]', 'Cytoplasm size [um3]']\n",
    "    for i, marker in enumerate(labels_df.index):\n",
    "        if (labels_df['Condition'][i] != 'NUCLEI') & (labels_df['Condition'][i] != 'CYTOPLASM') & (np.size(labels_df['Condition'][i])==1):\n",
    "            columns.append(f\"{marker} ({labels_df['Condition'][i]})\")\n",
    "            columns.append(f\"{labels_df['Condition'][i]} marker size [um3]\")\n",
    "    for k in range(1, int(labels_df['Number'][0])):\n",
    "        row = [labels_df['Mean cytoplasm positions [um]'][1][k-1], labels_df['Cytoplasm size [um3]'][1][k-1]]\n",
    "        row = [row[0][0], row[0][1], row[0][2], row[1]]\n",
    "        for i, marker in enumerate(labels_df.index):\n",
    "            if (labels_df['Condition'][i] != 'NUCLEI') & (labels_df['Condition'][i] != 'CYTOPLASM') & (np.size(labels_df['Condition'][i])==1):\n",
    "                shared = labels_df['Shared labels'][i]\n",
    "                if k in shared:\n",
    "                    idx = list(shared).index(k)\n",
    "                    row.append(marker)\n",
    "                    row.append(labels_df['Marker size [um3]'][marker][idx])\n",
    "                else:\n",
    "                    row.extend(['', ''])\n",
    "        xlsx_dict[k] = row\n",
    "    cell_df = pd.DataFrame.from_dict(xlsx_dict, orient='index', columns=columns)\n",
    "    cell_df.to_excel(writer, sheet_name='CYTOPLASM', index=True)\n",
    "    resume_df = labels_df.drop(columns=['Shared labels', 'Mean nuclei positions [um]', 'Mean cytoplasm positions [um]', 'Nuclei size [um3]', 'Cytoplasm size [um3]', 'Marker size [um3]'])\n",
    "    resume_df['Laser'] = [\n",
    "        labels_df['Laser'][t] if (np.size(labels_df['Condition'][t])==1) else ''\n",
    "        for t in range(len(labels_df))\n",
    "    ]\n",
    "    resume_df['Color'] = [\n",
    "        labels_df['Color'][t] if (np.size(labels_df['Condition'][t])==1) else ''\n",
    "        for t in range(len(labels_df))\n",
    "    ]\n",
    "    resume_df['%'] = [\n",
    "        100.0 * labels_df['Number'][t] / labels_df['Number'][0] if labels_df['Condition'][t] != 'NUCLEI' else ''\n",
    "        for t in range(len(labels_df))\n",
    "    ]\n",
    "    resume_df['Mean nuclei size [um3]'] = [np.mean(t) for t in labels_df['Nuclei size [um3]']]\n",
    "    resume_df['Mean cytoplasm size [um3]'] = [np.mean(t) for t in labels_df['Cytoplasm size [um3]']]\n",
    "    resume_df['Mean marker size [um3]'] = [\n",
    "        np.mean(val) if (labels_df['Condition'][t] != 'NUCLEI') & (labels_df['Condition'][t] != 'CYTOPLASM') & (np.size(labels_df['Condition'][t])==1) else ''\n",
    "        for t, val in enumerate(labels_df['Marker size [um3]'])\n",
    "    ]\n",
    "    resume_df.to_excel(writer, sheet_name='RECAP', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2bf51e-260b-4374-934c-24464188ef5d",
   "metadata": {},
   "source": [
    "# CREATE .inp FOR FINITE ELEMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0136c70d-e8e3-48be-a6fe-609ed4e4ae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleVolume = mrn.simpleVolumeFrom3Darray(np.float32(im_nuclei_segmented))\n",
    "floatGrid = mr.simpleVolumeToDenseGrid(simpleVolume)\n",
    "mesh_stl = mr.gridToMesh(floatGrid , mr.Vector3f(1.0,1.0,1.0), 0.5)\n",
    "\n",
    "outVerts = mrn.getNumpyVerts(mesh_stl)\n",
    "#print(outVerts)\n",
    "\n",
    "outFaces = mrn.getNumpyFaces(mesh_stl.topology)\n",
    "\n",
    "tet = tetgen.TetGen(outVerts,outFaces)\n",
    "nodes,elems=tet.tetrahedralize(order=1, mindihedral=20, minratio=1.5)\n",
    "\n",
    "tet.write('FE_segmentation_full.vtk', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1305c4d7-ade4-4f5e-b377-18ae57041db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "meshel = meshio.read('FE_segmentation_full.vtk')\n",
    "meshel.write('FE_segmentation.inp')\n",
    "\n",
    "for c in range(1, np.max(im_nuclei_segmented)+1):\n",
    "    globals()[str(c)+'cell_el']=[]\n",
    "\n",
    "for ce, x in enumerate(elems):\n",
    "    #print(np.shape(np.uint16(np.mean(nodes[x],0))))\n",
    "    coord=np.int16(np.round(np.mean(nodes[x],0),0))\n",
    "    step=0\n",
    "    taken=False\n",
    "    while not(taken):\n",
    "        step+=1\n",
    "        coord[coord<step]=1\n",
    "        for k in [0,1,2]:\n",
    "            if coord[k]>=np.shape(im_nuclei_segmented)[k]+1-step:coord[k]=np.shape(im_nuclei_segmented)[k]-1\n",
    "        elemlist=im_nuclei_segmented[coord[0]-step:coord[0]+1+step,coord[1]-step:coord[1]+1+step,coord[2]-step:coord[2]+1+step].flatten()\n",
    "        #print(elemlist)\n",
    "        if sum(elemlist)>0:\n",
    "            c_el=st.mode(elemlist[elemlist!=0])\n",
    "            taken=True\n",
    "\n",
    "    #print(c_el)\n",
    "    if c_el!=0:\n",
    "        globals()[str(c_el)+'cell_el'].append(ce+1)\n",
    "\n",
    "f = open(\"FE_segmentation.inp\", \"a\")\n",
    "for c in range(1,np.max(im_nuclei_segmented)+1):\n",
    "    f.write(\"*Elset, elset=cell\" + str(c) + \"\\n\")\n",
    "    j=1\n",
    "    for t in range(1, np.size(globals()[str(c)+'cell_el'])):\n",
    "        f.write(str(globals()[str(c)+'cell_el'][t]) + \",\")\n",
    "        j+=1\n",
    "        if j>16:\n",
    "            f.write(\"\\n\")\n",
    "            j=1\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2513300b-4e15-4b54-bea3-b60a737b3727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now insert *PART header manually\n",
    "with open(\"FE_segmentation.inp\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with open(Path(input_file).stem + \"_FEA.inp\", \"w\") as f:\n",
    "    for line in lines:\n",
    "        if (line==\"*NODE\\n\"):\n",
    "            f.write(\"*PART, name=Part-1\\n\")\n",
    "        f.write(line)\n",
    "    f.write(\"*END PART\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab0a4d-5051-4a2a-972b-7e3a1c3d8ece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
